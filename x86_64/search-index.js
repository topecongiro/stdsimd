var N = null;var searchIndex = {};
searchIndex["coresimd"]={"doc":"SIMD and vendor intrinsics support library.","items":[[0,"arch","coresimd","Platform dependent vendor intrinsics.",N,N],[0,"x86_64","coresimd::arch","Platform-specific intrinsics for the `x86_64` platform.",N,N],[3,"__m64","coresimd::arch::x86_64","64-bit wide integer vector type, x86-specific",N,N],[3,"__m128i","","128-bit wide integer vector type, x86-specific",N,N],[3,"__m128","","128-bit wide set of four `f32` types, x86-specific",N,N],[3,"__m128d","","128-bit wide set of two `f64` types, x86-specific",N,N],[3,"__m256i","","256-bit wide integer vector type, x86-specific",N,N],[3,"__m256","","256-bit wide set of eight `f32` types, x86-specific",N,N],[3,"__m256d","","256-bit wide set of four `f64` types, x86-specific",N,N],[3,"CpuidResult","","Result of the `cpuid` instruction.",N,N],[12,"eax","","EAX register.",0,N],[12,"ebx","","EBX register.",0,N],[12,"ecx","","ECX register.",0,N],[12,"edx","","EDX register.",0,N],[5,"_fxsave","","Saves the `x87` FPU, `MMX` technology, `XMM`, and `MXCSR` registers to the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_fxrstor","","Restores the `XMM`, `MMX`, `MXCSR`, and `x87` FPU registers from the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_bswap","","Return an integer with the reversed byte order of x",N,[[["i32"]],["i32"]]],[5,"_rdtsc","","Reads the current value of the processor’s time-stamp counter.",N,[[],["i64"]]],[5,"__rdtscp","","Reads the current value of the processor’s time-stamp counter and the `IA32_TSC_AUX MSR`.",N,N],[5,"__cpuid_count","","Returns the result of the `cpuid` instruction for a given `leaf` (`EAX`) and `sub_leaf` (`ECX`).",N,[[["u32"],["u32"]],["cpuidresult"]]],[5,"__cpuid","","See `__cpuid_count`.",N,[[["u32"]],["cpuidresult"]]],[5,"has_cpuid","","Does the host support the `cpuid` instruction?",N,[[],["bool"]]],[5,"__get_cpuid_max","","Returns the highest-supported `leaf` (`EAX`) and sub-leaf (`ECX`) `cpuid` values.",N,N],[5,"_xsave","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_xrstor","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_xsetbv","","Copy 64-bits from `val` to the extended control register (`XCR`) specified by `a`.",N,[[["u32"],["u64"]]]],[5,"_xgetbv","","Reads the contents of the extended control register `XCR` specified in `xcr_no`.",N,[[["u32"]],["u64"]]],[5,"_xsaveopt","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_xsavec","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_xsaves","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`",N,N],[5,"_xrstors","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_mm_add_ss","","Adds the first component of `a` and `b`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_add_ps","","Adds __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_sub_ss","","Subtracts the first component of `b` from `a`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_sub_ps","","Subtracts __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_mul_ss","","Multiplies the first component of `a` and `b`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_mul_ps","","Multiplies __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_div_ss","","Divides the first component of `b` by `a`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_div_ps","","Divides __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_sqrt_ss","","Return the square root of the first single-precision (32-bit) floating-point element in `a`, the other elements are unchanged.",N,[[["__m128"]],["__m128"]]],[5,"_mm_sqrt_ps","","Return the square root of packed single-precision (32-bit) floating-point elements in `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm_rcp_ss","","Return the approximate reciprocal of the first single-precision (32-bit) floating-point element in `a`, the other elements are unchanged.",N,[[["__m128"]],["__m128"]]],[5,"_mm_rcp_ps","","Return the approximate reciprocal of packed single-precision (32-bit) floating-point elements in `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm_rsqrt_ss","","Return the approximate reciprocal square root of the fist single-precision (32-bit) floating-point elements in `a`, the other elements are unchanged.",N,[[["__m128"]],["__m128"]]],[5,"_mm_rsqrt_ps","","Return the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm_min_ss","","Compare the first single-precision (32-bit) floating-point element of `a` and `b`, and return the minimum value in the first element of the return value, the other elements are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_min_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return the corresponding minimum values.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_max_ss","","Compare the first single-precision (32-bit) floating-point element of `a` and `b`, and return the maximum value in the first element of the return value, the other elements are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_max_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return the corresponding maximum values.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_and_ps","","Bitwise AND of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_andnot_ps","","Bitwise AND-NOT of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_or_ps","","Bitwise OR of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_xor_ps","","Bitwise exclusive OR of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpeq_ss","","Compare the lowest `f32` of both inputs for equality. The lowest 32 bits of the result will be `0xffffffff` if the two inputs are equal, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmplt_ss","","Compare the lowest `f32` of both inputs for less than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is less than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmple_ss","","Compare the lowest `f32` of both inputs for less than or equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is less than or equal `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpgt_ss","","Compare the lowest `f32` of both inputs for greater than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is greater than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpge_ss","","Compare the lowest `f32` of both inputs for greater than or equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is greater than or equal `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpneq_ss","","Compare the lowest `f32` of both inputs for inequality. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not equal to `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpnlt_ss","","Compare the lowest `f32` of both inputs for not-less-than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not less than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpnle_ss","","Compare the lowest `f32` of both inputs for not-less-than-or-equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not less than or equal to `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpngt_ss","","Compare the lowest `f32` of both inputs for not-greater-than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not greater than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpnge_ss","","Compare the lowest `f32` of both inputs for not-greater-than-or-equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not greater than or equal to `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpord_ss","","Check if the lowest `f32` of both inputs are ordered. The lowest 32 bits of the result will be `0xffffffff` if neither of `a.extract(0)` or `b.extract(0)` is a NaN, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpunord_ss","","Check if the lowest `f32` of both inputs are unordered. The lowest 32 bits of the result will be `0xffffffff` if any of `a.extract(0)` or `b.extract(0)` is a NaN, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpeq_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input elements were equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmplt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is less than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmple_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is less than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpgt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is greater than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpge_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is greater than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpneq_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input elements are not equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpnlt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not less than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpnle_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not less than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpngt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not greater than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpnge_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not greater than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpord_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. Returns four floats that have one of two possible bit patterns. The element in the output vector will be `0xffffffff` if the input elements in `a` and `b` are ordered (i.e., neither of them is a NaN), or 0 otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpunord_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. Returns four floats that have one of two possible bit patterns. The element in the output vector will be `0xffffffff` if the input elements in `a` and `b` are unordered (i.e., at least on of them is a NaN), or 0 otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_comieq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_comilt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_comile_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than or equal to the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_comigt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_comige_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than or equal to the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_comineq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are not equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_ucomieq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are equal, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_ucomilt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_ucomile_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than or equal to the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_ucomigt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_ucomige_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than or equal to the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_ucomineq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are not equal, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_cvtss_si32","","Convert the lowest 32 bit float in the input vector to a 32 bit integer.",N,[[["__m128"]],["i32"]]],[5,"_mm_cvt_ss2si","","Alias for `_mm_cvtss_si32`.",N,[[["__m128"]],["i32"]]],[5,"_mm_cvttss_si32","","Convert the lowest 32 bit float in the input vector to a 32 bit integer with truncation.",N,[[["__m128"]],["i32"]]],[5,"_mm_cvtt_ss2si","","Alias for `_mm_cvttss_si32`.",N,[[["__m128"]],["i32"]]],[5,"_mm_cvtss_f32","","Extract the lowest 32 bit float from the input vector.",N,[[["__m128"]],["f32"]]],[5,"_mm_cvtsi32_ss","","Convert a 32 bit integer to a 32 bit float. The result vector is the input vector `a` with the lowest 32 bit float replaced by the converted integer.",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm_cvt_si2ss","","Alias for `_mm_cvtsi32_ss`.",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm_set_ss","","Construct a `__m128` with the lowest element set to `a` and the rest set to zero.",N,[[["f32"]],["__m128"]]],[5,"_mm_set1_ps","","Construct a `__m128` with all element set to `a`.",N,[[["f32"]],["__m128"]]],[5,"_mm_set_ps1","","Alias for `_mm_set1_ps`",N,[[["f32"]],["__m128"]]],[5,"_mm_set_ps","","Construct a `__m128` from four floating point values highest to lowest.",N,[[["f32"],["f32"],["f32"],["f32"]],["__m128"]]],[5,"_mm_setr_ps","","Construct a `__m128` from four floating point values lowest to highest.",N,[[["f32"],["f32"],["f32"],["f32"]],["__m128"]]],[5,"_mm_setzero_ps","","Construct a `__m128` with all elements initialized to zero.",N,[[],["__m128"]]],[5,"_MM_SHUFFLE","","A utility function for creating masks to use with Intel shuffle and permute intrinsics.",N,[[["u32"],["u32"],["u32"],["u32"]],["u32"]]],[5,"_mm_shuffle_ps","","Shuffle packed single-precision (32-bit) floating-point elements in `a` and `b` using `mask`.",N,[[["__m128"],["__m128"],["u32"]],["__m128"]]],[5,"_mm_unpackhi_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the higher half of `a` and `b`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_unpacklo_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the lower half of `a` and `b`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_movehl_ps","","Combine higher half of `a` and `b`. The highwe half of `b` occupies the lower half of result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_movelh_ps","","Combine lower half of `a` and `b`. The lower half of `b` occupies the higher half of result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_movemask_ps","","Return a mask of the most significant bit of each element in `a`.",N,[[["__m128"]],["i32"]]],[5,"_mm_loadh_pi","","Set the upper two single-precision floating-point values with 64 bits of data loaded from the address `p`; the lower two values are passed through from `a`.",N,N],[5,"_mm_loadl_pi","","Load two floats from `p` into the lower half of a `__m128`. The upper half is copied from the upper half of `a`.",N,N],[5,"_mm_load_ss","","Construct a `__m128` with the lowest element read from `p` and the other elements set to zero.",N,N],[5,"_mm_load1_ps","","Construct a `__m128` by duplicating the value read from `p` into all elements.",N,N],[5,"_mm_load_ps1","","Alias for `_mm_load1_ps`",N,N],[5,"_mm_load_ps","","Load four `f32` values from aligned memory into a `__m128`. If the pointer is not aligned to a 128-bit boundary (16 bytes) a general protection fault will be triggered (fatal program crash).",N,N],[5,"_mm_loadu_ps","","Load four `f32` values from memory into a `__m128`. There are no restrictions on memory alignment. For aligned memory `_mm_load_ps` may be faster.",N,N],[5,"_mm_loadr_ps","","Load four `f32` values from aligned memory into a `__m128` in reverse order.",N,N],[5,"_mm_storeh_pi","","Store the upper half of `a` (64 bits) into memory.",N,N],[5,"_mm_storel_pi","","Store the lower half of `a` (64 bits) into memory.",N,N],[5,"_mm_store_ss","","Store the lowest 32 bit float of `a` into memory.",N,N],[5,"_mm_store1_ps","","Store the lowest 32 bit float of `a` repeated four times into aligned memory.",N,N],[5,"_mm_store_ps1","","Alias for `_mm_store1_ps`",N,N],[5,"_mm_store_ps","","Store four 32-bit floats into aligned memory.",N,N],[5,"_mm_storeu_ps","","Store four 32-bit floats into memory. There are no restrictions on memory alignment. For aligned memory `_mm_store_ps` may be faster.",N,N],[5,"_mm_storer_ps","","Store four 32-bit floats into aligned memory in reverse order.",N,N],[5,"_mm_move_ss","","Return a `__m128` with the first component from `b` and the remaining components from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_sfence","","Perform a serializing operation on all store-to-memory instructions that were issued prior to this instruction.",N,[[]]],[5,"_mm_getcsr","","Get the unsigned 32-bit value of the MXCSR control and status register.",N,[[],["u32"]]],[5,"_mm_setcsr","","Set the MXCSR register with the 32-bit unsigned integer value.",N,[[["u32"]]]],[5,"_MM_GET_EXCEPTION_MASK","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_MM_GET_EXCEPTION_STATE","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_MM_GET_FLUSH_ZERO_MODE","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_MM_GET_ROUNDING_MODE","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_MM_SET_EXCEPTION_MASK","","See `_mm_setcsr`",N,[[["u32"]]]],[5,"_MM_SET_EXCEPTION_STATE","","See `_mm_setcsr`",N,[[["u32"]]]],[5,"_MM_SET_FLUSH_ZERO_MODE","","See `_mm_setcsr`",N,[[["u32"]]]],[5,"_MM_SET_ROUNDING_MODE","","See `_mm_setcsr`",N,[[["u32"]]]],[5,"_mm_prefetch","","Fetch the cache line that contains address `p` using the given `strategy`.",N,N],[5,"_mm_undefined_ps","","Return vector of type __m128 with undefined elements.",N,[[],["__m128"]]],[5,"_MM_TRANSPOSE4_PS","","Transpose the 4x4 matrix formed by 4 rows of __m128 in place.",N,[[["__m128"],["__m128"],["__m128"],["__m128"]]]],[5,"_mm_stream_ps","","Stores `a` into the memory at `mem_addr` using a non-temporal memory hint.",N,N],[5,"_mm_stream_pi","","Store 64-bits of integer data from a into memory using a non-temporal memory hint.",N,N],[5,"_mm_max_pi16","","Compares the packed 16-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pmaxsw","","Compares the packed 16-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_max_pu8","","Compares the packed 8-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pmaxub","","Compares the packed 8-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_min_pi16","","Compares the packed 16-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pminsw","","Compares the packed 16-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_min_pu8","","Compares the packed 8-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pminub","","Compares the packed 8-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_mulhi_pu16","","Multiplies packed 16-bit unsigned integer values and writes the high-order 16 bits of each 32-bit product to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_mullo_pi16","","Multiplies packed 16-bit integer values and writes the low-order 16 bits of each 32-bit product to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pmulhuw","","Multiplies packed 16-bit unsigned integer values and writes the high-order 16 bits of each 32-bit product to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_avg_pu8","","Computes the rounded averages of the packed unsigned 8-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pavgb","","Computes the rounded averages of the packed unsigned 8-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_avg_pu16","","Computes the rounded averages of the packed unsigned 16-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pavgw","","Computes the rounded averages of the packed unsigned 16-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sad_pu8","","Subtracts the corresponding 8-bit unsigned integer values of the two 64-bit vector operands and computes the absolute value for each of the difference. Then sum of the 8 absolute differences is written to the bits `[15:0]` of the destination; the remaining bits `[63:16]` are cleared.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psadbw","","Subtracts the corresponding 8-bit unsigned integer values of the two 64-bit vector operands and computes the absolute value for each of the difference. Then sum of the 8 absolute differences is written to the bits `[15:0]` of the destination; the remaining bits `[63:16]` are cleared.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cvtpi32_ps","","Converts two elements of a 64-bit vector of `[2 x i32]` into two floating point values and writes them to the lower 64-bits of the destination. The remaining higher order elements of the destination are copied from the corresponding elements in the first operand.",N,[[["__m128"],["__m64"]],["__m128"]]],[5,"_mm_cvt_pi2ps","","Converts two elements of a 64-bit vector of `[2 x i32]` into two floating point values and writes them to the lower 64-bits of the destination. The remaining higher order elements of the destination are copied from the corresponding elements in the first operand.",N,[[["__m128"],["__m64"]],["__m128"]]],[5,"_mm_cvtpi8_ps","","Converts the lower 4 8-bit values of `a` into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm_cvtpu8_ps","","Converts the lower 4 8-bit values of `a` into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm_cvtpi16_ps","","Converts a 64-bit vector of `i16`s into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm_cvtpu16_ps","","Converts a 64-bit vector of `i16`s into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm_cvtpi32x2_ps","","Converts the two 32-bit signed integer values from each 64-bit vector operand of `[2 x i32]` into a 128-bit vector of `[4 x float]`.",N,[[["__m64"],["__m64"]],["__m128"]]],[5,"_mm_maskmove_si64","","Conditionally copies the values from each 8-bit element in the first 64-bit integer vector operand to the specified memory location, as specified by the most significant bit in the corresponding element in the second 64-bit integer vector operand.",N,N],[5,"_m_maskmovq","","Conditionally copies the values from each 8-bit element in the first 64-bit integer vector operand to the specified memory location, as specified by the most significant bit in the corresponding element in the second 64-bit integer vector operand.",N,N],[5,"_mm_extract_pi16","","Extracts 16-bit element from a 64-bit vector of `[4 x i16]` and returns it, as specified by the immediate integer operand.",N,[[["__m64"],["i32"]],["i32"]]],[5,"_m_pextrw","","Extracts 16-bit element from a 64-bit vector of `[4 x i16]` and returns it, as specified by the immediate integer operand.",N,[[["__m64"],["i32"]],["i32"]]],[5,"_mm_insert_pi16","","Copies data from the 64-bit vector of `[4 x i16]` to the destination, and inserts the lower 16-bits of an integer operand at the 16-bit offset specified by the immediate operand `n`.",N,[[["__m64"],["i32"],["i32"]],["__m64"]]],[5,"_m_pinsrw","","Copies data from the 64-bit vector of `[4 x i16]` to the destination, and inserts the lower 16-bits of an integer operand at the 16-bit offset specified by the immediate operand `n`.",N,[[["__m64"],["i32"],["i32"]],["__m64"]]],[5,"_mm_movemask_pi8","","Takes the most significant bit from each 8-bit element in a 64-bit integer vector to create a 16-bit mask value. Zero-extends the value to 32-bit integer and writes it to the destination.",N,[[["__m64"]],["i32"]]],[5,"_m_pmovmskb","","Takes the most significant bit from each 8-bit element in a 64-bit integer vector to create a 16-bit mask value. Zero-extends the value to 32-bit integer and writes it to the destination.",N,[[["__m64"]],["i32"]]],[5,"_mm_shuffle_pi16","","Shuffles the 4 16-bit integers from a 64-bit integer vector to the destination, as specified by the immediate value operand.",N,[[["__m64"],["i32"]],["__m64"]]],[5,"_m_pshufw","","Shuffles the 4 16-bit integers from a 64-bit integer vector to the destination, as specified by the immediate value operand.",N,[[["__m64"],["i32"]],["__m64"]]],[5,"_mm_cvttps_pi32","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128"]],["__m64"]]],[5,"_mm_cvtt_ps2pi","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128"]],["__m64"]]],[5,"_mm_cvtps_pi32","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128"]],["__m64"]]],[5,"_mm_cvt_ps2pi","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128"]],["__m64"]]],[5,"_mm_cvtps_pi16","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 16-bit integers.",N,[[["__m128"]],["__m64"]]],[5,"_mm_cvtps_pi8","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 8-bit integers, and returns theem in the lower 4 elements of the result.",N,[[["__m128"]],["__m64"]]],[5,"_mm_pause","","Provide a hint to the processor that the code sequence is a spin-wait loop.",N,[[]]],[5,"_mm_clflush","","Invalidate and flush the cache line that contains `p` from all levels of the cache hierarchy.",N,N],[5,"_mm_lfence","","Perform a serializing operation on all load-from-memory instructions that were issued prior to this instruction.",N,[[]]],[5,"_mm_mfence","","Perform a serializing operation on all load-from-memory and store-to-memory instructions that were issued prior to this instruction.",N,[[]]],[5,"_mm_add_epi8","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_add_epi16","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_add_epi32","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_add_epi64","","Add packed 64-bit integers in `a` and \"b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_adds_epi8","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_adds_epi16","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_adds_epu8","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_adds_epu16","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_avg_epu8","","Average packed unsigned 8-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_avg_epu16","","Average packed unsigned 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_madd_epi16","","Multiply and then horizontally add signed 16 bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_max_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_max_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_min_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_min_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mulhi_epi16","","Multiply the packed 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mulhi_epu16","","Multiply the packed unsigned 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mullo_epi16","","Multiply the packed 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mul_epu32","","Multiply the low unsigned 32-bit integers from each packed 64-bit element in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sad_epu8","","Sum the absolute differences of packed unsigned 8-bit integers.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sub_epi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sub_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sub_epi32","","Subtract packed 32-bit integers in `b` from packed 32-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sub_epi64","","Subtract packed 64-bit integers in `b` from packed 64-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_subs_epi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_subs_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_subs_epu8","","Subtract packed unsigned 8-bit integers in `b` from packed unsigned 8-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_subs_epu16","","Subtract packed unsigned 16-bit integers in `b` from packed unsigned 16-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_slli_si128","","Shift `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_bslli_si128","","Shift `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_bsrli_si128","","Shift `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_slli_epi16","","Shift packed 16-bit integers in `a` left by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_sll_epi16","","Shift packed 16-bit integers in `a` left by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_slli_epi32","","Shift packed 32-bit integers in `a` left by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_sll_epi32","","Shift packed 32-bit integers in `a` left by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_slli_epi64","","Shift packed 64-bit integers in `a` left by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_sll_epi64","","Shift packed 64-bit integers in `a` left by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_srai_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_sra_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_srai_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_sra_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_srli_si128","","Shift `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_srli_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_srl_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_srli_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_srl_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_srli_epi64","","Shift packed 64-bit integers in `a` right by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_srl_epi64","","Shift packed 64-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_and_si128","","Compute the bitwise AND of 128 bits (representing integer data) in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_andnot_si128","","Compute the bitwise NOT of 128 bits (representing integer data) in `a` and then AND with `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_or_si128","","Compute the bitwise OR of 128 bits (representing integer data) in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_xor_si128","","Compute the bitwise XOR of 128 bits (representing integer data) in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpeq_epi8","","Compare packed 8-bit integers in `a` and `b` for equality.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpeq_epi16","","Compare packed 16-bit integers in `a` and `b` for equality.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpeq_epi32","","Compare packed 32-bit integers in `a` and `b` for equality.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpgt_epi8","","Compare packed 8-bit integers in `a` and `b` for greater-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpgt_epi16","","Compare packed 16-bit integers in `a` and `b` for greater-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpgt_epi32","","Compare packed 32-bit integers in `a` and `b` for greater-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmplt_epi8","","Compare packed 8-bit integers in `a` and `b` for less-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmplt_epi16","","Compare packed 16-bit integers in `a` and `b` for less-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmplt_epi32","","Compare packed 32-bit integers in `a` and `b` for less-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi32_pd","","Convert the lower two packed 32-bit integers in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128i"]],["__m128d"]]],[5,"_mm_cvtsi32_sd","","Return `a` with its lower element replaced by `b` after converting it to an `f64`.",N,[[["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_cvtepi32_ps","","Convert packed 32-bit integers in `a` to packed single-precision (32-bit) floating-point elements.",N,[[["__m128i"]],["__m128"]]],[5,"_mm_cvtps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128"]],["__m128i"]]],[5,"_mm_cvtsi32_si128","","Return a vector whose lowest element is `a` and all higher elements are `0`.",N,[[["i32"]],["__m128i"]]],[5,"_mm_cvtsi128_si32","","Return the lowest element of `a`.",N,[[["__m128i"]],["i32"]]],[5,"_mm_set_epi64x","","Set packed 64-bit integers with the supplied values, from highest to lowest.",N,[[["i64"],["i64"]],["__m128i"]]],[5,"_mm_set_epi32","","Set packed 32-bit integers with the supplied values.",N,[[["i32"],["i32"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_set_epi16","","Set packed 16-bit integers with the supplied values.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m128i"]]],[5,"_mm_set_epi8","","Set packed 8-bit integers with the supplied values.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m128i"]]],[5,"_mm_set1_epi64x","","Broadcast 64-bit integer `a` to all elements.",N,[[["i64"]],["__m128i"]]],[5,"_mm_set1_epi32","","Broadcast 32-bit integer `a` to all elements.",N,[[["i32"]],["__m128i"]]],[5,"_mm_set1_epi16","","Broadcast 16-bit integer `a` to all elements.",N,[[["i16"]],["__m128i"]]],[5,"_mm_set1_epi8","","Broadcast 8-bit integer `a` to all elements.",N,[[["i8"]],["__m128i"]]],[5,"_mm_setr_epi32","","Set packed 32-bit integers with the supplied values in reverse order.",N,[[["i32"],["i32"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_setr_epi16","","Set packed 16-bit integers with the supplied values in reverse order.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m128i"]]],[5,"_mm_setr_epi8","","Set packed 8-bit integers with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m128i"]]],[5,"_mm_setzero_si128","","Returns a vector with all elements set to zero.",N,[[],["__m128i"]]],[5,"_mm_loadl_epi64","","Load 64-bit integer from memory into first element of returned vector.",N,N],[5,"_mm_load_si128","","Load 128-bits of integer data from memory into a new vector.",N,N],[5,"_mm_loadu_si128","","Load 128-bits of integer data from memory into a new vector.",N,N],[5,"_mm_maskmoveu_si128","","Conditionally store 8-bit integer elements from `a` into memory using `mask`.",N,N],[5,"_mm_store_si128","","Store 128-bits of integer data from `a` into memory.",N,N],[5,"_mm_storeu_si128","","Store 128-bits of integer data from `a` into memory.",N,N],[5,"_mm_storel_epi64","","Store the lower 64-bit integer `a` to a memory location.",N,N],[5,"_mm_stream_si128","","Stores a 128-bit integer vector to a 128-bit aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_stream_si32","","Stores a 32-bit integer value in the specified memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_move_epi64","","Return a vector where the low element is extracted from `a` and its upper element is zero.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_packs_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using signed saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_packs_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using signed saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_packus_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using unsigned saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_extract_epi16","","Return the `imm8` element of `a`.",N,[[["__m128i"],["i32"]],["i32"]]],[5,"_mm_insert_epi16","","Return a new vector where the `imm8` element of `a` is replaced with `i`.",N,[[["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_movemask_epi8","","Return a mask of the most significant bit of each element in `a`.",N,[[["__m128i"]],["i32"]]],[5,"_mm_shuffle_epi32","","Shuffle 32-bit integers in `a` using the control in `imm8`.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_shufflehi_epi16","","Shuffle 16-bit integers in the high 64 bits of `a` using the control in `imm8`.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_shufflelo_epi16","","Shuffle 16-bit integers in the low 64 bits of `a` using the control in `imm8`.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_unpackhi_epi8","","Unpack and interleave 8-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpackhi_epi16","","Unpack and interleave 16-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpackhi_epi32","","Unpack and interleave 32-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpackhi_epi64","","Unpack and interleave 64-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpacklo_epi8","","Unpack and interleave 8-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpacklo_epi16","","Unpack and interleave 16-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpacklo_epi32","","Unpack and interleave 32-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpacklo_epi64","","Unpack and interleave 64-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_add_sd","","Return a new vector with the low element of `a` replaced by the sum of the low elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_add_pd","","Add packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_div_sd","","Return a new vector with the low element of `a` replaced by the result of diving the lower element of `a` by the lower element of `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_div_pd","","Divide packed double-precision (64-bit) floating-point elements in `a` by packed elements in `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_max_sd","","Return a new vector with the low element of `a` replaced by the maximum of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_max_pd","","Return a new vector with the maximum values from corresponding elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_min_sd","","Return a new vector with the low element of `a` replaced by the minimum of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_min_pd","","Return a new vector with the minimum values from corresponding elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_mul_sd","","Return a new vector with the low element of `a` replaced by multiplying the low elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_mul_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_sqrt_sd","","Return a new vector with the low element of `a` replaced by the square root of the lower element `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_sqrt_pd","","Return a new vector with the square root of each of the values in `a`.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm_sub_sd","","Return a new vector with the low element of `a` replaced by subtracting the low element by `b` from the low element of `a`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_sub_pd","","Subtract packed double-precision (64-bit) floating-point elements in `b` from `a`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_and_pd","","Compute the bitwise AND of packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_andnot_pd","","Compute the bitwise NOT of `a` and then AND with `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_or_pd","","Compute the bitwise OR of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_xor_pd","","Compute the bitwise OR of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpeq_sd","","Return a new vector with the low element of `a` replaced by the equality comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmplt_sd","","Return a new vector with the low element of `a` replaced by the less-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmple_sd","","Return a new vector with the low element of `a` replaced by the less-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpgt_sd","","Return a new vector with the low element of `a` replaced by the greater-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpge_sd","","Return a new vector with the low element of `a` replaced by the greater-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpord_sd","","Return a new vector with the low element of `a` replaced by the result of comparing both of the lower elements of `a` and `b` to `NaN`. If neither are equal to `NaN` then `0xFFFFFFFFFFFFFFFF` is used and `0` otherwise.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpunord_sd","","Return a new vector with the low element of `a` replaced by the result of comparing both of the lower elements of `a` and `b` to `NaN`. If either is equal to `NaN` then `0xFFFFFFFFFFFFFFFF` is used and `0` otherwise.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpneq_sd","","Return a new vector with the low element of `a` replaced by the not-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpnlt_sd","","Return a new vector with the low element of `a` replaced by the not-less-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpnle_sd","","Return a new vector with the low element of `a` replaced by the not-less-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpngt_sd","","Return a new vector with the low element of `a` replaced by the not-greater-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpnge_sd","","Return a new vector with the low element of `a` replaced by the not-greater-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpeq_pd","","Compare corresponding elements in `a` and `b` for equality.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmplt_pd","","Compare corresponding elements in `a` and `b` for less-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmple_pd","","Compare corresponding elements in `a` and `b` for less-than-or-equal",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpgt_pd","","Compare corresponding elements in `a` and `b` for greater-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpge_pd","","Compare corresponding elements in `a` and `b` for greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpord_pd","","Compare corresponding elements in `a` and `b` to see if neither is `NaN`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpunord_pd","","Compare corresponding elements in `a` and `b` to see if either is `NaN`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpneq_pd","","Compare corresponding elements in `a` and `b` for not-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpnlt_pd","","Compare corresponding elements in `a` and `b` for not-less-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpnle_pd","","Compare corresponding elements in `a` and `b` for not-less-than-or-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpngt_pd","","Compare corresponding elements in `a` and `b` for not-greater-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpnge_pd","","Compare corresponding elements in `a` and `b` for not-greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_comieq_sd","","Compare the lower element of `a` and `b` for equality.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_comilt_sd","","Compare the lower element of `a` and `b` for less-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_comile_sd","","Compare the lower element of `a` and `b` for less-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_comigt_sd","","Compare the lower element of `a` and `b` for greater-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_comige_sd","","Compare the lower element of `a` and `b` for greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_comineq_sd","","Compare the lower element of `a` and `b` for not-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_ucomieq_sd","","Compare the lower element of `a` and `b` for equality.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_ucomilt_sd","","Compare the lower element of `a` and `b` for less-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_ucomile_sd","","Compare the lower element of `a` and `b` for less-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_ucomigt_sd","","Compare the lower element of `a` and `b` for greater-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_ucomige_sd","","Compare the lower element of `a` and `b` for greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_ucomineq_sd","","Compare the lower element of `a` and `b` for not-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_cvtpd_ps","","Convert packed double-precision (64-bit) floating-point elements in \"a\" to packed single-precision (32-bit) floating-point elements",N,[[["__m128d"]],["__m128"]]],[5,"_mm_cvtps_pd","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128"]],["__m128d"]]],[5,"_mm_cvtpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128d"]],["__m128i"]]],[5,"_mm_cvtsd_si32","","Convert the lower double-precision (64-bit) floating-point element in a to a 32-bit integer.",N,[[["__m128d"]],["i32"]]],[5,"_mm_cvtsd_ss","","Convert the lower double-precision (64-bit) floating-point element in `b` to a single-precision (32-bit) floating-point element, store the result in the lower element of the return value, and copy the upper element from `a` to the upper element the return value.",N,[[["__m128"],["__m128d"]],["__m128"]]],[5,"_mm_cvtsd_f64","","Return the lower double-precision (64-bit) floating-point element of \"a\".",N,[[["__m128d"]],["f64"]]],[5,"_mm_cvtss_sd","","Convert the lower single-precision (32-bit) floating-point element in `b` to a double-precision (64-bit) floating-point element, store the result in the lower element of the return value, and copy the upper element from `a` to the upper element the return value.",N,[[["__m128d"],["__m128"]],["__m128d"]]],[5,"_mm_cvttpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128d"]],["__m128i"]]],[5,"_mm_cvttsd_si32","","Convert the lower double-precision (64-bit) floating-point element in `a` to a 32-bit integer with truncation.",N,[[["__m128d"]],["i32"]]],[5,"_mm_cvttps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128"]],["__m128i"]]],[5,"_mm_set_sd","","Copy double-precision (64-bit) floating-point element `a` to the lower element of the packed 64-bit return value.",N,[[["f64"]],["__m128d"]]],[5,"_mm_set1_pd","","Broadcast double-precision (64-bit) floating-point value a to all elements of the return value.",N,[[["f64"]],["__m128d"]]],[5,"_mm_set_pd1","","Broadcast double-precision (64-bit) floating-point value a to all elements of the return value.",N,[[["f64"]],["__m128d"]]],[5,"_mm_set_pd","","Set packed double-precision (64-bit) floating-point elements in the return value with the supplied values.",N,[[["f64"],["f64"]],["__m128d"]]],[5,"_mm_setr_pd","","Set packed double-precision (64-bit) floating-point elements in the return value with the supplied values in reverse order.",N,[[["f64"],["f64"]],["__m128d"]]],[5,"_mm_setzero_pd","","Returns packed double-precision (64-bit) floating-point elements with all zeros.",N,[[],["__m128d"]]],[5,"_mm_movemask_pd","","Return a mask of the most significant bit of each element in `a`.",N,[[["__m128d"]],["i32"]]],[5,"_mm_load_pd","","Load 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from memory into the returned vector. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_load_sd","","Loads a 64-bit double-precision value to the low element of a 128-bit integer vector and clears the upper element.",N,N],[5,"_mm_loadh_pd","","Loads a double-precision value into the high-order bits of a 128-bit vector of `[2 x double]`. The low-order bits are copied from the low-order bits of the first operand.",N,N],[5,"_mm_loadl_pd","","Loads a double-precision value into the low-order bits of a 128-bit vector of `[2 x double]`. The high-order bits are copied from the high-order bits of the first operand.",N,N],[5,"_mm_stream_pd","","Stores a 128-bit floating point vector of `[2 x double]` to a 128-bit aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_store_sd","","Stores the lower 64 bits of a 128-bit vector of `[2 x double]` to a memory location.",N,N],[5,"_mm_store_pd","","Store 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_storeu_pd","","Store 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_store1_pd","","Store the lower double-precision (64-bit) floating-point element from `a` into 2 contiguous elements in memory. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_store_pd1","","Store the lower double-precision (64-bit) floating-point element from `a` into 2 contiguous elements in memory. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_storer_pd","","Store 2 double-precision (64-bit) floating-point elements from `a` into memory in reverse order. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_storeh_pd","","Stores the upper 64 bits of a 128-bit vector of `[2 x double]` to a memory location.",N,N],[5,"_mm_storel_pd","","Stores the lower 64 bits of a 128-bit vector of `[2 x double]` to a memory location.",N,N],[5,"_mm_load1_pd","","Load a double-precision (64-bit) floating-point element from memory into both elements of returned vector.",N,N],[5,"_mm_load_pd1","","Load a double-precision (64-bit) floating-point element from memory into both elements of returned vector.",N,N],[5,"_mm_loadr_pd","","Load 2 double-precision (64-bit) floating-point elements from memory into the returned vector in reverse order. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_loadu_pd","","Load 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from memory into the returned vector. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_shuffle_pd","","Constructs a 128-bit floating-point vector of `[2 x double]` from two 128-bit vector parameters of `[2 x double]`, using the immediate-value parameter as a specifier.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_move_sd","","Constructs a 128-bit floating-point vector of `[2 x double]`. The lower 64 bits are set to the lower 64 bits of the second parameter. The upper 64 bits are set to the upper 64 bits of the first parameter.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_castpd_ps","","Casts a 128-bit floating-point vector of `[2 x double]` into a 128-bit floating-point vector of `[4 x float]`.",N,[[["__m128d"]],["__m128"]]],[5,"_mm_castpd_si128","","Casts a 128-bit floating-point vector of `[2 x double]` into a 128-bit integer vector.",N,[[["__m128d"]],["__m128i"]]],[5,"_mm_castps_pd","","Casts a 128-bit floating-point vector of `[4 x float]` into a 128-bit floating-point vector of `[2 x double]`.",N,[[["__m128"]],["__m128d"]]],[5,"_mm_castps_si128","","Casts a 128-bit floating-point vector of `[4 x float]` into a 128-bit integer vector.",N,[[["__m128"]],["__m128i"]]],[5,"_mm_castsi128_pd","","Casts a 128-bit integer vector into a 128-bit floating-point vector of `[2 x double]`.",N,[[["__m128i"]],["__m128d"]]],[5,"_mm_castsi128_ps","","Casts a 128-bit integer vector into a 128-bit floating-point vector of `[4 x float]`.",N,[[["__m128i"]],["__m128"]]],[5,"_mm_undefined_pd","","Return vector of type __m128d with undefined elements.",N,[[],["__m128d"]]],[5,"_mm_undefined_si128","","Return vector of type __m128i with undefined elements.",N,[[],["__m128i"]]],[5,"_mm_unpackhi_pd","","The resulting `__m128d` element is composed by the low-order values of the two `__m128d` interleaved input elements, i.e.:",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_unpacklo_pd","","The resulting `__m128d` element is composed by the high-order values of the two `__m128d` interleaved input elements, i.e.:",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_add_si64","","Adds two signed or unsigned 64-bit integer values, returning the lower 64 bits of the sum.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_mul_su32","","Multiplies 32-bit unsigned integer values contained in the lower bits of the two 64-bit integer vectors and returns the 64-bit unsigned product.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sub_si64","","Subtracts signed or unsigned 64-bit integer values and writes the difference to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cvtpi32_pd","","Converts the two signed 32-bit integer elements of a 64-bit vector of `[2 x i32]` into two double-precision floating-point values, returned in a 128-bit vector of `[2 x double]`.",N,[[["__m64"]],["__m128d"]]],[5,"_mm_set_epi64","","Initializes both 64-bit values in a 128-bit vector of `[2 x i64]` with the specified 64-bit integer values.",N,[[["__m64"],["__m64"]],["__m128i"]]],[5,"_mm_set1_epi64","","Initializes both values in a 128-bit vector of `[2 x i64]` with the specified 64-bit value.",N,[[["__m64"]],["__m128i"]]],[5,"_mm_setr_epi64","","Constructs a 128-bit integer vector, initialized in reverse order with the specified 64-bit integral values.",N,[[["__m64"],["__m64"]],["__m128i"]]],[5,"_mm_movepi64_pi64","","Returns the lower 64 bits of a 128-bit integer vector as a 64-bit integer.",N,[[["__m128i"]],["__m64"]]],[5,"_mm_movpi64_epi64","","Moves the 64-bit operand to a 128-bit integer vector, zeroing the upper bits.",N,[[["__m64"]],["__m128i"]]],[5,"_mm_cvtpd_pi32","","Converts the two double-precision floating-point elements of a 128-bit vector of `[2 x double]` into two signed 32-bit integer values, returned in a 64-bit vector of `[2 x i32]`.",N,[[["__m128d"]],["__m64"]]],[5,"_mm_cvttpd_pi32","","Converts the two double-precision floating-point elements of a 128-bit vector of `[2 x double]` into two signed 32-bit integer values, returned in a 64-bit vector of `[2 x i32]`. If the result of either conversion is inexact, the result is truncated (rounded towards zero) regardless of the current MXCSR setting.",N,[[["__m128d"]],["__m64"]]],[5,"_mm_addsub_ps","","Alternatively add and subtract packed single-precision (32-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_addsub_pd","","Alternatively add and subtract packed double-precision (64-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_hadd_pd","","Horizontally add adjacent pairs of double-precision (64-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_hadd_ps","","Horizontally add adjacent pairs of single-precision (32-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_hsub_pd","","Horizontally subtract adjacent pairs of double-precision (64-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_hsub_ps","","Horizontally add adjacent pairs of single-precision (32-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_lddqu_si128","","Load 128-bits of integer data from unaligned memory. This intrinsic may perform better than `_mm_loadu_si128` when the data crosses a cache line boundary.",N,N],[5,"_mm_movedup_pd","","Duplicate the low double-precision (64-bit) floating-point element from `a`.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm_loaddup_pd","","Load a double-precision (64-bit) floating-point element from memory into both elements of return vector.",N,N],[5,"_mm_movehdup_ps","","Duplicate odd-indexed single-precision (32-bit) floating-point elements from `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm_moveldup_ps","","Duplicate even-indexed single-precision (32-bit) floating-point elements from `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm_abs_epi8","","Compute the absolute value of packed 8-bit signed integers in `a` and return the unsigned results.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_abs_epi16","","Compute the absolute value of each of the packed 16-bit signed integers in `a` and return the 16-bit unsigned integer",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_abs_epi32","","Compute the absolute value of each of the packed 32-bit signed integers in `a` and return the 32-bit unsigned integer",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_shuffle_epi8","","Shuffle bytes from `a` according to the content of `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_alignr_epi8","","Concatenate 16-byte blocks in `a` and `b` into a 32-byte temporary result, shift the result right by `n` bytes, and return the low 16 bytes.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_hadd_epi16","","Horizontally add the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_hadds_epi16","","Horizontally add the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`. Positive sums greater than 7FFFh are saturated to 7FFFh. Negative sums less than 8000h are saturated to 8000h.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_hadd_epi32","","Horizontally add the adjacent pairs of values contained in 2 packed 128-bit vectors of `[4 x i32]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_hsub_epi16","","Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_hsubs_epi16","","Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`. Positive differences greater than 7FFFh are saturated to 7FFFh. Negative differences less than 8000h are saturated to 8000h.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_hsub_epi32","","Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of `[4 x i32]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_maddubs_epi16","","Multiply corresponding pairs of packed 8-bit unsigned integer values contained in the first source operand and packed 8-bit signed integer values contained in the second source operand, add pairs of contiguous products with signed saturation, and writes the 16-bit sums to the corresponding bits in the destination.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mulhrs_epi16","","Multiply packed 16-bit signed integer values, truncate the 32-bit product to the 18 most significant bits by right-shifting, round the truncated value by adding 1, and write bits `[16:1]` to the destination.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sign_epi8","","Negate packed 8-bit integers in `a` when the corresponding signed 8-bit integer in `b` is negative, and return the result. Elements in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sign_epi16","","Negate packed 16-bit integers in `a` when the corresponding signed 16-bit integer in `b` is negative, and return the results. Elements in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sign_epi32","","Negate packed 32-bit integers in `a` when the corresponding signed 32-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_abs_pi8","","Compute the absolute value of packed 8-bit integers in `a` and return the unsigned results.",N,[[["__m64"]],["__m64"]]],[5,"_mm_abs_pi16","","Compute the absolute value of packed 8-bit integers in `a`, and return the unsigned results.",N,[[["__m64"]],["__m64"]]],[5,"_mm_abs_pi32","","Compute the absolute value of packed 32-bit integers in `a`, and return the unsigned results.",N,[[["__m64"]],["__m64"]]],[5,"_mm_shuffle_pi8","","Shuffle packed 8-bit integers in `a` according to shuffle control mask in the corresponding 8-bit element of `b`, and return the results",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_alignr_pi8","","Concatenates the two 64-bit integer vector operands, and right-shifts the result by the number of bytes specified in the immediate operand.",N,[[["__m64"],["__m64"],["i32"]],["__m64"]]],[5,"_mm_hadd_pi16","","Horizontally add the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_hadd_pi32","","Horizontally add the adjacent pairs of values contained in 2 packed 64-bit vectors of `[2 x i32]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_hadds_pi16","","Horizontally add the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`. Positive sums greater than 7FFFh are saturated to 7FFFh. Negative sums less than 8000h are saturated to 8000h.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_hsub_pi16","","Horizontally subtracts the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_hsub_pi32","","Horizontally subtracts the adjacent pairs of values contained in 2 packed 64-bit vectors of `[2 x i32]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_hsubs_pi16","","Horizontally subtracts the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`. Positive differences greater than 7FFFh are saturated to 7FFFh. Negative differences less than 8000h are saturated to 8000h.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_maddubs_pi16","","Multiplies corresponding pairs of packed 8-bit unsigned integer values contained in the first source operand and packed 8-bit signed integer values contained in the second source operand, adds pairs of contiguous products with signed saturation, and writes the 16-bit sums to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_mulhrs_pi16","","Multiplies packed 16-bit signed integer values, truncates the 32-bit products to the 18 most significant bits by right-shifting, rounds the truncated value by adding 1, and writes bits `[16:1]` to the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sign_pi8","","Negate packed 8-bit integers in `a` when the corresponding signed 8-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sign_pi16","","Negate packed 16-bit integers in `a` when the corresponding signed 16-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sign_pi32","","Negate packed 32-bit integers in `a` when the corresponding signed 32-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_blendv_epi8","","Blend packed 8-bit integers from `a` and `b` using `mask`",N,[[["__m128i"],["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_blend_epi16","","Blend packed 16-bit integers from `a` and `b` using the mask `imm8`.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_blendv_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using `mask`",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_blendv_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using `mask`",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_blend_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using control mask `imm2`",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_blend_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using mask `imm4`",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_extract_ps","","Extract a single-precision (32-bit) floating-point element from `a`, selected with `imm8`",N,[[["__m128"],["i32"]],["i32"]]],[5,"_mm_extract_epi8","","Extract an 8-bit integer from `a`, selected with `imm8`. Returns a 32-bit integer containing the zero-extended integer data.",N,[[["__m128i"],["i32"]],["i32"]]],[5,"_mm_extract_epi32","","Extract an 32-bit integer from `a` selected with `imm8`",N,[[["__m128i"],["i32"]],["i32"]]],[5,"_mm_insert_ps","","Select a single value in `a` to store at some position in `b`, Then zero elements according to `imm8`.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_insert_epi8","","Return a copy of `a` with the 8-bit integer from `i` inserted at a location specified by `imm8`.",N,[[["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_insert_epi32","","Return a copy of `a` with the 32-bit integer from `i` inserted at a location specified by `imm8`.",N,[[["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_max_epi8","","Compare packed 8-bit integers in `a` and `b` and return packed maximum values in dst.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_max_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return packed maximum.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_max_epi32","","Compare packed 32-bit integers in `a` and `b`, and return packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_max_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_min_epi8","","Compare packed 8-bit integers in `a` and `b` and return packed minimum values in dst.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_min_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return packed minimum.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_min_epi32","","Compare packed 32-bit integers in `a` and `b`, and return packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_min_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_packus_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using unsigned saturation",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpeq_epi64","","Compare packed 64-bit integers in `a` and `b` for equality",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi8_epi16","","Sign extend packed 8-bit integers in `a` to packed 16-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi8_epi32","","Sign extend packed 8-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi8_epi64","","Sign extend packed 8-bit integers in the low 8 bytes of `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi16_epi32","","Sign extend packed 16-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi16_epi64","","Sign extend packed 16-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi32_epi64","","Sign extend packed 32-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepu8_epi16","","Zero extend packed unsigned 8-bit integers in `a` to packed 16-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepu8_epi32","","Zero extend packed unsigned 8-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepu8_epi64","","Zero extend packed unsigned 8-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepu16_epi32","","Zero extend packed unsigned 16-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepu16_epi64","","Zero extend packed unsigned 16-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepu32_epi64","","Zero extend packed unsigned 32-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_dp_pd","","Returns the dot product of two __m128d vectors.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_dp_ps","","Returns the dot product of two __m128 vectors.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_floor_pd","","Round the packed double-precision (64-bit) floating-point elements in `a` down to an integer value, and store the results as packed double-precision floating-point elements.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm_floor_ps","","Round the packed single-precision (32-bit) floating-point elements in `a` down to an integer value, and store the results as packed single-precision floating-point elements.",N,[[["__m128"]],["__m128"]]],[5,"_mm_floor_sd","","Round the lower double-precision (64-bit) floating-point element in `b` down to an integer value, store the result as a double-precision floating-point element in the lower element of the intrinsic result, and copy the upper element from `a` to the upper element of the intrinsic result.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_floor_ss","","Round the lower single-precision (32-bit) floating-point element in `b` down to an integer value, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copy the upper 3 packed elements from `a` to the upper elements of the intrinsic result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_ceil_pd","","Round the packed double-precision (64-bit) floating-point elements in `a` up to an integer value, and store the results as packed double-precision floating-point elements.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm_ceil_ps","","Round the packed single-precision (32-bit) floating-point elements in `a` up to an integer value, and store the results as packed single-precision floating-point elements.",N,[[["__m128"]],["__m128"]]],[5,"_mm_ceil_sd","","Round the lower double-precision (64-bit) floating-point element in `b` up to an integer value, store the result as a double-precision floating-point element in the lower element of the intrisic result, and copy the upper element from `a` to the upper element of the intrinsic result.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_ceil_ss","","Round the lower single-precision (32-bit) floating-point element in `b` up to an integer value, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copy the upper 3 packed elements from `a` to the upper elements of the intrinsic result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_round_pd","","Round the packed double-precision (64-bit) floating-point elements in `a` using the `rounding` parameter, and store the results as packed double-precision floating-point elements. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_round_ps","","Round the packed single-precision (32-bit) floating-point elements in `a` using the `rounding` parameter, and store the results as packed single-precision floating-point elements. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm_round_sd","","Round the lower double-precision (64-bit) floating-point element in `b` using the `rounding` parameter, store the result as a double-precision floating-point element in the lower element of the intrinsic result, and copy the upper element from `a` to the upper element of the intrinsic result. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_round_ss","","Round the lower single-precision (32-bit) floating-point element in `b` using the `rounding` parameter, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copy the upper 3 packed elements from `a` to the upper elements of the instrinsic result. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_minpos_epu16","","Finds the minimum unsigned 16-bit element in the 128-bit __m128i vector, returning a vector containing its value in its first position, and its index in its second position; all other elements are set to zero.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_mul_epi32","","Multiply the low 32-bit integers from each packed 64-bit element in `a` and `b`, and return the signed 64-bit result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mullo_epi32","","Multiply the packed 32-bit integers in `a` and `b`, producing intermediate 64-bit integers, and returns the lowest 32-bit, whatever they might be, reinterpreted as a signed integer. While `pmulld __m128i::splat(2), __m128i::splat(2)` returns the obvious `__m128i::splat(4)`, due to wrapping arithmetic `pmulld __m128i::splat(i32::MAX), __m128i::splat(2)` would return a negative number.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mpsadbw_epu8","","Subtracts 8-bit unsigned integer values and computes the absolute values of the differences to the corresponding bits in the destination. Then sums of the absolute differences are returned according to the bit fields in the immediate operand.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_testz_si128","","Tests whether the specified bits in a 128-bit integer vector are all zeros.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm_testc_si128","","Tests whether the specified bits in a 128-bit integer vector are all ones.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm_testnzc_si128","","Tests whether the specified bits in a 128-bit integer vector are neither all zeros nor all ones.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm_test_all_zeros","","Tests whether the specified bits in a 128-bit integer vector are all zeros.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm_test_all_ones","","Tests whether the specified bits in `a` 128-bit integer vector are all ones.",N,[[["__m128i"]],["i32"]]],[5,"_mm_test_mix_ones_zeros","","Tests whether the specified bits in a 128-bit integer vector are neither all zeros nor all ones.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm_cmpistrm","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return the generated mask.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_cmpistri","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8` and return the generated index. Similar to [`_mm_cmpestri`] with the exception that [`_mm_cmpestri`] requires the lengths of `a` and `b` to be explicitly specified.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmpistrz","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return `1` if any character in `b` was null. and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmpistrc","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return `1` if the resulting mask was non-zero, and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmpistrs","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and returns `1` if any character in `a` was null, and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmpistro","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return bit `0` of the resulting bit mask.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmpistra","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return `1` if `b` did not contain a null character and the resulting mask was zero, and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmpestrm","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return the generated mask.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_cmpestri","","Compare packed strings `a` and `b` with lengths `la` and `lb` using the control in `imm8` and return the generated index. Similar to [`_mm_cmpistri`] with the exception that [`_mm_cmpistri`] implicitly determines the length of `a` and `b`.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_cmpestrz","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if any character in `b` was null, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_cmpestrc","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if the resulting mask was non-zero, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_cmpestrs","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if any character in a was null, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_cmpestro","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return bit `0` of the resulting bit mask.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_cmpestra","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if `b` did not contain a null character and the resulting mask was zero, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_crc32_u8","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 8-bit integer `v`.",N,[[["u32"],["u8"]],["u32"]]],[5,"_mm_crc32_u16","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 16-bit integer `v`.",N,[[["u32"],["u16"]],["u32"]]],[5,"_mm_crc32_u32","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 32-bit integer `v`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm_cmpgt_epi64","","Compare packed 64-bit integers in `a` and `b` for greater-than, return the results.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_add_pd","","Add packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_add_ps","","Add packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_and_pd","","Compute the bitwise AND of a packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_and_ps","","Compute the bitwise AND of packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_or_pd","","Compute the bitwise OR packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_or_ps","","Compute the bitwise OR packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_shuffle_pd","","Shuffle double-precision (64-bit) floating-point elements within 128-bit lanes using the control in `imm8`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_mm256_shuffle_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` within 128-bit lanes using the control in `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm256_andnot_pd","","Compute the bitwise NOT of packed double-precision (64-bit) floating-point elements in `a` and then AND with `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_andnot_ps","","Compute the bitwise NOT of packed single-precision (32-bit) floating-point elements in `a` and then AND with `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_max_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b`, and return packed maximum values",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_max_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return packed maximum values",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_min_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b`, and return packed minimum values",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_min_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return packed minimum values",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_mul_pd","","Add packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_mul_ps","","Add packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_addsub_pd","","Alternatively add and subtract packed double-precision (64-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_addsub_ps","","Alternatively add and subtract packed single-precision (32-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_sub_pd","","Subtract packed double-precision (64-bit) floating-point elements in `b` from packed elements in `a`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_sub_ps","","Subtract packed single-precision (32-bit) floating-point elements in `b` from packed elements in `a`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_div_ps","","Compute the division of each of the 8 packed 32-bit floating-point elements in `a` by the corresponding packed elements in `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_div_pd","","Compute the division of each of the 4 packed 64-bit floating-point elements in `a` by the corresponding packed elements in `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_round_pd","","Round packed double-precision (64-bit) floating point elements in `a` according to the flag `b`. The value of `b` may be as follows:",N,[[["__m256d"],["i32"]],["__m256d"]]],[5,"_mm256_ceil_pd","","Round packed double-precision (64-bit) floating point elements in `a` toward positive infinity.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm256_floor_pd","","Round packed double-precision (64-bit) floating point elements in `a` toward negative infinity.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm256_round_ps","","Round packed single-precision (32-bit) floating point elements in `a` according to the flag `b`. The value of `b` may be as follows:",N,[[["__m256"],["i32"]],["__m256"]]],[5,"_mm256_ceil_ps","","Round packed single-precision (32-bit) floating point elements in `a` toward positive infinity.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_floor_ps","","Round packed single-precision (32-bit) floating point elements in `a` toward negative infinity.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_sqrt_ps","","Return the square root of packed single-precision (32-bit) floating point elements in `a`.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_sqrt_pd","","Return the square root of packed double-precision (64-bit) floating point elements in `a`.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm256_blend_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using control mask `imm8`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_mm256_blend_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using control mask `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm256_blendv_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using `c` as a mask.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_blendv_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using `c` as a mask.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_dp_ps","","Conditionally multiply the packed single-precision (32-bit) floating-point elements in `a` and `b` using the high 4 bits in `imm8`, sum the four products, and conditionally return the sum  using the low 4 bits of `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm256_hadd_pd","","Horizontal addition of adjacent pairs in the two packed vectors of 4 64-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in even locations, while sums of elements from `b` are returned in odd locations.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_hadd_ps","","Horizontal addition of adjacent pairs in the two packed vectors of 8 32-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in locations of indices 0, 1, 4, 5; while sums of elements from `b` are locations 2, 3, 6, 7.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_hsub_pd","","Horizontal subtraction of adjacent pairs in the two packed vectors of 4 64-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in even locations, while sums of elements from `b` are returned in odd locations.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_hsub_ps","","Horizontal subtraction of adjacent pairs in the two packed vectors of 8 32-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in locations of indices 0, 1, 4, 5; while sums of elements from `b` are locations 2, 3, 6, 7.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_xor_pd","","Compute the bitwise XOR of packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_xor_ps","","Compute the bitwise XOR of packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_cmp_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm256_cmp_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_mm_cmp_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm256_cmp_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm_cmp_sd","","Compare the lower double-precision (64-bit) floating-point element in `a` and `b` based on the comparison operand specified by `imm8`, store the result in the lower element of returned vector, and copy the upper element from `a` to the upper element of returned vector.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_cmp_ss","","Compare the lower single-precision (32-bit) floating-point element in `a` and `b` based on the comparison operand specified by `imm8`, store the result in the lower element of returned vector, and copy the upper 3 packed elements from `a` to the upper elements of returned vector.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm256_cvtepi32_pd","","Convert packed 32-bit integers in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128i"]],["__m256d"]]],[5,"_mm256_cvtepi32_ps","","Convert packed 32-bit integers in `a` to packed single-precision (32-bit) floating-point elements.",N,[[["__m256i"]],["__m256"]]],[5,"_mm256_cvtpd_ps","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed single-precision (32-bit) floating-point elements.",N,[[["__m256d"]],["__m128"]]],[5,"_mm256_cvtps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m256"]],["__m256i"]]],[5,"_mm256_cvtps_pd","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128"]],["__m256d"]]],[5,"_mm256_cvttpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m256d"]],["__m128i"]]],[5,"_mm256_cvtpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m256d"]],["__m128i"]]],[5,"_mm256_cvttps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m256"]],["__m256i"]]],[5,"_mm256_extractf128_ps","","Extract 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from `a`, selected with `imm8`.",N,[[["__m256"],["i32"]],["__m128"]]],[5,"_mm256_extractf128_pd","","Extract 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `a`, selected with `imm8`.",N,[[["__m256d"],["i32"]],["__m128d"]]],[5,"_mm256_extractf128_si256","","Extract 128 bits (composed of integer data) from `a`, selected with `imm8`.",N,[[["__m256i"],["i32"]],["__m128i"]]],[5,"_mm256_zeroall","","Zero the contents of all XMM or YMM registers.",N,[[]]],[5,"_mm256_zeroupper","","Zero the upper 128 bits of all YMM registers; the lower 128-bits of the registers are unmodified.",N,[[]]],[5,"_mm256_permutevar_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` within 128-bit lanes using the control in `b`.",N,[[["__m256"],["__m256i"]],["__m256"]]],[5,"_mm_permutevar_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` using the control in `b`.",N,[[["__m128"],["__m128i"]],["__m128"]]],[5,"_mm256_permute_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` within 128-bit lanes using the control in `imm8`.",N,[[["__m256"],["i32"]],["__m256"]]],[5,"_mm_permute_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` using the control in `imm8`.",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm256_permutevar_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` within 256-bit lanes using the control in `b`.",N,[[["__m256d"],["__m256i"]],["__m256d"]]],[5,"_mm_permutevar_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` using the control in `b`.",N,[[["__m128d"],["__m128i"]],["__m128d"]]],[5,"_mm256_permute_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` within 128-bit lanes using the control in `imm8`.",N,[[["__m256d"],["i32"]],["__m256d"]]],[5,"_mm_permute_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` using the control in `imm8`.",N,[[["__m128d"],["i32"]],["__m128d"]]],[5,"_mm256_permute2f128_ps","","Shuffle 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) selected by `imm8` from `a` and `b`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm256_permute2f128_pd","","Shuffle 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) selected by `imm8` from `a` and `b`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_mm256_permute2f128_si256","","Shuffle 258-bits (composed of integer data) selected by `imm8` from `a` and `b`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_broadcast_ss","","Broadcast a single-precision (32-bit) floating-point element from memory to all elements of the returned vector.",N,[[["f32"]],["__m256"]]],[5,"_mm_broadcast_ss","","Broadcast a single-precision (32-bit) floating-point element from memory to all elements of the returned vector.",N,[[["f32"]],["__m128"]]],[5,"_mm256_broadcast_sd","","Broadcast a double-precision (64-bit) floating-point element from memory to all elements of the returned vector.",N,[[["f64"]],["__m256d"]]],[5,"_mm256_broadcast_ps","","Broadcast 128 bits from memory (composed of 4 packed single-precision (32-bit) floating-point elements) to all elements of the returned vector.",N,[[["__m128"]],["__m256"]]],[5,"_mm256_broadcast_pd","","Broadcast 128 bits from memory (composed of 2 packed double-precision (64-bit) floating-point elements) to all elements of the returned vector.",N,[[["__m128d"]],["__m256d"]]],[5,"_mm256_insertf128_ps","","Copy `a` to result, then insert 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from `b` into result at the location specified by `imm8`.",N,[[["__m256"],["__m128"],["i32"]],["__m256"]]],[5,"_mm256_insertf128_pd","","Copy `a` to result, then insert 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `b` into result at the location specified by `imm8`.",N,[[["__m256d"],["__m128d"],["i32"]],["__m256d"]]],[5,"_mm256_insertf128_si256","","Copy `a` to result, then insert 128 bits from `b` into result at the location specified by `imm8`.",N,[[["__m256i"],["__m128i"],["i32"]],["__m256i"]]],[5,"_mm256_insert_epi8","","Copy `a` to result, and insert the 8-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i8"],["i32"]],["__m256i"]]],[5,"_mm256_insert_epi16","","Copy `a` to result, and insert the 16-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i16"],["i32"]],["__m256i"]]],[5,"_mm256_insert_epi32","","Copy `a` to result, and insert the 32-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i32"],["i32"]],["__m256i"]]],[5,"_mm256_load_pd","","Load 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from memory into result. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_store_pd","","Store 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_load_ps","","Load 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from memory into result. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_store_ps","","Store 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from `a` into memory. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_loadu_pd","","Load 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from memory into result. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm256_storeu_pd","","Store 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm256_loadu_ps","","Load 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from memory into result. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm256_storeu_ps","","Store 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from `a` into memory. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm256_load_si256","","Load 256-bits of integer data from memory into result. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_store_si256","","Store 256-bits of integer data from `a` into memory. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_loadu_si256","","Load 256-bits of integer data from memory into result. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm256_storeu_si256","","Store 256-bits of integer data from `a` into memory.    `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm256_maskload_pd","","Load packed double-precision (64-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm256_maskstore_pd","","Store packed double-precision (64-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm_maskload_pd","","Load packed double-precision (64-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm_maskstore_pd","","Store packed double-precision (64-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm256_maskload_ps","","Load packed single-precision (32-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm256_maskstore_ps","","Store packed single-precision (32-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm_maskload_ps","","Load packed single-precision (32-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm_maskstore_ps","","Store packed single-precision (32-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm256_movehdup_ps","","Duplicate odd-indexed single-precision (32-bit) floating-point elements from `a`, and return the results.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_moveldup_ps","","Duplicate even-indexed single-precision (32-bit) floating-point elements from `a`, and return the results.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_movedup_pd","","Duplicate even-indexed double-precision (64-bit) floating-point elements from \"a\", and return the results.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm256_lddqu_si256","","Load 256-bits of integer data from unaligned memory into result. This intrinsic may perform better than `_mm256_loadu_si256` when the data crosses a cache line boundary.",N,N],[5,"_mm256_stream_si256","","Moves integer data from a 256-bit integer vector to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon)",N,N],[5,"_mm256_stream_pd","","Moves double-precision values from a 256-bit vector of `[4 x double]` to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm256_stream_ps","","Moves single-precision floating point values from a 256-bit vector of `[8 x float]` to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm256_rcp_ps","","Compute the approximate reciprocal of packed single-precision (32-bit) floating-point elements in `a`, and return the results. The maximum relative error for this approximation is less than 1.5*2^-12.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_rsqrt_ps","","Compute the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in `a`, and return the results. The maximum relative error for this approximation is less than 1.5*2^-12.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_unpackhi_pd","","Unpack and interleave double-precision (64-bit) floating-point elements from the high half of each 128-bit lane in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_unpackhi_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the high half of each 128-bit lane in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_unpacklo_pd","","Unpack and interleave double-precision (64-bit) floating-point elements from the low half of each 128-bit lane in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_unpacklo_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the low half of each 128-bit lane in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_testz_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`, and set `ZF` to 1 if the result is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, and set `CF` to 1 if the result is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m256i"],["__m256i"]],["i32"]]],[5,"_mm256_testc_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`, and set `ZF` to 1 if the result is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, and set `CF` to 1 if the result is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m256i"],["__m256i"]],["i32"]]],[5,"_mm256_testnzc_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`, and set `ZF` to 1 if the result is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, and set `CF` to 1 if the result is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m256i"],["__m256i"]],["i32"]]],[5,"_mm256_testz_pd","","Compute the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m256d"],["__m256d"]],["i32"]]],[5,"_mm256_testc_pd","","Compute the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m256d"],["__m256d"]],["i32"]]],[5,"_mm256_testnzc_pd","","Compute the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m256d"],["__m256d"]],["i32"]]],[5,"_mm_testz_pd","","Compute the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_testc_pd","","Compute the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_testnzc_pd","","Compute the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm256_testz_ps","","Compute the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m256"],["__m256"]],["i32"]]],[5,"_mm256_testc_ps","","Compute the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m256"],["__m256"]],["i32"]]],[5,"_mm256_testnzc_ps","","Compute the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m256"],["__m256"]],["i32"]]],[5,"_mm_testz_ps","","Compute the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_testc_ps","","Compute the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_testnzc_ps","","Compute the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm256_movemask_pd","","Set each bit of the returned mask based on the most significant bit of the corresponding packed double-precision (64-bit) floating-point element in `a`.",N,[[["__m256d"]],["i32"]]],[5,"_mm256_movemask_ps","","Set each bit of the returned mask based on the most significant bit of the corresponding packed single-precision (32-bit) floating-point element in `a`.",N,[[["__m256"]],["i32"]]],[5,"_mm256_setzero_pd","","Return vector of type __m256d with all elements set to zero.",N,[[],["__m256d"]]],[5,"_mm256_setzero_ps","","Return vector of type __m256 with all elements set to zero.",N,[[],["__m256"]]],[5,"_mm256_setzero_si256","","Return vector of type __m256i with all elements set to zero.",N,[[],["__m256i"]]],[5,"_mm256_set_pd","","Set packed double-precision (64-bit) floating-point elements in returned vector with the supplied values.",N,[[["f64"],["f64"],["f64"],["f64"]],["__m256d"]]],[5,"_mm256_set_ps","","Set packed single-precision (32-bit) floating-point elements in returned vector with the supplied values.",N,[[["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"]],["__m256"]]],[5,"_mm256_set_epi8","","Set packed 8-bit integers in returned vector with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m256i"]]],[5,"_mm256_set_epi16","","Set packed 16-bit integers in returned vector with the supplied values.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m256i"]]],[5,"_mm256_set_epi32","","Set packed 32-bit integers in returned vector with the supplied values.",N,[[["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"]],["__m256i"]]],[5,"_mm256_set_epi64x","","Set packed 64-bit integers in returned vector with the supplied values.",N,[[["i64"],["i64"],["i64"],["i64"]],["__m256i"]]],[5,"_mm256_setr_pd","","Set packed double-precision (64-bit) floating-point elements in returned vector with the supplied values in reverse order.",N,[[["f64"],["f64"],["f64"],["f64"]],["__m256d"]]],[5,"_mm256_setr_ps","","Set packed single-precision (32-bit) floating-point elements in returned vector with the supplied values in reverse order.",N,[[["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"]],["__m256"]]],[5,"_mm256_setr_epi8","","Set packed 8-bit integers in returned vector with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m256i"]]],[5,"_mm256_setr_epi16","","Set packed 16-bit integers in returned vector with the supplied values in reverse order.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m256i"]]],[5,"_mm256_setr_epi32","","Set packed 32-bit integers in returned vector with the supplied values in reverse order.",N,[[["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"]],["__m256i"]]],[5,"_mm256_setr_epi64x","","Set packed 64-bit integers in returned vector with the supplied values in reverse order.",N,[[["i64"],["i64"],["i64"],["i64"]],["__m256i"]]],[5,"_mm256_set1_pd","","Broadcast double-precision (64-bit) floating-point value `a` to all elements of returned vector.",N,[[["f64"]],["__m256d"]]],[5,"_mm256_set1_ps","","Broadcast single-precision (32-bit) floating-point value `a` to all elements of returned vector.",N,[[["f32"]],["__m256"]]],[5,"_mm256_set1_epi8","","Broadcast 8-bit integer `a` to all elements of returned vector. This intrinsic may generate the `vpbroadcastb`.",N,[[["i8"]],["__m256i"]]],[5,"_mm256_set1_epi16","","Broadcast 16-bit integer `a` to all all elements of returned vector. This intrinsic may generate the `vpbroadcastw`.",N,[[["i16"]],["__m256i"]]],[5,"_mm256_set1_epi32","","Broadcast 32-bit integer `a` to all elements of returned vector. This intrinsic may generate the `vpbroadcastd`.",N,[[["i32"]],["__m256i"]]],[5,"_mm256_set1_epi64x","","Broadcast 64-bit integer `a` to all elements of returned vector. This intrinsic may generate the `vpbroadcastq`.",N,[[["i64"]],["__m256i"]]],[5,"_mm256_castpd_ps","","Cast vector of type __m256d to type __m256.",N,[[["__m256d"]],["__m256"]]],[5,"_mm256_castps_pd","","Cast vector of type __m256 to type __m256d.",N,[[["__m256"]],["__m256d"]]],[5,"_mm256_castps_si256","","Casts vector of type __m256 to type __m256i.",N,[[["__m256"]],["__m256i"]]],[5,"_mm256_castsi256_ps","","Casts vector of type __m256i to type __m256.",N,[[["__m256i"]],["__m256"]]],[5,"_mm256_castpd_si256","","Casts vector of type __m256d to type __m256i.",N,[[["__m256d"]],["__m256i"]]],[5,"_mm256_castsi256_pd","","Casts vector of type __m256i to type __m256d.",N,[[["__m256i"]],["__m256d"]]],[5,"_mm256_castps256_ps128","","Casts vector of type __m256 to type __m128.",N,[[["__m256"]],["__m128"]]],[5,"_mm256_castpd256_pd128","","Casts vector of type __m256d to type __m128d.",N,[[["__m256d"]],["__m128d"]]],[5,"_mm256_castsi256_si128","","Casts vector of type __m256i to type __m128i.",N,[[["__m256i"]],["__m128i"]]],[5,"_mm256_castps128_ps256","","Casts vector of type __m128 to type __m256; the upper 128 bits of the result are undefined.",N,[[["__m128"]],["__m256"]]],[5,"_mm256_castpd128_pd256","","Casts vector of type __m128d to type __m256d; the upper 128 bits of the result are undefined.",N,[[["__m128d"]],["__m256d"]]],[5,"_mm256_castsi128_si256","","Casts vector of type __m128i to type __m256i; the upper 128 bits of the result are undefined.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_zextps128_ps256","","Constructs a 256-bit floating-point vector of `[8 x float]` from a 128-bit floating-point vector of `[4 x float]`. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.",N,[[["__m128"]],["__m256"]]],[5,"_mm256_zextsi128_si256","","Constructs a 256-bit integer vector from a 128-bit integer vector. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_zextpd128_pd256","","Constructs a 256-bit floating-point vector of `[4 x double]` from a 128-bit floating-point vector of `[2 x double]`. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.",N,[[["__m128d"]],["__m256d"]]],[5,"_mm256_undefined_ps","","Return vector of type `__m256` with undefined elements.",N,[[],["__m256"]]],[5,"_mm256_undefined_pd","","Return vector of type `__m256d` with undefined elements.",N,[[],["__m256d"]]],[5,"_mm256_undefined_si256","","Return vector of type __m256i with undefined elements.",N,[[],["__m256i"]]],[5,"_mm256_set_m128","","Set packed __m256 returned vector with the supplied values.",N,[[["__m128"],["__m128"]],["__m256"]]],[5,"_mm256_set_m128d","","Set packed __m256d returned vector with the supplied values.",N,[[["__m128d"],["__m128d"]],["__m256d"]]],[5,"_mm256_set_m128i","","Set packed __m256i returned vector with the supplied values.",N,[[["__m128i"],["__m128i"]],["__m256i"]]],[5,"_mm256_setr_m128","","Set packed __m256 returned vector with the supplied values.",N,[[["__m128"],["__m128"]],["__m256"]]],[5,"_mm256_setr_m128d","","Set packed __m256d returned vector with the supplied values.",N,[[["__m128d"],["__m128d"]],["__m256d"]]],[5,"_mm256_setr_m128i","","Set packed __m256i returned vector with the supplied values.",N,[[["__m128i"],["__m128i"]],["__m256i"]]],[5,"_mm256_loadu2_m128","","Load two 128-bit values (composed of 4 packed single-precision (32-bit) floating-point elements) from memory, and combine them into a 256-bit value. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm256_loadu2_m128d","","Load two 128-bit values (composed of 2 packed double-precision (64-bit) floating-point elements) from memory, and combine them into a 256-bit value. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm256_loadu2_m128i","","Load two 128-bit values (composed of integer data) from memory, and combine them into a 256-bit value. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm256_storeu2_m128","","Store the high and low 128-bit halves (each composed of 4 packed single-precision (32-bit) floating-point elements) from `a` into memory two different 128-bit locations. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm256_storeu2_m128d","","Store the high and low 128-bit halves (each composed of 2 packed double-precision (64-bit) floating-point elements) from `a` into memory two different 128-bit locations. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm256_storeu2_m128i","","Store the high and low 128-bit halves (each composed of integer data) from `a` into memory two different 128-bit locations. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm256_cvtss_f32","","Returns the first element of the input vector of `[8 x float]`.",N,[[["__m256"]],["f32"]]],[5,"_mm256_abs_epi32","","Computes the absolute values of packed 32-bit integers in `a`.",N,[[["__m256i"]],["__m256i"]]],[5,"_mm256_abs_epi16","","Computes the absolute values of packed 16-bit integers in `a`.",N,[[["__m256i"]],["__m256i"]]],[5,"_mm256_abs_epi8","","Computes the absolute values of packed 8-bit integers in `a`.",N,[[["__m256i"]],["__m256i"]]],[5,"_mm256_add_epi64","","Add packed 64-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_add_epi32","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_add_epi16","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_add_epi8","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_adds_epi8","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_adds_epi16","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_adds_epu8","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_adds_epu16","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_alignr_epi8","","Concatenate pairs of 16-byte blocks in `a` and `b` into a 32-byte temporary result, shift the result right by `n` bytes, and return the low 16 bytes.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_and_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_andnot_si256","","Compute the bitwise NOT of 256 bits (representing integer data) in `a` and then AND with `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_avg_epu16","","Average packed unsigned 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_avg_epu8","","Average packed unsigned 8-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_blend_epi32","","Blend packed 32-bit integers from `a` and `b` using control mask `imm8`.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm256_blend_epi32","","Blend packed 32-bit integers from `a` and `b` using control mask `imm8`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_blend_epi16","","Blend packed 16-bit integers from `a` and `b` using control mask `imm8`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_blendv_epi8","","Blend packed 8-bit integers from `a` and `b` using `mask`.",N,[[["__m256i"],["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_broadcastb_epi8","","Broadcast the low packed 8-bit integer from `a` to all elements of the 128-bit returned value.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_broadcastb_epi8","","Broadcast the low packed 8-bit integer from `a` to all elements of the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_broadcastd_epi32","","Broadcast the low packed 32-bit integer from `a` to all elements of the 128-bit returned value.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_broadcastd_epi32","","Broadcast the low packed 32-bit integer from `a` to all elements of the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_broadcastq_epi64","","Broadcast the low packed 64-bit integer from `a` to all elements of the 128-bit returned value.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_broadcastq_epi64","","Broadcast the low packed 64-bit integer from `a` to all elements of the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_broadcastsd_pd","","Broadcast the low double-precision (64-bit) floating-point element from `a` to all elements of the 128-bit returned value.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm256_broadcastsd_pd","","Broadcast the low double-precision (64-bit) floating-point element from `a` to all elements of the 256-bit returned value.",N,[[["__m128d"]],["__m256d"]]],[5,"_mm256_broadcastsi128_si256","","Broadcast 128 bits of integer data from a to all 128-bit lanes in the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_broadcastss_ps","","Broadcast the low single-precision (32-bit) floating-point element from `a` to all elements of the 128-bit returned value.",N,[[["__m128"]],["__m128"]]],[5,"_mm256_broadcastss_ps","","Broadcast the low single-precision (32-bit) floating-point element from `a` to all elements of the 256-bit returned value.",N,[[["__m128"]],["__m256"]]],[5,"_mm_broadcastw_epi16","","Broadcast the low packed 16-bit integer from a to all elements of the 128-bit returned value",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_broadcastw_epi16","","Broadcast the low packed 16-bit integer from a to all elements of the 256-bit returned value",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cmpeq_epi64","","Compare packed 64-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpeq_epi32","","Compare packed 32-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpeq_epi16","","Compare packed 16-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpeq_epi8","","Compare packed 8-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpgt_epi64","","Compare packed 64-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpgt_epi32","","Compare packed 32-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpgt_epi16","","Compare packed 16-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpgt_epi8","","Compare packed 8-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cvtepi16_epi32","","Sign-extend 16-bit integers to 32-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepi16_epi64","","Sign-extend 16-bit integers to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepi32_epi64","","Sign-extend 32-bit integers to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepi8_epi16","","Sign-extend 8-bit integers to 16-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepi8_epi32","","Sign-extend 8-bit integers to 32-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepi8_epi64","","Sign-extend 8-bit integers to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepu16_epi32","","Zero extend packed unsigned 16-bit integers in `a` to packed 32-bit integers, and store the results in dst.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepu16_epi64","","Zero-extend the lower four unsigned 16-bit integers in `a` to 64-bit integers. The upper four elements of `a` are unused.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepu32_epi64","","Zero-extend unsigned 32-bit integers in `a` to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepu8_epi16","","Zero-extend unsigned 8-bit integers in `a` to 16-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepu8_epi32","","Zero-extend the lower eight unsigned 8-bit integers in `a` to 32-bit integers. The upper eight elements of `a` are unused.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepu8_epi64","","Zero-extend the lower four unsigned 8-bit integers in `a` to 64-bit integers. The upper twelve elements of `a` are unused.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_extracti128_si256","","Extract 128 bits (of integer data) from `a` selected with `imm8`.",N,[[["__m256i"],["i32"]],["__m128i"]]],[5,"_mm256_hadd_epi16","","Horizontally add adjacent pairs of 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_hadd_epi32","","Horizontally add adjacent pairs of 32-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_hadds_epi16","","Horizontally add adjacent pairs of 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_hsub_epi16","","Horizontally subtract adjacent pairs of 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_hsub_epi32","","Horizontally subtract adjacent pairs of 32-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_hsubs_epi16","","Horizontally subtract adjacent pairs of 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_inserti128_si256","","Copy `a` to `dst`, then insert 128 bits (of integer data) from `b` at the location specified by `imm8`.",N,[[["__m256i"],["__m128i"],["i32"]],["__m256i"]]],[5,"_mm256_madd_epi16","","Multiply packed signed 16-bit integers in `a` and `b`, producing intermediate signed 32-bit integers. Horizontally add adjacent pairs of intermediate 32-bit integers.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_maddubs_epi16","","Vertically multiply each unsigned 8-bit integer from `a` with the corresponding signed 8-bit integer from `b`, producing intermediate signed 16-bit integers. Horizontally add adjacent pairs of intermediate signed 16-bit integers",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_maskload_epi32","","Load packed 32-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_maskload_epi32","","Load packed 32-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_maskload_epi64","","Load packed 64-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_maskload_epi64","","Load packed 64-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_maskstore_epi32","","Store packed 32-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_maskstore_epi32","","Store packed 32-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_maskstore_epi64","","Store packed 64-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_maskstore_epi64","","Store packed 64-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_max_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_max_epi32","","Compare packed 32-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_max_epi8","","Compare packed 8-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_max_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_max_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_max_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_min_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_min_epi32","","Compare packed 32-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_min_epi8","","Compare packed 8-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_min_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_min_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_min_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_movemask_epi8","","Create mask from the most significant bit of each 8-bit element in `a`, return the result.",N,[[["__m256i"]],["i32"]]],[5,"_mm256_mpsadbw_epu8","","Compute the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in `a` compared to those in `b`, and store the 16-bit results in dst. Eight SADs are performed for each 128-bit lane using one quadruplet from `b` and eight quadruplets from `a`. One quadruplet is selected from `b` starting at on the offset specified in `imm8`. Eight quadruplets are formed from sequential 8-bit integers selected from `a` starting at the offset specified in `imm8`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_mul_epi32","","Multiply the low 32-bit integers from each packed 64-bit element in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mul_epu32","","Multiply the low unsigned 32-bit integers from each packed 64-bit element in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mulhi_epi16","","Multiply the packed 16-bit integers in `a` and `b`, producing intermediate 32-bit integers and returning the high 16 bits of the intermediate integers.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mulhi_epu16","","Multiply the packed unsigned 16-bit integers in `a` and `b`, producing intermediate 32-bit integers and returning the high 16 bits of the intermediate integers.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mullo_epi16","","Multiply the packed 16-bit integers in `a` and `b`, producing intermediate 32-bit integers, and return the low 16 bits of the intermediate integers",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mullo_epi32","","Multiply the packed 32-bit integers in `a` and `b`, producing intermediate 64-bit integers, and return the low 16 bits of the intermediate integers",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mulhrs_epi16","","Multiply packed 16-bit integers in `a` and `b`, producing intermediate signed 32-bit integers. Truncate each intermediate integer to the 18 most significant bits, round by adding 1, and return bits `[16:1]`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_or_si256","","Compute the bitwise OR of 256 bits (representing integer data) in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_packs_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using signed saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_packs_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using signed saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_packus_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using unsigned saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_packus_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using unsigned saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_permutevar8x32_epi32","","Permutes packed 32-bit integers from `a` according to the content of `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_permute4x64_epi64","","Permutes 64-bit integers from `a` using control mask `imm8`.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_permute2x128_si256","","Shuffle 128-bits of integer data selected by `imm8` from `a` and `b`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_permute4x64_pd","","Shuffle 64-bit floating-point elements in `a` across lanes using the control in `imm8`.",N,[[["__m256d"],["i32"]],["__m256d"]]],[5,"_mm256_permutevar8x32_ps","","Shuffle eight 32-bit foating-point elements in `a` across lanes using the corresponding 32-bit integer index in `idx`.",N,[[["__m256"],["__m256i"]],["__m256"]]],[5,"_mm256_sad_epu8","","Compute the absolute differences of packed unsigned 8-bit integers in `a` and `b`, then horizontally sum each consecutive 8 differences to produce four unsigned 16-bit integers, and pack these unsigned 16-bit integers in the low 16 bits of the 64-bit return value",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_shuffle_epi8","","Shuffle bytes from `a` according to the content of `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_shuffle_epi32","","Shuffle 32-bit integers in 128-bit lanes of `a` using the control in `imm8`.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_shufflehi_epi16","","Shuffle 16-bit integers in the high 64 bits of 128-bit lanes of `a` using the control in `imm8`. The low 64 bits of 128-bit lanes of `a` are copied to the output.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_shufflelo_epi16","","Shuffle 16-bit integers in the low 64 bits of 128-bit lanes of `a` using the control in `imm8`. The high 64 bits of 128-bit lanes of `a` are copied to the output.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_sign_epi16","","Negate packed 16-bit integers in `a` when the corresponding signed 16-bit integer in `b` is negative, and return the results. Results are zeroed out when the corresponding element in `b` is zero.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sign_epi32","","Negate packed 32-bit integers in `a` when the corresponding signed 32-bit integer in `b` is negative, and return the results. Results are zeroed out when the corresponding element in `b` is zero.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sign_epi8","","Negate packed 8-bit integers in `a` when the corresponding signed 8-bit integer in `b` is negative, and return the results. Results are zeroed out when the corresponding element in `b` is zero.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sll_epi16","","Shift packed 16-bit integers in `a` left by `count` while shifting in zeros, and return the result",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_sll_epi32","","Shift packed 32-bit integers in `a` left by `count` while shifting in zeros, and return the result",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_sll_epi64","","Shift packed 64-bit integers in `a` left by `count` while shifting in zeros, and return the result",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_slli_epi16","","Shift packed 16-bit integers in `a` left by `imm8` while shifting in zeros, return the results;",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_slli_epi32","","Shift packed 32-bit integers in `a` left by `imm8` while shifting in zeros, return the results;",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_slli_epi64","","Shift packed 64-bit integers in `a` left by `imm8` while shifting in zeros, return the results;",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_slli_si256","","Shift 128-bit lanes in `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_bslli_epi128","","Shift 128-bit lanes in `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_sllv_epi32","","Shift packed 32-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_sllv_epi32","","Shift packed 32-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_sllv_epi64","","Shift packed 64-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_sllv_epi64","","Shift packed 64-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sra_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_sra_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_srai_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_srai_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_srav_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in sign bits.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_srav_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in sign bits.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_srli_si256","","Shift 128-bit lanes in `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_bsrli_epi128","","Shift 128-bit lanes in `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_srl_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_srl_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_srl_epi64","","Shift packed 64-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_srli_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in zeros",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_srli_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in zeros",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_srli_epi64","","Shift packed 64-bit integers in `a` right by `imm8` while shifting in zeros",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_srlv_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_srlv_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_srlv_epi64","","Shift packed 64-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_srlv_epi64","","Shift packed 64-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sub_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sub_epi32","","Subtract packed 32-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sub_epi64","","Subtract packed 64-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sub_epi8","","Subtract packed 8-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_subs_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_subs_epi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_subs_epu16","","Subtract packed unsigned 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_subs_epu8","","Subtract packed unsigned 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpackhi_epi8","","Unpack and interleave 8-bit integers from the high half of each 128-bit lane in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpacklo_epi8","","Unpack and interleave 8-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpackhi_epi16","","Unpack and interleave 16-bit integers from the high half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpacklo_epi16","","Unpack and interleave 16-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpackhi_epi32","","Unpack and interleave 32-bit integers from the high half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpacklo_epi32","","Unpack and interleave 32-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpackhi_epi64","","Unpack and interleave 64-bit integers from the high half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpacklo_epi64","","Unpack and interleave 64-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_xor_si256","","Compute the bitwise XOR of 256 bits (representing integer data) in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_extract_epi8","","Extract an 8-bit integer from `a`, selected with `imm8`. Returns a 32-bit integer containing the zero-extended integer data.",N,[[["__m256i"],["i32"]],["i8"]]],[5,"_mm256_extract_epi16","","Extract a 16-bit integer from `a`, selected with `imm8`. Returns a 32-bit integer containing the zero-extended integer data.",N,[[["__m256i"],["i32"]],["i16"]]],[5,"_mm256_extract_epi32","","Extract a 32-bit integer from `a`, selected with `imm8`.",N,[[["__m256i"],["i32"]],["i32"]]],[5,"_mm256_cvtsd_f64","","Returns the first element of the input vector of `[4 x double]`.",N,[[["__m256d"]],["f64"]]],[5,"_mm256_cvtsi256_si32","","Returns the first element of the input vector of `[8 x i32]`.",N,[[["__m256i"]],["i32"]]],[5,"_mm_fmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_fmadd_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and add the intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_fmadd_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`, and add the intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_fmaddsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fmaddsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fmaddsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fmaddsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_fmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_fmsub_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and subtract the lower element in `c` from the intermediate result. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_fmsub_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`,  and subtract the lower element in `c` from the intermediate result. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_fmsubadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fmsubadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fmsubadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fmsubadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_fnmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fnmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fnmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fnmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_fnmadd_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_fnmadd_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_fnmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fnmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fnmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fnmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_fnmsub_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_fnmsub_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_lzcnt_u32","","Counts the leading most significant zero bits.",N,[[["u32"]],["u32"]]],[5,"_popcnt32","","Counts the bits that are set.",N,[[["i32"]],["i32"]]],[5,"_bextr_u32","","Extracts bits in range [`start`, `start` + `length`) from `a` into the least significant bits of the result.",N,[[["u32"],["u32"],["u32"]],["u32"]]],[5,"_bextr2_u32","","Extracts bits of `a` specified by `control` into the least significant bits of the result.",N,[[["u32"],["u32"]],["u32"]]],[5,"_andn_u32","","Bitwise logical `AND` of inverted `a` with `b`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_blsi_u32","","Extract lowest set isolated bit.",N,[[["u32"]],["u32"]]],[5,"_blsmsk_u32","","Get mask up to lowest set bit.",N,[[["u32"]],["u32"]]],[5,"_blsr_u32","","Resets the lowest set bit of `x`.",N,[[["u32"]],["u32"]]],[5,"_tzcnt_u32","","Counts the number of trailing least significant zero bits.",N,[[["u32"]],["u32"]]],[5,"_mm_tzcnt_32","","Counts the number of trailing least significant zero bits.",N,[[["u32"]],["i32"]]],[5,"_mulx_u32","","Unsigned multiply without affecting flags.",N,[[["u32"],["u32"],["u32"]],["u32"]]],[5,"_bzhi_u32","","Zero higher bits of `a` >= `index`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_pdep_u32","","Scatter contiguous low order bits of `a` to the result at the positions specified by the `mask`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_pext_u32","","Gathers the bits of `x` specified by the `mask` into the contiguous low order bit positions of the result.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm_extract_si64","","Extracts the bit range specified by `y` from the lower 64 bits of `x`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_insert_si64","","Inserts the `[length:0]` bits of `y` into `x` at `index`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_stream_sd","","Non-temporal store of `a.0` into `p`.",N,N],[5,"_mm_stream_ss","","Non-temporal store of `a.0` into `p`.",N,N],[5,"_blcfill_u32","","Clears all bits below the least significant zero bit of `x`.",N,[[["u32"]],["u32"]]],[5,"_blcfill_u64","","Clears all bits below the least significant zero bit of `x`.",N,[[["u64"]],["u64"]]],[5,"_blci_u32","","Sets all bits of `x` to 1 except for the least significant zero bit.",N,[[["u32"]],["u32"]]],[5,"_blci_u64","","Sets all bits of `x` to 1 except for the least significant zero bit.",N,[[["u64"]],["u64"]]],[5,"_blcic_u32","","Sets the least significant zero bit of `x` and clears all other bits.",N,[[["u32"]],["u32"]]],[5,"_blcic_u64","","Sets the least significant zero bit of `x` and clears all other bits.",N,[[["u64"]],["u64"]]],[5,"_blcmsk_u32","","Sets the least significant zero bit of `x` and clears all bits above that bit.",N,[[["u32"]],["u32"]]],[5,"_blcmsk_u64","","Sets the least significant zero bit of `x` and clears all bits above that bit.",N,[[["u64"]],["u64"]]],[5,"_blcs_u32","","Sets the least significant zero bit of `x`.",N,[[["u32"]],["u32"]]],[5,"_blcs_u64","","Sets the least significant zero bit of `x`.",N,[[["u64"]],["u64"]]],[5,"_blsfill_u32","","Sets all bits of `x` below the least significant one.",N,[[["u32"]],["u32"]]],[5,"_blsfill_u64","","Sets all bits of `x` below the least significant one.",N,[[["u64"]],["u64"]]],[5,"_blsic_u32","","Clears least significant bit and sets all other bits.",N,[[["u32"]],["u32"]]],[5,"_blsic_u64","","Clears least significant bit and sets all other bits.",N,[[["u64"]],["u64"]]],[5,"_t1mskc_u32","","Clears all bits below the least significant zero of `x` and sets all other bits.",N,[[["u32"]],["u32"]]],[5,"_t1mskc_u64","","Clears all bits below the least significant zero of `x` and sets all other bits.",N,[[["u64"]],["u64"]]],[5,"_tzmsk_u32","","Sets all bits below the least significant one of `x` and clears all other bits.",N,[[["u32"]],["u32"]]],[5,"_tzmsk_u64","","Sets all bits below the least significant one of `x` and clears all other bits.",N,[[["u64"]],["u64"]]],[5,"_mm_setzero_si64","","Constructs a 64-bit integer vector initialized to zero.",N,[[],["__m64"]]],[5,"_mm_add_pi8","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddb","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_add_pi16","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddw","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_add_pi32","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddd","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_adds_pi8","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddsb","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_adds_pi16","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddsw","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_adds_pu8","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddusb","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_adds_pu16","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddusw","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sub_pi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubb","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sub_pi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubw","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sub_pi32","","Subtract packed 32-bit integers in `b` from packed 32-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubd","","Subtract packed 32-bit integers in `b` from packed 32-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_subs_pi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubsb","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_subs_pi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubsw","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_subs_pu8","","Subtract packed unsigned 8-bit integers in `b` from packed unsigned 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubusb","","Subtract packed unsigned 8-bit integers in `b` from packed unsigned 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_subs_pu16","","Subtract packed unsigned 16-bit integers in `b` from packed unsigned 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubusw","","Subtract packed unsigned 16-bit integers in `b` from packed unsigned 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_packs_pi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using signed saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_packs_pi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using signed saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmpgt_pi8","","Compares whether each element of `a` is greater than the corresponding element of `b` returning `0` for `false` and `-1` for `true`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmpgt_pi16","","Compares whether each element of `a` is greater than the corresponding element of `b` returning `0` for `false` and `-1` for `true`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmpgt_pi32","","Compares whether each element of `a` is greater than the corresponding element of `b` returning `0` for `false` and `-1` for `true`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_unpackhi_pi16","","Unpacks the upper two elements from two `i16x4` vectors and interleaves them into the result: `[a.2, b.2, a.3, b.3]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_unpackhi_pi8","","Unpacks the upper four elements from two `i8x8` vectors and interleaves them into the result: `[a.4, b.4, a.5, b.5, a.6, b.6, a.7, b.7]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_unpacklo_pi8","","Unpacks the lower four elements from two `i8x8` vectors and interleaves them into the result: `[a.0, b.0, a.1, b.1, a.2, b.2, a.3, b.3]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_unpacklo_pi16","","Unpacks the lower two elements from two `i16x4` vectors and interleaves them into the result: `[a.0 b.0 a.1 b.1]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_unpackhi_pi32","","Unpacks the upper element from two `i32x2` vectors and interleaves them into the result: `[a.1, b.1]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_unpacklo_pi32","","Unpacks the lower element from two `i32x2` vectors and interleaves them into the result: `[a.0, b.0]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_set_pi16","","Set packed 16-bit integers in dst with the supplied values.",N,[[["i16"],["i16"],["i16"],["i16"]],["__m64"]]],[5,"_mm_set_pi32","","Set packed 32-bit integers in dst with the supplied values.",N,[[["i32"],["i32"]],["__m64"]]],[5,"_mm_set_pi8","","Set packed 8-bit integers in dst with the supplied values.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m64"]]],[5,"_mm_set1_pi16","","Broadcast 16-bit integer a to all all elements of dst.",N,[[["i16"]],["__m64"]]],[5,"_mm_set1_pi32","","Broadcast 32-bit integer a to all all elements of dst.",N,[[["i32"]],["__m64"]]],[5,"_mm_set1_pi8","","Broadcast 8-bit integer a to all all elements of dst.",N,[[["i8"]],["__m64"]]],[5,"_mm_setr_pi16","","Set packed 16-bit integers in dst with the supplied values in reverse order.",N,[[["i16"],["i16"],["i16"],["i16"]],["__m64"]]],[5,"_mm_setr_pi32","","Set packed 32-bit integers in dst with the supplied values in reverse order.",N,[[["i32"],["i32"]],["__m64"]]],[5,"_mm_setr_pi8","","Set packed 8-bit integers in dst with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m64"]]],[5,"_mm_clmulepi64_si128","","Perform a carry-less multiplication of two 64-bit polynomials over the finite field GF(2^k).",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_aesdec_si128","","Perform one round of an AES decryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_aesdeclast_si128","","Perform the last round of an AES decryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_aesenc_si128","","Perform one round of an AES encryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_aesenclast_si128","","Perform the last round of an AES encryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_aesimc_si128","","Perform the `InvMixColumns` transformation on `a`.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_aeskeygenassist_si128","","Assist in expanding the AES cipher key.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_rdrand16_step","","Read a hardware generated 16-bit random value and store the result in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u16"]],["i32"]]],[5,"_rdrand32_step","","Read a hardware generated 32-bit random value and store the result in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u32"]],["i32"]]],[5,"_rdseed16_step","","Read a 16-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u16"]],["i32"]]],[5,"_rdseed32_step","","Read a 32-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u32"]],["i32"]]],[5,"_mm_sha1msg1_epu32","","Perform an intermediate calculation for the next four SHA1 message values (unsigned 32-bit integers) using previous message values from `a` and `b`, and returning the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sha1msg2_epu32","","Perform the final calculation for the next four SHA1 message values (unsigned 32-bit integers) using the intermediate result in `a` and the previous message values in `b`, and returns the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sha1nexte_epu32","","Calculate SHA1 state variable E after four rounds of operation from the current SHA1 state variable `a`, add that value to the scheduled values (unsigned 32-bit integers) in `b`, and returns the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sha1rnds4_epu32","","Perform four rounds of SHA1 operation using an initial SHA1 state (A,B,C,D) from `a` and some pre-computed sum of the next 4 round message values (unsigned 32-bit integers), and state variable E from `b`, and return the updated SHA1 state (A,B,C,D). `func` contains the logic functions and round constants.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_sha256msg1_epu32","","Perform an intermediate calculation for the next four SHA256 message values (unsigned 32-bit integers) using previous message values from `a` and `b`, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sha256msg2_epu32","","Perform the final calculation for the next four SHA256 message values (unsigned 32-bit integers) using previous message values from `a` and `b`, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sha256rnds2_epu32","","Perform 2 rounds of SHA256 operation using an initial SHA256 state (C,D,G,H) from `a`, an initial SHA256 state (A,B,E,F) from `b`, and a pre-computed sum of the next 2 round message values (unsigned 32-bit integers) and the corresponding round constants from `k`, and store the updated SHA256 state (A,B,E,F) in dst.",N,[[["__m128i"],["__m128i"],["__m128i"]],["__m128i"]]],[5,"_fxsave64","","Saves the `x87` FPU, `MMX` technology, `XMM`, and `MXCSR` registers to the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_fxrstor64","","Restores the `XMM`, `MMX`, `MXCSR`, and `x87` FPU registers from the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_mm_cvtss_si64","","Convert the lowest 32 bit float in the input vector to a 64 bit integer.",N,[[["__m128"]],["i64"]]],[5,"_mm_cvttss_si64","","Convert the lowest 32 bit float in the input vector to a 64 bit integer with truncation.",N,[[["__m128"]],["i64"]]],[5,"_mm_cvtsi64_ss","","Convert a 64 bit integer to a 32 bit float. The result vector is the input vector `a` with the lowest 32 bit float replaced by the converted integer.",N,[[["__m128"],["i64"]],["__m128"]]],[5,"_mm_cvtsd_si64","","Convert the lower double-precision (64-bit) floating-point element in a to a 64-bit integer.",N,[[["__m128d"]],["i64"]]],[5,"_mm_cvtsd_si64x","","Alias for `_mm_cvtsd_si64`",N,[[["__m128d"]],["i64"]]],[5,"_mm_cvttsd_si64","","Convert the lower double-precision (64-bit) floating-point element in `a` to a 64-bit integer with truncation.",N,[[["__m128d"]],["i64"]]],[5,"_mm_cvttsd_si64x","","Alias for `_mm_cvttsd_si64`",N,[[["__m128d"]],["i64"]]],[5,"_mm_stream_si64","","Stores a 64-bit integer value in the specified memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_cvtsi64_si128","","Return a vector whose lowest element is `a` and all higher elements are `0`.",N,[[["i64"]],["__m128i"]]],[5,"_mm_cvtsi64x_si128","","Return a vector whose lowest element is `a` and all higher elements are `0`.",N,[[["i64"]],["__m128i"]]],[5,"_mm_cvtsi128_si64","","Return the lowest element of `a`.",N,[[["__m128i"]],["i64"]]],[5,"_mm_cvtsi128_si64x","","Return the lowest element of `a`.",N,[[["__m128i"]],["i64"]]],[5,"_mm_cvtsi64_sd","","Return `a` with its lower element replaced by `b` after converting it to an `f64`.",N,[[["__m128d"],["i64"]],["__m128d"]]],[5,"_mm_cvtsi64x_sd","","Return `a` with its lower element replaced by `b` after converting it to an `f64`.",N,[[["__m128d"],["i64"]],["__m128d"]]],[5,"_mm_extract_epi64","","Extract an 64-bit integer from `a` selected with `imm8`",N,[[["__m128i"],["i32"]],["i64"]]],[5,"_mm_insert_epi64","","Return a copy of `a` with the 64-bit integer from `i` inserted at a location specified by `imm8`.",N,[[["__m128i"],["i64"],["i32"]],["__m128i"]]],[5,"_mm_crc32_u64","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 64-bit integer `v`.",N,[[["u64"],["u64"]],["u64"]]],[5,"_xsave64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_xrstor64","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_xsaveopt64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_xsavec64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_xsaves64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`",N,N],[5,"_xrstors64","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_lzcnt_u64","","Counts the leading most significant zero bits.",N,[[["u64"]],["u64"]]],[5,"_popcnt64","","Counts the bits that are set.",N,[[["i64"]],["i32"]]],[5,"_mm256_insert_epi64","","Copy `a` to result, and insert the 64-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i64"],["i32"]],["__m256i"]]],[5,"_bextr_u64","","Extracts bits in range [`start`, `start` + `length`) from `a` into the least significant bits of the result.",N,[[["u64"],["u32"],["u32"]],["u64"]]],[5,"_bextr2_u64","","Extracts bits of `a` specified by `control` into the least significant bits of the result.",N,[[["u64"],["u64"]],["u64"]]],[5,"_andn_u64","","Bitwise logical `AND` of inverted `a` with `b`.",N,[[["u64"],["u64"]],["u64"]]],[5,"_blsi_u64","","Extract lowest set isolated bit.",N,[[["u64"]],["u64"]]],[5,"_blsmsk_u64","","Get mask up to lowest set bit.",N,[[["u64"]],["u64"]]],[5,"_blsr_u64","","Resets the lowest set bit of `x`.",N,[[["u64"]],["u64"]]],[5,"_tzcnt_u64","","Counts the number of trailing least significant zero bits.",N,[[["u64"]],["u64"]]],[5,"_mm_tzcnt_64","","Counts the number of trailing least significant zero bits.",N,[[["u64"]],["i64"]]],[5,"_mulx_u64","","Unsigned multiply without affecting flags.",N,[[["u64"],["u64"],["u64"]],["u64"]]],[5,"_bzhi_u64","","Zero higher bits of `a` >= `index`.",N,[[["u64"],["u32"]],["u64"]]],[5,"_pdep_u64","","Scatter contiguous low order bits of `a` to the result at the positions specified by the `mask`.",N,[[["u64"],["u64"]],["u64"]]],[5,"_pext_u64","","Gathers the bits of `x` specified by the `mask` into the contiguous low order bit positions of the result.",N,[[["u64"],["u64"]],["u64"]]],[5,"_mm256_extract_epi64","","Extract a 64-bit integer from `a`, selected with `imm8`.",N,[[["__m256i"],["i32"]],["i64"]]],[5,"_bswap64","","Return an integer with the reversed byte order of x",N,[[["i64"]],["i64"]]],[5,"_rdrand64_step","","Read a hardware generated 64-bit random value and store the result in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u64"]],["i32"]]],[5,"_rdseed64_step","","Read a 64-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u64"]],["i32"]]],[17,"_XCR_XFEATURE_ENABLED_MASK","","`XFEATURE_ENABLED_MASK` for `XCR`",N,N],[17,"_MM_EXCEPT_INVALID","","See `_mm_setcsr`",N,N],[17,"_MM_EXCEPT_DENORM","","See `_mm_setcsr`",N,N],[17,"_MM_EXCEPT_DIV_ZERO","","See `_mm_setcsr`",N,N],[17,"_MM_EXCEPT_OVERFLOW","","See `_mm_setcsr`",N,N],[17,"_MM_EXCEPT_UNDERFLOW","","See `_mm_setcsr`",N,N],[17,"_MM_EXCEPT_INEXACT","","See `_mm_setcsr`",N,N],[17,"_MM_EXCEPT_MASK","","See `_MM_GET_EXCEPTION_STATE`",N,N],[17,"_MM_MASK_INVALID","","See `_mm_setcsr`",N,N],[17,"_MM_MASK_DENORM","","See `_mm_setcsr`",N,N],[17,"_MM_MASK_DIV_ZERO","","See `_mm_setcsr`",N,N],[17,"_MM_MASK_OVERFLOW","","See `_mm_setcsr`",N,N],[17,"_MM_MASK_UNDERFLOW","","See `_mm_setcsr`",N,N],[17,"_MM_MASK_INEXACT","","See `_mm_setcsr`",N,N],[17,"_MM_MASK_MASK","","See `_MM_GET_EXCEPTION_MASK`",N,N],[17,"_MM_ROUND_NEAREST","","See `_mm_setcsr`",N,N],[17,"_MM_ROUND_DOWN","","See `_mm_setcsr`",N,N],[17,"_MM_ROUND_UP","","See `_mm_setcsr`",N,N],[17,"_MM_ROUND_TOWARD_ZERO","","See `_mm_setcsr`",N,N],[17,"_MM_ROUND_MASK","","See `_MM_GET_ROUNDING_MODE`",N,N],[17,"_MM_FLUSH_ZERO_MASK","","See `_MM_GET_FLUSH_ZERO_MODE`",N,N],[17,"_MM_FLUSH_ZERO_ON","","See `_mm_setcsr`",N,N],[17,"_MM_FLUSH_ZERO_OFF","","See `_mm_setcsr`",N,N],[17,"_MM_HINT_T0","","See `_mm_prefetch`.",N,N],[17,"_MM_HINT_T1","","See `_mm_prefetch`.",N,N],[17,"_MM_HINT_T2","","See `_mm_prefetch`.",N,N],[17,"_MM_HINT_NTA","","See `_mm_prefetch`.",N,N],[17,"_MM_FROUND_TO_NEAREST_INT","","round to nearest",N,N],[17,"_MM_FROUND_TO_NEG_INF","","round down",N,N],[17,"_MM_FROUND_TO_POS_INF","","round up",N,N],[17,"_MM_FROUND_TO_ZERO","","truncate",N,N],[17,"_MM_FROUND_CUR_DIRECTION","","use MXCSR.RC; see `vendor::_MM_SET_ROUNDING_MODE`",N,N],[17,"_MM_FROUND_RAISE_EXC","","do not suppress exceptions",N,N],[17,"_MM_FROUND_NO_EXC","","suppress exceptions",N,N],[17,"_MM_FROUND_NINT","","round to nearest and do not suppress exceptions",N,N],[17,"_MM_FROUND_FLOOR","","round down and do not suppress exceptions",N,N],[17,"_MM_FROUND_CEIL","","round up and do not suppress exceptions",N,N],[17,"_MM_FROUND_TRUNC","","truncate and do not suppress exceptions",N,N],[17,"_MM_FROUND_RINT","","use MXCSR.RC and do not suppress exceptions; see `vendor::_MM_SET_ROUNDING_MODE`",N,N],[17,"_MM_FROUND_NEARBYINT","","use MXCSR.RC and suppress exceptions; see `vendor::_MM_SET_ROUNDING_MODE`",N,N],[17,"_SIDD_UBYTE_OPS","","String contains unsigned 8-bit characters (Default)",N,N],[17,"_SIDD_UWORD_OPS","","String contains unsigned 16-bit characters",N,N],[17,"_SIDD_SBYTE_OPS","","String contains signed 8-bit characters",N,N],[17,"_SIDD_SWORD_OPS","","String contains unsigned 16-bit characters",N,N],[17,"_SIDD_CMP_EQUAL_ANY","","For each character in `a`, find if it is in `b` (Default)",N,N],[17,"_SIDD_CMP_RANGES","","For each character in `a`, determine if `b[0] <= c <= b[1] or b[1] <= c <= b[2]...`",N,N],[17,"_SIDD_CMP_EQUAL_EACH","","The strings defined by `a` and `b` are equal",N,N],[17,"_SIDD_CMP_EQUAL_ORDERED","","Search for the defined substring in the target",N,N],[17,"_SIDD_POSITIVE_POLARITY","","Do not negate results (Default)",N,N],[17,"_SIDD_NEGATIVE_POLARITY","","Negate results",N,N],[17,"_SIDD_MASKED_POSITIVE_POLARITY","","Do not negate results before the end of the string",N,N],[17,"_SIDD_MASKED_NEGATIVE_POLARITY","","Negate results only before the end of the string",N,N],[17,"_SIDD_LEAST_SIGNIFICANT","","Index only: return the least significant bit (Default)",N,N],[17,"_SIDD_MOST_SIGNIFICANT","","Index only: return the most significant bit",N,N],[17,"_SIDD_BIT_MASK","","Mask only: return the bit mask",N,N],[17,"_SIDD_UNIT_MASK","","Mask only: return the byte mask",N,N],[17,"_CMP_EQ_OQ","","Equal (ordered, non-signaling)",N,N],[17,"_CMP_LT_OS","","Less-than (ordered, signaling)",N,N],[17,"_CMP_LE_OS","","Less-than-or-equal (ordered, signaling)",N,N],[17,"_CMP_UNORD_Q","","Unordered (non-signaling)",N,N],[17,"_CMP_NEQ_UQ","","Not-equal (unordered, non-signaling)",N,N],[17,"_CMP_NLT_US","","Not-less-than (unordered, signaling)",N,N],[17,"_CMP_NLE_US","","Not-less-than-or-equal (unordered, signaling)",N,N],[17,"_CMP_ORD_Q","","Ordered (non-signaling)",N,N],[17,"_CMP_EQ_UQ","","Equal (unordered, non-signaling)",N,N],[17,"_CMP_NGE_US","","Not-greater-than-or-equal (unordered, signaling)",N,N],[17,"_CMP_NGT_US","","Not-greater-than (unordered, signaling)",N,N],[17,"_CMP_FALSE_OQ","","False (ordered, non-signaling)",N,N],[17,"_CMP_NEQ_OQ","","Not-equal (ordered, non-signaling)",N,N],[17,"_CMP_GE_OS","","Greater-than-or-equal (ordered, signaling)",N,N],[17,"_CMP_GT_OS","","Greater-than (ordered, signaling)",N,N],[17,"_CMP_TRUE_UQ","","True (unordered, non-signaling)",N,N],[17,"_CMP_EQ_OS","","Equal (ordered, signaling)",N,N],[17,"_CMP_LT_OQ","","Less-than (ordered, non-signaling)",N,N],[17,"_CMP_LE_OQ","","Less-than-or-equal (ordered, non-signaling)",N,N],[17,"_CMP_UNORD_S","","Unordered (signaling)",N,N],[17,"_CMP_NEQ_US","","Not-equal (unordered, signaling)",N,N],[17,"_CMP_NLT_UQ","","Not-less-than (unordered, non-signaling)",N,N],[17,"_CMP_NLE_UQ","","Not-less-than-or-equal (unordered, non-signaling)",N,N],[17,"_CMP_ORD_S","","Ordered (signaling)",N,N],[17,"_CMP_EQ_US","","Equal (unordered, signaling)",N,N],[17,"_CMP_NGE_UQ","","Not-greater-than-or-equal (unordered, non-signaling)",N,N],[17,"_CMP_NGT_UQ","","Not-greater-than (unordered, non-signaling)",N,N],[17,"_CMP_FALSE_OS","","False (ordered, signaling)",N,N],[17,"_CMP_NEQ_OS","","Not-equal (ordered, signaling)",N,N],[17,"_CMP_GE_OQ","","Greater-than-or-equal (ordered, non-signaling)",N,N],[17,"_CMP_GT_OQ","","Greater-than (ordered, non-signaling)",N,N],[17,"_CMP_TRUE_US","","True (unordered, signaling)",N,N],[11,"clone","","",0,[[["self"]],["cpuidresult"]]],[11,"cmp","","",0,[[["self"],["cpuidresult"]],["ordering"]]],[11,"eq","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"ne","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"partial_cmp","","",0,[[["self"],["cpuidresult"]],["option",["ordering"]]]],[11,"lt","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"le","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"gt","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"ge","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"clone","","",1,[[["self"]],["__m64"]]],[11,"fmt","","",1,[[["self"],["formatter"]],["result"]]],[11,"clone","","",2,[[["self"]],["__m128i"]]],[11,"fmt","","",2,[[["self"],["formatter"]],["result"]]],[11,"clone","","",3,[[["self"]],["__m128"]]],[11,"fmt","","",3,[[["self"],["formatter"]],["result"]]],[11,"clone","","",4,[[["self"]],["__m128d"]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result"]]],[11,"clone","","",5,[[["self"]],["__m256i"]]],[11,"fmt","","",5,[[["self"],["formatter"]],["result"]]],[11,"clone","","",6,[[["self"]],["__m256"]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result"]]],[11,"clone","","",7,[[["self"]],["__m256d"]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result"]]]],"paths":[[3,"CpuidResult"],[3,"__m64"],[3,"__m128i"],[3,"__m128"],[3,"__m128d"],[3,"__m256i"],[3,"__m256"],[3,"__m256d"]]};
searchIndex["stdsimd"]={"doc":"SIMD and vendor intrinsics support library.","items":[[0,"arch","stdsimd","SIMD and vendor intrinsics module.",N,N],[0,"x86_64","stdsimd::arch","Platform-specific intrinsics for the `x86_64` platform.",N,N],[5,"_pext_u64","stdsimd::arch::x86_64","Gathers the bits of `x` specified by the `mask` into the contiguous low order bit positions of the result.",N,[[["u64"],["u64"]],["u64"]]],[5,"_mm_bslli_si128","","Shift `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_setr_epi8","","Set packed 8-bit integers with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m128i"]]],[5,"_mm_permute_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` using the control in `imm8`.",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_blcs_u32","","Sets the least significant zero bit of `x`.",N,[[["u32"]],["u32"]]],[5,"_mm_cvtepi8_epi64","","Sign extend packed 8-bit integers in the low 8 bytes of `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_testc_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`, and set `ZF` to 1 if the result is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, and set `CF` to 1 if the result is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m256i"],["__m256i"]],["i32"]]],[5,"_mm256_set1_epi64x","","Broadcast 64-bit integer `a` to all elements of returned vector. This intrinsic may generate the `vpbroadcastq`.",N,[[["i64"]],["__m256i"]]],[5,"_mm_avg_pu16","","Computes the rounded averages of the packed unsigned 16-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_cvttps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m256"]],["__m256i"]]],[5,"_mm_cmpord_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. Returns four floats that have one of two possible bit patterns. The element in the output vector will be `0xffffffff` if the input elements in `a` and `b` are ordered (i.e., neither of them is a NaN), or 0 otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_cvtepi8_epi16","","Sign-extend 8-bit integers to 16-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_shufflelo_epi16","","Shuffle 16-bit integers in the low 64 bits of 128-bit lanes of `a` using the control in `imm8`. The high 64 bits of 128-bit lanes of `a` are copied to the output.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_adds_epi16","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmplt_pd","","Compare corresponding elements in `a` and `b` for less-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_maskstore_epi64","","Store packed 64-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_abs_pi32","","Compute the absolute value of packed 32-bit integers in `a`, and return the unsigned results.",N,[[["__m64"]],["__m64"]]],[5,"_mm_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_hadd_epi16","","Horizontally add the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpeq_epi8","","Compare packed 8-bit integers in `a` and `b` for equality.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_slli_epi32","","Shift packed 32-bit integers in `a` left by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_ucomilt_sd","","Compare the lower element of `a` and `b` for less-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_cvtepi16_epi64","","Sign extend packed 16-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_castpd_si128","","Casts a 128-bit floating-point vector of `[2 x double]` into a 128-bit integer vector.",N,[[["__m128d"]],["__m128i"]]],[5,"_mm256_min_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b`, and return packed minimum values",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_store1_pd","","Store the lower double-precision (64-bit) floating-point element from `a` into 2 contiguous elements in memory. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_loadu_pd","","Load 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from memory into result. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_srli_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_cmpgt_pi32","","Compares whether each element of `a` is greater than the corresponding element of `b` returning `0` for `false` and `-1` for `true`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_broadcastsd_pd","","Broadcast the low double-precision (64-bit) floating-point element from `a` to all elements of the 128-bit returned value.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm256_sra_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm_mfence","","Perform a serializing operation on all load-from-memory and store-to-memory instructions that were issued prior to this instruction.",N,N],[5,"_mm256_shuffle_pd","","Shuffle double-precision (64-bit) floating-point elements within 128-bit lanes using the control in `imm8`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_mm256_mask_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[17,"_SIDD_BIT_MASK","","Mask only: return the bit mask",N,N],[5,"_mm_shuffle_pi16","","Shuffles the 4 16-bit integers from a 64-bit integer vector to the destination, as specified by the immediate value operand.",N,[[["__m64"],["i32"]],["__m64"]]],[5,"_mm_cvt_si2ss","","Alias for `_mm_cvtsi32_ss`.",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm_cvtepi8_epi32","","Sign extend packed 8-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_bsrli_epi128","","Shift 128-bit lanes in `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[17,"_CMP_ORD_S","","Ordered (signaling)",N,N],[5,"_mm_adds_pu8","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sub_epi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[17,"_SIDD_UBYTE_OPS","","String contains unsigned 8-bit characters (Default)",N,N],[5,"_mm_cmpgt_pi8","","Compares whether each element of `a` is greater than the corresponding element of `b` returning `0` for `false` and `-1` for `true`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_sub_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_comile_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than or equal to the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm256_alignr_epi8","","Concatenate pairs of 16-byte blocks in `a` and `b` into a 32-byte temporary result, shift the result right by `n` bytes, and return the low 16 bytes.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_fxrstor64","","Restores the `XMM`, `MMX`, `MXCSR`, and `x87` FPU registers from the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_mm_andnot_ps","","Bitwise AND-NOT of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_srli_si256","","Shift 128-bit lanes in `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_storer_pd","","Store 2 double-precision (64-bit) floating-point elements from `a` into memory in reverse order. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_abs_epi32","","Computes the absolute values of packed 32-bit integers in `a`.",N,[[["__m256i"]],["__m256i"]]],[17,"_CMP_TRUE_UQ","","True (unordered, non-signaling)",N,N],[5,"_mm_div_ps","","Divides __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_setr_epi64","","Constructs a 128-bit integer vector, initialized in reverse order with the specified 64-bit integral values.",N,[[["__m64"],["__m64"]],["__m128i"]]],[5,"_m_pmulhuw","","Multiplies packed 16-bit unsigned integer values and writes the high-order 16 bits of each 32-bit product to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_set1_epi32","","Broadcast 32-bit integer `a` to all elements.",N,[[["i32"]],["__m128i"]]],[5,"_mm_fnmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_load_sd","","Loads a 64-bit double-precision value to the low element of a 128-bit integer vector and clears the upper element.",N,N],[5,"_mm256_castpd_ps","","Cast vector of type __m256d to type __m256.",N,[[["__m256d"]],["__m256"]]],[5,"_mm_sub_epi32","","Subtract packed 32-bit integers in `b` from packed 32-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mulx_u64","","Unsigned multiply without affecting flags.",N,[[["u64"],["u64"],["u64"]],["u64"]]],[5,"_mm_max_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpnle_ss","","Compare the lowest `f32` of both inputs for not-less-than-or-equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not less than or equal to `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_cvtepu16_epi32","","Zero extend packed unsigned 16-bit integers in `a` to packed 32-bit integers, and store the results in dst.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_setr_epi32","","Set packed 32-bit integers in returned vector with the supplied values in reverse order.",N,[[["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"]],["__m256i"]]],[5,"_mm_sha1rnds4_epu32","","Perform four rounds of SHA1 operation using an initial SHA1 state (A,B,C,D) from `a` and some pre-computed sum of the next 4 round message values (unsigned 32-bit integers), and state variable E from `b`, and return the updated SHA1 state (A,B,C,D). `func` contains the logic functions and round constants.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_floor_ps","","Round the packed single-precision (32-bit) floating-point elements in `a` down to an integer value, and store the results as packed single-precision floating-point elements.",N,[[["__m128"]],["__m128"]]],[5,"_blcs_u64","","Sets the least significant zero bit of `x`.",N,[[["u64"]],["u64"]]],[5,"_xsaveopt64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_mm_maskstore_epi32","","Store packed 32-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_maskstore_pd","","Store packed double-precision (64-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm256_movemask_ps","","Set each bit of the returned mask based on the most significant bit of the corresponding packed single-precision (32-bit) floating-point element in `a`.",N,[[["__m256"]],["i32"]]],[5,"_mm_move_sd","","Constructs a 128-bit floating-point vector of `[2 x double]`. The lower 64 bits are set to the lower 64 bits of the second parameter. The upper 64 bits are set to the upper 64 bits of the first parameter.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_slli_epi64","","Shift packed 64-bit integers in `a` left by `imm8` while shifting in zeros, return the results;",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_hsub_epi32","","Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of `[4 x i32]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_mask_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_testc_pd","","Compute the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_aesimc_si128","","Perform the `InvMixColumns` transformation on `a`.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_unpacklo_pd","","The resulting `__m128d` element is composed by the high-order values of the two `__m128d` interleaved input elements, i.e.:",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_shufflelo_epi16","","Shuffle 16-bit integers in the low 64 bits of `a` using the control in `imm8`.",N,[[["__m128i"],["i32"]],["__m128i"]]],[17,"_SIDD_MASKED_NEGATIVE_POLARITY","","Negate results only before the end of the string",N,N],[5,"_mm256_cvtss_f32","","Returns the first element of the input vector of `[8 x float]`.",N,[[["__m256"]],["f32"]]],[5,"_mm_xor_pd","","Compute the bitwise OR of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_MM_GET_EXCEPTION_MASK","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_mm_insert_pi16","","Copies data from the 64-bit vector of `[4 x i16]` to the destination, and inserts the lower 16-bits of an integer operand at the 16-bit offset specified by the immediate operand `n`.",N,[[["__m64"],["i32"],["i32"]],["__m64"]]],[5,"_mm_testc_ps","","Compute the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_set1_epi8","","Broadcast 8-bit integer `a` to all elements.",N,[[["i8"]],["__m128i"]]],[17,"_MM_EXCEPT_UNDERFLOW","","See `_mm_setcsr`",N,N],[5,"_mm256_permute2f128_ps","","Shuffle 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) selected by `imm8` from `a` and `b`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_popcnt64","","Counts the bits that are set.",N,[[["i64"]],["i32"]]],[5,"_mm_cmpistra","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return `1` if `b` did not contain a null character and the resulting mask was zero, and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm256_blend_epi16","","Blend packed 16-bit integers from `a` and `b` using control mask `imm8`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_zextps128_ps256","","Constructs a 256-bit floating-point vector of `[8 x float]` from a 128-bit floating-point vector of `[4 x float]`. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.",N,[[["__m128"]],["__m256"]]],[5,"_mm_set_pd1","","Broadcast double-precision (64-bit) floating-point value a to all elements of the return value.",N,[[["f64"]],["__m128d"]]],[5,"_mm_fmaddsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_rsqrt_ss","","Return the approximate reciprocal square root of the fist single-precision (32-bit) floating-point elements in `a`, the other elements are unchanged.",N,[[["__m128"]],["__m128"]]],[5,"_mm256_set1_epi32","","Broadcast 32-bit integer `a` to all elements of returned vector. This intrinsic may generate the `vpbroadcastd`.",N,[[["i32"]],["__m256i"]]],[5,"_mm_cmpestrc","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if the resulting mask was non-zero, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm256_fnmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[17,"_CMP_LE_OS","","Less-than-or-equal (ordered, signaling)",N,N],[5,"_bzhi_u64","","Zero higher bits of `a` >= `index`.",N,[[["u64"],["u32"]],["u64"]]],[5,"_mm_sign_pi8","","Negate packed 8-bit integers in `a` when the corresponding signed 8-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_unpackhi_pd","","The resulting `__m128d` element is composed by the low-order values of the two `__m128d` interleaved input elements, i.e.:",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_permutevar_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` using the control in `b`.",N,[[["__m128"],["__m128i"]],["__m128"]]],[3,"__m128","","128-bit wide set of four `f32` types, x86-specific",N,N],[5,"_mm256_cvttpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m256d"]],["__m128i"]]],[5,"_mm_insert_si64","","Inserts the `[length:0]` bits of `y` into `x` at `index`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[17,"_MM_FROUND_CEIL","","round up and do not suppress exceptions",N,N],[5,"_mm256_inserti128_si256","","Copy `a` to `dst`, then insert 128 bits (of integer data) from `b` at the location specified by `imm8`.",N,[[["__m256i"],["__m128i"],["i32"]],["__m256i"]]],[17,"_CMP_TRUE_US","","True (unordered, signaling)",N,N],[5,"_mm_blend_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using control mask `imm2`",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_testnzc_pd","","Compute the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_xrstor","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_mm256_storeu2_m128d","","Store the high and low 128-bit halves (each composed of 2 packed double-precision (64-bit) floating-point elements) from `a` into memory two different 128-bit locations. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm_cvtsi64x_si128","","Return a vector whose lowest element is `a` and all higher elements are `0`.",N,[[["i64"]],["__m128i"]]],[5,"_mm_cmp_ss","","Compare the lower single-precision (32-bit) floating-point element in `a` and `b` based on the comparison operand specified by `imm8`, store the result in the lower element of returned vector, and copy the upper 3 packed elements from `a` to the upper elements of returned vector.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_tzcnt_32","","Counts the number of trailing least significant zero bits.",N,[[["u32"]],["i32"]]],[17,"_MM_FROUND_TO_NEAREST_INT","","round to nearest",N,N],[5,"_mm256_set_epi32","","Set packed 32-bit integers in returned vector with the supplied values.",N,[[["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"]],["__m256i"]]],[5,"_mm_cmple_pd","","Compare corresponding elements in `a` and `b` for less-than-or-equal",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_div_pd","","Compute the division of each of the 4 packed 64-bit floating-point elements in `a` by the corresponding packed elements in `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_broadcastq_epi64","","Broadcast the low packed 64-bit integer from `a` to all elements of the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_m_pshufw","","Shuffles the 4 16-bit integers from a 64-bit integer vector to the destination, as specified by the immediate value operand.",N,[[["__m64"],["i32"]],["__m64"]]],[5,"_mm_rcp_ps","","Return the approximate reciprocal of packed single-precision (32-bit) floating-point elements in `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm256_load_ps","","Load 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from memory into result. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_subs_pu16","","Subtract packed unsigned 16-bit integers in `b` from packed unsigned 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[17,"_MM_ROUND_MASK","","See `_MM_GET_ROUNDING_MODE`",N,N],[5,"_mm_cvt_pi2ps","","Converts two elements of a 64-bit vector of `[2 x i32]` into two floating point values and writes them to the lower 64-bits of the destination. The remaining higher order elements of the destination are copied from the corresponding elements in the first operand.",N,[[["__m128"],["__m64"]],["__m128"]]],[5,"_mm_max_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_sllv_epi64","","Shift packed 64-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_srl_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmp_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm256_or_ps","","Compute the bitwise OR packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_fmsubadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_hsub_ps","","Horizontally add adjacent pairs of single-precision (32-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cvtsi64x_sd","","Return `a` with its lower element replaced by `b` after converting it to an `f64`.",N,[[["__m128d"],["i64"]],["__m128d"]]],[5,"_mm256_rsqrt_ps","","Compute the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in `a`, and return the results. The maximum relative error for this approximation is less than 1.5*2^-12.",N,[[["__m256"]],["__m256"]]],[5,"_mm_mul_sd","","Return a new vector with the low element of `a` replaced by multiplying the low elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_MM_SET_EXCEPTION_MASK","","See `_mm_setcsr`",N,N],[17,"_CMP_NLT_UQ","","Not-less-than (unordered, non-signaling)",N,N],[5,"_mm_set_sd","","Copy double-precision (64-bit) floating-point element `a` to the lower element of the packed 64-bit return value.",N,[[["f64"]],["__m128d"]]],[5,"_mm256_hsub_epi32","","Horizontally subtract adjacent pairs of 32-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_maskmoveu_si128","","Conditionally store 8-bit integer elements from `a` into memory using `mask`.",N,N],[5,"_mm256_insertf128_si256","","Copy `a` to result, then insert 128 bits from `b` into result at the location specified by `imm8`.",N,[[["__m256i"],["__m128i"],["i32"]],["__m256i"]]],[5,"_mm_add_pi32","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_fmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_sub_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_popcnt32","","Counts the bits that are set.",N,[[["i32"]],["i32"]]],[5,"_mm_and_ps","","Bitwise AND of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_crc32_u16","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 16-bit integer `v`.",N,[[["u32"],["u16"]],["u32"]]],[5,"_mm_maddubs_epi16","","Multiply corresponding pairs of packed 8-bit unsigned integer values contained in the first source operand and packed 8-bit signed integer values contained in the second source operand, add pairs of contiguous products with signed saturation, and writes the 16-bit sums to the corresponding bits in the destination.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_cvtepu8_epi32","","Zero-extend the lower eight unsigned 8-bit integers in `a` to 32-bit integers. The upper eight elements of `a` are unused.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_setr_epi16","","Set packed 16-bit integers in returned vector with the supplied values in reverse order.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m256i"]]],[5,"_mm_unpacklo_epi32","","Unpack and interleave 32-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpunord_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. Returns four floats that have one of two possible bit patterns. The element in the output vector will be `0xffffffff` if the input elements in `a` and `b` are unordered (i.e., at least on of them is a NaN), or 0 otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_set_epi64","","Initializes both 64-bit values in a 128-bit vector of `[2 x i64]` with the specified 64-bit integer values.",N,[[["__m64"],["__m64"]],["__m128i"]]],[5,"_mm256_max_epi32","","Compare packed 32-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_sub_pd","","Subtract packed double-precision (64-bit) floating-point elements in `b` from `a`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_xor_pd","","Compute the bitwise XOR of packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_stream_ss","","Non-temporal store of `a.0` into `p`.",N,N],[5,"_mm_cmpnlt_ss","","Compare the lowest `f32` of both inputs for not-less-than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not less than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_addsub_pd","","Alternatively add and subtract packed double-precision (64-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_cvtepi8_epi64","","Sign-extend 8-bit integers to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_sqrt_ps","","Return the square root of packed single-precision (32-bit) floating point elements in `a`.",N,[[["__m256"]],["__m256"]]],[5,"_mm_storeu_pd","","Store 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_cvttsd_si64x","","Alias for `_mm_cvttsd_si64`",N,[[["__m128d"]],["i64"]]],[5,"_mm256_maskload_epi64","","Load packed 64-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_mask_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_cmpeq_epi8","","Compare packed 8-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cmpestrz","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if any character in `b` was null, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm256_srlv_epi64","","Shift packed 64-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cmpngt_pd","","Compare corresponding elements in `a` and `b` for not-greater-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpgt_sd","","Return a new vector with the low element of `a` replaced by the greater-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_aesenc_si128","","Perform one round of an AES encryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_avg_epu16","","Average packed unsigned 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_load_ss","","Construct a `__m128` with the lowest element read from `p` and the other elements set to zero.",N,N],[5,"_mm256_shufflehi_epi16","","Shuffle 16-bit integers in the high 64 bits of 128-bit lanes of `a` using the control in `imm8`. The low 64 bits of 128-bit lanes of `a` are copied to the output.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_max_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return the corresponding maximum values.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpeq_pd","","Compare corresponding elements in `a` and `b` for equality.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_store_pd1","","Store the lower double-precision (64-bit) floating-point element from `a` into 2 contiguous elements in memory. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_testnzc_si128","","Tests whether the specified bits in a 128-bit integer vector are neither all zeros nor all ones.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm256_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_sll_epi16","","Shift packed 16-bit integers in `a` left by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_permutevar8x32_epi32","","Permutes packed 32-bit integers from `a` according to the content of `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cvtsi32_ss","","Convert a 32 bit integer to a 32 bit float. The result vector is the input vector `a` with the lowest 32 bit float replaced by the converted integer.",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm_storeh_pi","","Store the upper half of `a` (64 bits) into memory.",N,N],[5,"_mm256_fmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_m_psubusw","","Subtract packed unsigned 16-bit integers in `b` from packed unsigned 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_set1_pi32","","Broadcast 32-bit integer a to all all elements of dst.",N,[[["i32"]],["__m64"]]],[5,"_mm256_movedup_pd","","Duplicate even-indexed double-precision (64-bit) floating-point elements from \"a\", and return the results.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm_load_ps1","","Alias for `_mm_load1_ps`",N,N],[5,"_mm_cvtpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128d"]],["__m128i"]]],[17,"_MM_MASK_UNDERFLOW","","See `_mm_setcsr`",N,N],[5,"_mm_unpackhi_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the higher half of `a` and `b`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_set_pd","","Set packed double-precision (64-bit) floating-point elements in the return value with the supplied values.",N,[[["f64"],["f64"]],["__m128d"]]],[5,"_mm_fmadd_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`, and add the intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cvtsi128_si32","","Return the lowest element of `a`.",N,[[["__m128i"]],["i32"]]],[5,"_blcmsk_u32","","Sets the least significant zero bit of `x` and clears all bits above that bit.",N,[[["u32"]],["u32"]]],[5,"_mm_mask_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_add_sd","","Return a new vector with the low element of `a` replaced by the sum of the low elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[17,"_MM_FROUND_NEARBYINT","","use MXCSR.RC and suppress exceptions; see `vendor::_MM_SET_ROUNDING_MODE`",N,N],[5,"_mm_ucomile_sd","","Compare the lower element of `a` and `b` for less-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm256_xor_ps","","Compute the bitwise XOR of packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_sha1msg2_epu32","","Perform the final calculation for the next four SHA1 message values (unsigned 32-bit integers) using the intermediate result in `a` and the previous message values in `b`, and returns the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_MM_TRANSPOSE4_PS","","Transpose the 4x4 matrix formed by 4 rows of __m128 in place.",N,N],[5,"_mm256_blendv_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using `c` as a mask.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_storeu2_m128","","Store the high and low 128-bit halves (each composed of 4 packed single-precision (32-bit) floating-point elements) from `a` into memory two different 128-bit locations. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm_stream_si64","","Stores a 64-bit integer value in the specified memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_rdseed32_step","","Read a 32-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u32"]],["i32"]]],[5,"_mm256_div_ps","","Compute the division of each of the 8 packed 32-bit floating-point elements in `a` by the corresponding packed elements in `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_cvtepu8_epi32","","Zero extend packed unsigned 8-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_packs_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using signed saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[17,"_SIDD_UWORD_OPS","","String contains unsigned 16-bit characters",N,N],[5,"_mm_cvtpu8_ps","","Converts the lower 4 8-bit values of `a` into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm_testz_pd","","Compute the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_aesenclast_si128","","Perform the last round of an AES encryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_max_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return packed maximum values",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_max_epi32","","Compare packed 32-bit integers in `a` and `b`, and return packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_avg_epu8","","Average packed unsigned 8-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_shuffle_epi8","","Shuffle bytes from `a` according to the content of `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_maskload_pd","","Load packed double-precision (64-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm_min_pi16","","Compares the packed 16-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_movemask_pd","","Set each bit of the returned mask based on the most significant bit of the corresponding packed double-precision (64-bit) floating-point element in `a`.",N,[[["__m256d"]],["i32"]]],[5,"_mm_test_all_zeros","","Tests whether the specified bits in a 128-bit integer vector are all zeros.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm_shuffle_pd","","Constructs a 128-bit floating-point vector of `[2 x double]` from two 128-bit vector parameters of `[2 x double]`, using the immediate-value parameter as a specifier.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_cvttps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128"]],["__m128i"]]],[5,"_mm256_hsub_epi16","","Horizontally subtract adjacent pairs of 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_stream_si32","","Stores a 32-bit integer value in the specified memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm256_load_pd","","Load 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from memory into result. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_subs_pi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_permute2f128_si256","","Shuffle 258-bits (composed of integer data) selected by `imm8` from `a` and `b`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_movepi64_pi64","","Returns the lower 64 bits of a 128-bit integer vector as a 64-bit integer.",N,[[["__m128i"]],["__m64"]]],[5,"_bextr_u64","","Extracts bits in range [`start`, `start` + `length`) from `a` into the least significant bits of the result.",N,[[["u64"],["u32"],["u32"]],["u64"]]],[5,"_mm_hsubs_pi16","","Horizontally subtracts the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`. Positive differences greater than 7FFFh are saturated to 7FFFh. Negative differences less than 8000h are saturated to 8000h.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_max_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mullo_epi16","","Multiply the packed 16-bit integers in `a` and `b`, producing intermediate 32-bit integers, and return the low 16 bits of the intermediate integers",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_permutevar_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` within 128-bit lanes using the control in `b`.",N,[[["__m256"],["__m256i"]],["__m256"]]],[5,"_blcic_u64","","Sets the least significant zero bit of `x` and clears all other bits.",N,[[["u64"]],["u64"]]],[5,"_mm_min_epi8","","Compare packed 8-bit integers in `a` and `b` and return packed minimum values in dst.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_adds_epu16","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cvtsi128_si64","","Return the lowest element of `a`.",N,[[["__m128i"]],["i64"]]],[5,"_mm256_rcp_ps","","Compute the approximate reciprocal of packed single-precision (32-bit) floating-point elements in `a`, and return the results. The maximum relative error for this approximation is less than 1.5*2^-12.",N,[[["__m256"]],["__m256"]]],[5,"_MM_GET_EXCEPTION_STATE","","See `_mm_setcsr`",N,[[],["u32"]]],[17,"_CMP_UNORD_S","","Unordered (signaling)",N,N],[5,"_mm_adds_epi8","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpngt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not greater than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_hsub_pi32","","Horizontally subtracts the adjacent pairs of values contained in 2 packed 64-bit vectors of `[2 x i32]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_andnot_pd","","Compute the bitwise NOT of `a` and then AND with `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_hsubs_epi16","","Horizontally subtract adjacent pairs of 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_extract_epi8","","Extract an 8-bit integer from `a`, selected with `imm8`. Returns a 32-bit integer containing the zero-extended integer data.",N,[[["__m256i"],["i32"]],["i8"]]],[5,"_mm256_hsub_ps","","Horizontal subtraction of adjacent pairs in the two packed vectors of 8 32-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in locations of indices 0, 1, 4, 5; while sums of elements from `b` are locations 2, 3, 6, 7.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_min_sd","","Return a new vector with the low element of `a` replaced by the minimum of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_comigt_sd","","Compare the lower element of `a` and `b` for greater-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_andnot_si128","","Compute the bitwise NOT of 128 bits (representing integer data) in `a` and then AND with `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_extract_ps","","Extract a single-precision (32-bit) floating-point element from `a`, selected with `imm8`",N,[[["__m128"],["i32"]],["i32"]]],[5,"_mm256_set1_epi8","","Broadcast 8-bit integer `a` to all elements of returned vector. This intrinsic may generate the `vpbroadcastb`.",N,[[["i8"]],["__m256i"]]],[5,"_mm_cvtsd_f64","","Return the lower double-precision (64-bit) floating-point element of \"a\".",N,[[["__m128d"]],["f64"]]],[5,"_mm_sll_epi32","","Shift packed 32-bit integers in `a` left by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_setr_pi8","","Set packed 8-bit integers in dst with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m64"]]],[5,"_mm256_packs_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using signed saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_broadcastd_epi32","","Broadcast the low packed 32-bit integer from `a` to all elements of the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_loadu2_m128d","","Load two 128-bit values (composed of 2 packed double-precision (64-bit) floating-point elements) from memory, and combine them into a 256-bit value. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm_cvtsd_si64x","","Alias for `_mm_cvtsd_si64`",N,[[["__m128d"]],["i64"]]],[17,"_SIDD_MASKED_POSITIVE_POLARITY","","Do not negate results before the end of the string",N,N],[17,"_CMP_NGE_US","","Not-greater-than-or-equal (unordered, signaling)",N,N],[5,"_mm256_cmpeq_epi32","","Compare packed 32-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cmpnge_sd","","Return a new vector with the low element of `a` replaced by the not-greater-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_testnzc_ps","","Compute the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m128"],["__m128"]],["i32"]]],[17,"_MM_FLUSH_ZERO_ON","","See `_mm_setcsr`",N,N],[5,"_mm_loadu_pd","","Load 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from memory into the returned vector. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_mul_ps","","Multiplies __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_set_m128","","Set packed __m256 returned vector with the supplied values.",N,[[["__m128"],["__m128"]],["__m256"]]],[5,"_bswap64","","Return an integer with the reversed byte order of x",N,[[["i64"]],["i64"]]],[5,"_mm_add_pi8","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_insertf128_pd","","Copy `a` to result, then insert 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `b` into result at the location specified by `imm8`.",N,[[["__m256d"],["__m128d"],["i32"]],["__m256d"]]],[5,"_mm256_mulhi_epu16","","Multiply the packed unsigned 16-bit integers in `a` and `b`, producing intermediate 32-bit integers and returning the high 16 bits of the intermediate integers.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_m_pminub","","Compares the packed 8-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_extract_epi64","","Extract an 64-bit integer from `a` selected with `imm8`",N,[[["__m128i"],["i32"]],["i64"]]],[5,"_mm_aesdec_si128","","Perform one round of an AES decryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_castps256_ps128","","Casts vector of type __m256 to type __m128.",N,[[["__m256"]],["__m128"]]],[5,"_mm_insert_epi64","","Return a copy of `a` with the 64-bit integer from `i` inserted at a location specified by `imm8`.",N,[[["__m128i"],["i64"],["i32"]],["__m128i"]]],[3,"__m256i","","256-bit wide integer vector type, x86-specific",N,N],[5,"_mm256_fnmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_comigt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_sllv_epi64","","Shift packed 64-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_or_pd","","Compute the bitwise OR packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fmsubadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[17,"_MM_FLUSH_ZERO_MASK","","See `_MM_GET_FLUSH_ZERO_MODE`",N,N],[5,"_mm_testc_si128","","Tests whether the specified bits in a 128-bit integer vector are all ones.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_m_pminsw","","Compares the packed 16-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_sll_epi16","","Shift packed 16-bit integers in `a` left by `count` while shifting in zeros, and return the result",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm_rcp_ss","","Return the approximate reciprocal of the first single-precision (32-bit) floating-point element in `a`, the other elements are unchanged.",N,[[["__m128"]],["__m128"]]],[5,"_m_psubsw","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_extract_epi64","","Extract a 64-bit integer from `a`, selected with `imm8`.",N,[[["__m256i"],["i32"]],["i64"]]],[5,"_bextr2_u64","","Extracts bits of `a` specified by `control` into the least significant bits of the result.",N,[[["u64"],["u64"]],["u64"]]],[5,"_mm256_cvtpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m256d"]],["__m128i"]]],[5,"_mm256_unpacklo_epi32","","Unpack and interleave 32-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cvtepu16_epi64","","Zero-extend the lower four unsigned 16-bit integers in `a` to 64-bit integers. The upper four elements of `a` are unused.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_set_pi32","","Set packed 32-bit integers in dst with the supplied values.",N,[[["i32"],["i32"]],["__m64"]]],[5,"_mm256_unpackhi_epi16","","Unpack and interleave 16-bit integers from the high half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_blend_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using control mask `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_xgetbv","","Reads the contents of the extended control register `XCR` specified in `xcr_no`.",N,[[["u32"]],["u64"]]],[5,"_lzcnt_u64","","Counts the leading most significant zero bits.",N,[[["u64"]],["u64"]]],[5,"_blcic_u32","","Sets the least significant zero bit of `x` and clears all other bits.",N,[[["u32"]],["u32"]]],[5,"_mm_or_si128","","Compute the bitwise OR of 128 bits (representing integer data) in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_sll_epi64","","Shift packed 64-bit integers in `a` left by `count` while shifting in zeros, and return the result",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_mask_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_cmplt_ss","","Compare the lowest `f32` of both inputs for less than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is less than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_movehdup_ps","","Duplicate odd-indexed single-precision (32-bit) floating-point elements from `a`, and return the results.",N,[[["__m256"]],["__m256"]]],[5,"_mm_ucomieq_sd","","Compare the lower element of `a` and `b` for equality.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_lzcnt_u32","","Counts the leading most significant zero bits.",N,[[["u32"]],["u32"]]],[5,"_mm_castpd_ps","","Casts a 128-bit floating-point vector of `[2 x double]` into a 128-bit floating-point vector of `[4 x float]`.",N,[[["__m128d"]],["__m128"]]],[5,"_mm_sra_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[17,"_CMP_GT_OQ","","Greater-than (ordered, non-signaling)",N,N],[5,"_bzhi_u32","","Zero higher bits of `a` >= `index`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm_max_ss","","Compare the first single-precision (32-bit) floating-point element of `a` and `b`, and return the maximum value in the first element of the return value, the other elements are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_packs_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using signed saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_store_ps","","Store 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from `a` into memory. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_max_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_subs_epi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_store_pd","","Store 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_cvttsd_si64","","Convert the lower double-precision (64-bit) floating-point element in `a` to a 64-bit integer with truncation.",N,[[["__m128d"]],["i64"]]],[17,"_CMP_NGT_US","","Not-greater-than (unordered, signaling)",N,N],[5,"_mm_alignr_epi8","","Concatenate 16-byte blocks in `a` and `b` into a 32-byte temporary result, shift the result right by `n` bytes, and return the low 16 bytes.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_movemask_pd","","Return a mask of the most significant bit of each element in `a`.",N,[[["__m128d"]],["i32"]]],[5,"_mm256_cmpeq_epi16","","Compare packed 16-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cmpeq_sd","","Return a new vector with the low element of `a` replaced by the equality comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[17,"_CMP_NLE_UQ","","Not-less-than-or-equal (unordered, non-signaling)",N,N],[5,"_m_paddw","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmple_sd","","Return a new vector with the low element of `a` replaced by the less-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_aesdeclast_si128","","Perform the last round of an AES decryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_fnmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_max_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b`, and return packed maximum values",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_castpd256_pd128","","Casts vector of type __m256d to type __m128d.",N,[[["__m256d"]],["__m128d"]]],[5,"_mm_max_pi16","","Compares the packed 16-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_unpacklo_pd","","Unpack and interleave double-precision (64-bit) floating-point elements from the low half of each 128-bit lane in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_abs_epi8","","Computes the absolute values of packed 8-bit integers in `a`.",N,[[["__m256i"]],["__m256i"]]],[5,"_mm256_castpd128_pd256","","Casts vector of type __m128d to type __m256d; the upper 128 bits of the result are undefined.",N,[[["__m128d"]],["__m256d"]]],[5,"_m_paddb","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_comineq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are not equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_set1_epi64","","Initializes both values in a 128-bit vector of `[2 x i64]` with the specified 64-bit value.",N,[[["__m64"]],["__m128i"]]],[5,"_mm_cmpestri","","Compare packed strings `a` and `b` with lengths `la` and `lb` using the control in `imm8` and return the generated index. Similar to [`_mm_cmpistri`] with the exception that [`_mm_cmpistri`] implicitly determines the length of `a` and `b`.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_fnmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_maskstore_ps","","Store packed single-precision (32-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm_unpacklo_epi16","","Unpack and interleave 16-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_fmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_loadl_pi","","Load two floats from `p` into the lower half of a `__m128`. The upper half is copied from the upper half of `a`.",N,N],[17,"_MM_EXCEPT_OVERFLOW","","See `_mm_setcsr`",N,N],[5,"_mm256_permutevar_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` within 256-bit lanes using the control in `b`.",N,[[["__m256d"],["__m256i"]],["__m256d"]]],[5,"_blsfill_u32","","Sets all bits of `x` below the least significant one.",N,[[["u32"]],["u32"]]],[5,"_mm_maskload_epi32","","Load packed 32-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_max_pd","","Return a new vector with the maximum values from corresponding elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_stream_ps","","Moves single-precision floating point values from a 256-bit vector of `[8 x float]` to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_cvttpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128d"]],["__m128i"]]],[5,"_mm_cmplt_epi32","","Compare packed 32-bit integers in `a` and `b` for less-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_extractf128_ps","","Extract 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from `a`, selected with `imm8`.",N,[[["__m256"],["i32"]],["__m128"]]],[5,"_mm_and_si128","","Compute the bitwise AND of 128 bits (representing integer data) in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_movemask_ps","","Return a mask of the most significant bit of each element in `a`.",N,[[["__m128"]],["i32"]]],[5,"_mm256_unpacklo_epi64","","Unpack and interleave 64-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cmpneq_pd","","Compare corresponding elements in `a` and `b` for not-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_set1_epi16","","Broadcast 16-bit integer `a` to all all elements of returned vector. This intrinsic may generate the `vpbroadcastw`.",N,[[["i16"]],["__m256i"]]],[5,"_mm_cvtps_pd","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128"]],["__m128d"]]],[5,"_mm_cmpge_sd","","Return a new vector with the low element of `a` replaced by the greater-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpnle_pd","","Compare corresponding elements in `a` and `b` for not-less-than-or-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_storeu2_m128i","","Store the high and low 128-bit halves (each composed of integer data) from `a` into memory two different 128-bit locations. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm_cvtsi128_si64x","","Return the lowest element of `a`.",N,[[["__m128i"]],["i64"]]],[5,"_mm256_andnot_ps","","Compute the bitwise NOT of packed single-precision (32-bit) floating-point elements in `a` and then AND with `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_MM_GET_FLUSH_ZERO_MODE","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_mm256_castps128_ps256","","Casts vector of type __m128 to type __m256; the upper 128 bits of the result are undefined.",N,[[["__m128"]],["__m256"]]],[17,"_MM_FROUND_TRUNC","","truncate and do not suppress exceptions",N,N],[5,"_mm256_subs_epu8","","Subtract packed unsigned 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cvtt_ps2pi","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128"]],["__m64"]]],[5,"_mm_min_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpistrz","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return `1` if any character in `b` was null. and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm256_loadu2_m128i","","Load two 128-bit values (composed of integer data) from memory, and combine them into a 256-bit value. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm_testz_ps","","Compute the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_cmpgt_pi16","","Compares whether each element of `a` is greater than the corresponding element of `b` returning `0` for `false` and `-1` for `true`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_loadu_si128","","Load 128-bits of integer data from memory into a new vector.",N,N],[5,"_mm_max_pu8","","Compares the packed 8-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_set_epi8","","Set packed 8-bit integers with the supplied values.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m128i"]]],[5,"_t1mskc_u64","","Clears all bits below the least significant zero of `x` and sets all other bits.",N,[[["u64"]],["u64"]]],[5,"_mm_subs_epu16","","Subtract packed unsigned 16-bit integers in `b` from packed unsigned 16-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_unpackhi_epi64","","Unpack and interleave 64-bit integers from the high half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_sub_ps","","Subtracts __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpnge_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not greater than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_m_pmaxsw","","Compares the packed 16-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmpistrs","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and returns `1` if any character in `a` was null, and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_sign_epi8","","Negate packed 8-bit integers in `a` when the corresponding signed 8-bit integer in `b` is negative, and return the result. Elements in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpunord_ss","","Check if the lowest `f32` of both inputs are unordered. The lowest 32 bits of the result will be `0xffffffff` if any of `a.extract(0)` or `b.extract(0)` is a NaN, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_maskload_epi32","","Load packed 32-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_blendv_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using `c` as a mask.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_loadr_pd","","Load 2 double-precision (64-bit) floating-point elements from memory into the returned vector in reverse order. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_extract_si64","","Extracts the bit range specified by `y` from the lower 64 bits of `x`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_set_ps","","Set packed single-precision (32-bit) floating-point elements in returned vector with the supplied values.",N,[[["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"]],["__m256"]]],[5,"_mm_getcsr","","Get the unsigned 32-bit value of the MXCSR control and status register.",N,[[],["u32"]]],[5,"_mm_cmp_sd","","Compare the lower double-precision (64-bit) floating-point element in `a` and `b` based on the comparison operand specified by `imm8`, store the result in the lower element of returned vector, and copy the upper element from `a` to the upper element of returned vector.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_sha1nexte_epu32","","Calculate SHA1 state variable E after four rounds of operation from the current SHA1 state variable `a`, add that value to the scheduled values (unsigned 32-bit integers) in `b`, and returns the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpnle_sd","","Return a new vector with the low element of `a` replaced by the not-less-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[17,"_CMP_NEQ_OS","","Not-equal (ordered, signaling)",N,N],[5,"_mm_set_ps","","Construct a `__m128` from four floating point values highest to lowest.",N,[[["f32"],["f32"],["f32"],["f32"]],["__m128"]]],[17,"_MM_FROUND_RINT","","use MXCSR.RC and do not suppress exceptions; see `vendor::_MM_SET_ROUNDING_MODE`",N,N],[17,"_SIDD_MOST_SIGNIFICANT","","Index only: return the most significant bit",N,N],[5,"_mm256_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_store_pd","","Store 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_m_psubusb","","Subtract packed unsigned 8-bit integers in `b` from packed unsigned 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[17,"_MM_MASK_INVALID","","See `_mm_setcsr`",N,N],[5,"_mm256_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_set_pi8","","Set packed 8-bit integers in dst with the supplied values.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m64"]]],[5,"_mm_cvtpi8_ps","","Converts the lower 4 8-bit values of `a` into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm_cvtt_ss2si","","Alias for `_mm_cvttss_si32`.",N,[[["__m128"]],["i32"]]],[5,"_mm_hsub_pd","","Horizontally subtract adjacent pairs of double-precision (64-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_testnzc_pd","","Compute the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m256d"],["__m256d"]],["i32"]]],[5,"_mm_loadl_epi64","","Load 64-bit integer from memory into first element of returned vector.",N,N],[5,"_mm_cvtepu16_epi32","","Zero extend packed unsigned 16-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_cmpeq_epi64","","Compare packed 64-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_clflush","","Invalidate and flush the cache line that contains `p` from all levels of the cache hierarchy.",N,N],[5,"_mm_cvttsd_si32","","Convert the lower double-precision (64-bit) floating-point element in `a` to a 32-bit integer with truncation.",N,[[["__m128d"]],["i32"]]],[5,"_mm_sub_sd","","Return a new vector with the low element of `a` replaced by subtracting the low element by `b` from the low element of `a`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_fxsave64","","Saves the `x87` FPU, `MMX` technology, `XMM`, and `MXCSR` registers to the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[17,"_SIDD_SWORD_OPS","","String contains unsigned 16-bit characters",N,N],[5,"_mm256_add_epi32","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[17,"_CMP_NEQ_US","","Not-equal (unordered, signaling)",N,N],[5,"_mm_comige_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than or equal to the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_cvttpd_pi32","","Converts the two double-precision floating-point elements of a 128-bit vector of `[2 x double]` into two signed 32-bit integer values, returned in a 64-bit vector of `[2 x i32]`. If the result of either conversion is inexact, the result is truncated (rounded towards zero) regardless of the current MXCSR setting.",N,[[["__m128d"]],["__m64"]]],[5,"_blsr_u64","","Resets the lowest set bit of `x`.",N,[[["u64"]],["u64"]]],[5,"_mm_cvtepi8_epi16","","Sign extend packed 8-bit integers in `a` to packed 16-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_broadcastb_epi8","","Broadcast the low packed 8-bit integer from `a` to all elements of the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_fmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[17,"_MM_EXCEPT_MASK","","See `_MM_GET_EXCEPTION_STATE`",N,N],[5,"_mm_mask_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[17,"_CMP_ORD_Q","","Ordered (non-signaling)",N,N],[5,"_mm256_permute2f128_pd","","Shuffle 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) selected by `imm8` from `a` and `b`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_mm_cmpnle_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not less than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_max_epi8","","Compare packed 8-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_and_pd","","Compute the bitwise AND of packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_fnmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_andn_u32","","Bitwise logical `AND` of inverted `a` with `b`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_m_pmaxub","","Compares the packed 8-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cvtpi32_pd","","Converts the two signed 32-bit integer elements of a 64-bit vector of `[2 x i32]` into two double-precision floating-point values, returned in a 128-bit vector of `[2 x double]`.",N,[[["__m64"]],["__m128d"]]],[5,"_mm256_maskstore_ps","","Store packed single-precision (32-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm256_hsub_pd","","Horizontal subtraction of adjacent pairs in the two packed vectors of 4 64-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in even locations, while sums of elements from `b` are returned in odd locations.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_comineq_sd","","Compare the lower element of `a` and `b` for not-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_ceil_sd","","Round the lower double-precision (64-bit) floating-point element in `b` up to an integer value, store the result as a double-precision floating-point element in the lower element of the intrisic result, and copy the upper element from `a` to the upper element of the intrinsic result.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_cvtepi16_epi64","","Sign-extend 16-bit integers to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_set_epi64x","","Set packed 64-bit integers with the supplied values, from highest to lowest.",N,[[["i64"],["i64"]],["__m128i"]]],[5,"_mm_cmplt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is less than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_sign_epi32","","Negate packed 32-bit integers in `a` when the corresponding signed 32-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cvtps_pi8","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 8-bit integers, and returns theem in the lower 4 elements of the result.",N,[[["__m128"]],["__m64"]]],[5,"_mm256_stream_pd","","Moves double-precision values from a 256-bit vector of `[4 x double]` to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_extract_epi16","","Return the `imm8` element of `a`.",N,[[["__m128i"],["i32"]],["i32"]]],[5,"_mm256_subs_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cmplt_epi8","","Compare packed 8-bit integers in `a` and `b` for less-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_packs_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using signed saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_unpackhi_epi64","","Unpack and interleave 64-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_subs_pi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_xsaveopt","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_mm256_madd_epi16","","Multiply packed signed 16-bit integers in `a` and `b`, producing intermediate signed 32-bit integers. Horizontally add adjacent pairs of intermediate 32-bit integers.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"__cpuid","","See `__cpuid_count`.",N,[[["u32"]],["cpuidresult"]]],[5,"_mm256_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_sub_pi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[17,"_MM_FROUND_FLOOR","","round down and do not suppress exceptions",N,N],[5,"_mm_stream_si128","","Stores a 128-bit integer vector to a 128-bit aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_cmpngt_sd","","Return a new vector with the low element of `a` replaced by the not-greater-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_round_ps","","Round packed single-precision (32-bit) floating point elements in `a` according to the flag `b`. The value of `b` may be as follows:",N,[[["__m256"],["i32"]],["__m256"]]],[5,"_mm_cvtepu8_epi64","","Zero extend packed unsigned 8-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_store_ps1","","Alias for `_mm_store1_ps`",N,N],[5,"_mm_srlv_epi64","","Shift packed 64-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cvtsi64_ss","","Convert a 64 bit integer to a 32 bit float. The result vector is the input vector `a` with the lowest 32 bit float replaced by the converted integer.",N,[[["__m128"],["i64"]],["__m128"]]],[5,"_mm256_loadu_si256","","Load 256-bits of integer data from memory into result. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_maskmove_si64","","Conditionally copies the values from each 8-bit element in the first 64-bit integer vector operand to the specified memory location, as specified by the most significant bit in the corresponding element in the second 64-bit integer vector operand.",N,N],[3,"__m256","","256-bit wide set of eight `f32` types, x86-specific",N,N],[5,"_mm256_setr_ps","","Set packed single-precision (32-bit) floating-point elements in returned vector with the supplied values in reverse order.",N,[[["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"]],["__m256"]]],[5,"_mm_cvtsi64_si128","","Return a vector whose lowest element is `a` and all higher elements are `0`.",N,[[["i64"]],["__m128i"]]],[5,"_mm256_castsi256_pd","","Casts vector of type __m256i to type __m256d.",N,[[["__m256i"]],["__m256d"]]],[17,"_MM_FLUSH_ZERO_OFF","","See `_mm_setcsr`",N,N],[5,"_mm_unpacklo_pi8","","Unpacks the lower four elements from two `i8x8` vectors and interleaves them into the result: `[a.0, b.0, a.1, b.1, a.2, b.2, a.3, b.3]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[17,"_MM_FROUND_NINT","","round to nearest and do not suppress exceptions",N,N],[5,"_mm256_testz_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`, and set `ZF` to 1 if the result is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, and set `CF` to 1 if the result is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m256i"],["__m256i"]],["i32"]]],[5,"_mm256_add_epi16","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_abs_epi8","","Compute the absolute value of packed 8-bit signed integers in `a` and return the unsigned results.",N,[[["__m128i"]],["__m128i"]]],[3,"__m64","","64-bit wide integer vector type, x86-specific",N,N],[5,"_mm_move_epi64","","Return a vector where the low element is extracted from `a` and its upper element is zero.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_fnmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_load1_ps","","Construct a `__m128` by duplicating the value read from `p` into all elements.",N,N],[5,"_mm_subs_epu8","","Subtract packed unsigned 8-bit integers in `b` from packed unsigned 8-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[17,"_CMP_EQ_UQ","","Equal (unordered, non-signaling)",N,N],[5,"_mm256_packus_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using unsigned saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_setzero_si64","","Constructs a 64-bit integer vector initialized to zero.",N,[[],["__m64"]]],[5,"_mm_sub_ss","","Subtracts the first component of `b` from `a`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_broadcast_pd","","Broadcast 128 bits from memory (composed of 2 packed double-precision (64-bit) floating-point elements) to all elements of the returned vector.",N,[[["__m128d"]],["__m256d"]]],[5,"_mm_stream_pi","","Store 64-bits of integer data from a into memory using a non-temporal memory hint.",N,N],[5,"_mm256_sllv_epi32","","Shift packed 32-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_max_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return packed maximum.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_shufflehi_epi16","","Shuffle 16-bit integers in the high 64 bits of `a` using the control in `imm8`.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_cvtsi32_si128","","Return a vector whose lowest element is `a` and all higher elements are `0`.",N,[[["i32"]],["__m128i"]]],[5,"_mm256_moveldup_ps","","Duplicate even-indexed single-precision (32-bit) floating-point elements from `a`, and return the results.",N,[[["__m256"]],["__m256"]]],[5,"_mm_hsub_pi16","","Horizontally subtracts the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmpgt_epi16","","Compare packed 16-bit integers in `a` and `b` for greater-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpnlt_pd","","Compare corresponding elements in `a` and `b` for not-less-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_mul_ss","","Multiplies the first component of `a` and `b`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_lddqu_si128","","Load 128-bits of integer data from unaligned memory. This intrinsic may perform better than `_mm_loadu_si128` when the data crosses a cache line boundary.",N,N],[5,"_mm_pause","","Provide a hint to the processor that the code sequence is a spin-wait loop.",N,N],[5,"_mm_cmpgt_ss","","Compare the lowest `f32` of both inputs for greater than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is greater than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_set_pd","","Set packed double-precision (64-bit) floating-point elements in returned vector with the supplied values.",N,[[["f64"],["f64"],["f64"],["f64"]],["__m256d"]]],[5,"_rdseed16_step","","Read a 16-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u16"]],["i32"]]],[5,"_mm256_ceil_pd","","Round packed double-precision (64-bit) floating point elements in `a` toward positive infinity.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm_add_epi64","","Add packed 64-bit integers in `a` and \"b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_packs_pi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using signed saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_ceil_ps","","Round packed single-precision (32-bit) floating point elements in `a` toward positive infinity.",N,[[["__m256"]],["__m256"]]],[5,"_mm_broadcastq_epi64","","Broadcast the low packed 64-bit integer from `a` to all elements of the 128-bit returned value.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cmpnlt_sd","","Return a new vector with the low element of `a` replaced by the not-less-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_testnzc_ps","","Compute the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m256"],["__m256"]],["i32"]]],[5,"_mm256_broadcast_ps","","Broadcast 128 bits from memory (composed of 4 packed single-precision (32-bit) floating-point elements) to all elements of the returned vector.",N,[[["__m128"]],["__m256"]]],[5,"_mm256_sub_pd","","Subtract packed double-precision (64-bit) floating-point elements in `b` from packed elements in `a`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_unpacklo_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the low half of each 128-bit lane in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_m_pinsrw","","Copies data from the 64-bit vector of `[4 x i16]` to the destination, and inserts the lower 16-bits of an integer operand at the 16-bit offset specified by the immediate operand `n`.",N,[[["__m64"],["i32"],["i32"]],["__m64"]]],[5,"_mm256_permutevar8x32_ps","","Shuffle eight 32-bit foating-point elements in `a` across lanes using the corresponding 32-bit integer index in `idx`.",N,[[["__m256"],["__m256i"]],["__m256"]]],[5,"_mm_cmpestrs","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if any character in a was null, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_blsic_u32","","Clears least significant bit and sets all other bits.",N,[[["u32"]],["u32"]]],[5,"_mm256_fnmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_max_epi8","","Compare packed 8-bit integers in `a` and `b` and return packed maximum values in dst.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_load_pd","","Load 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from memory into the returned vector. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_stream_si256","","Moves integer data from a 256-bit integer vector to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon)",N,N],[5,"_bextr_u32","","Extracts bits in range [`start`, `start` + `length`) from `a` into the least significant bits of the result.",N,[[["u32"],["u32"],["u32"]],["u32"]]],[5,"_mm_hadd_pi32","","Horizontally add the adjacent pairs of values contained in 2 packed 64-bit vectors of `[2 x i32]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cvtps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128"]],["__m128i"]]],[5,"_mm256_shuffle_epi32","","Shuffle 32-bit integers in 128-bit lanes of `a` using the control in `imm8`.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_blcfill_u64","","Clears all bits below the least significant zero bit of `x`.",N,[[["u64"]],["u64"]]],[5,"_mm256_min_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_andn_u64","","Bitwise logical `AND` of inverted `a` with `b`.",N,[[["u64"],["u64"]],["u64"]]],[5,"_mm_maskload_ps","","Load packed single-precision (32-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm256_sll_epi32","","Shift packed 32-bit integers in `a` left by `count` while shifting in zeros, and return the result",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm_comige_sd","","Compare the lower element of `a` and `b` for greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm256_cvtepi16_epi32","","Sign-extend 16-bit integers to 32-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_insert_epi64","","Copy `a` to result, and insert the 64-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i64"],["i32"]],["__m256i"]]],[5,"_mm_hadd_pi16","","Horizontally add the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_castps_pd","","Casts a 128-bit floating-point vector of `[4 x float]` into a 128-bit floating-point vector of `[2 x double]`.",N,[[["__m128"]],["__m128d"]]],[5,"_mm_cmpistri","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8` and return the generated index. Similar to [`_mm_cmpestri`] with the exception that [`_mm_cmpestri`] requires the lengths of `a` and `b` to be explicitly specified.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_shuffle_ps","","Shuffle packed single-precision (32-bit) floating-point elements in `a` and `b` using `mask`.",N,[[["__m128"],["__m128"],["u32"]],["__m128"]]],[5,"_mm_blendv_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using `mask`",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_unpacklo_epi8","","Unpack and interleave 8-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cvtepu32_epi64","","Zero-extend unsigned 32-bit integers in `a` to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[17,"_XCR_XFEATURE_ENABLED_MASK","","`XFEATURE_ENABLED_MASK` for `XCR`",N,N],[5,"_mm256_broadcastss_ps","","Broadcast the low single-precision (32-bit) floating-point element from `a` to all elements of the 256-bit returned value.",N,[[["__m128"]],["__m256"]]],[5,"_mm_madd_epi16","","Multiply and then horizontally add signed 16 bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_mul_pd","","Add packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_and_ps","","Compute the bitwise AND of packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_max_sd","","Return a new vector with the low element of `a` replaced by the maximum of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fmsubadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fmadd_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and add the intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_set1_pi16","","Broadcast 16-bit integer a to all all elements of dst.",N,[[["i16"]],["__m64"]]],[5,"_mm256_setr_epi8","","Set packed 8-bit integers in returned vector with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m256i"]]],[5,"_mm256_addsub_ps","","Alternatively add and subtract packed single-precision (32-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_cmpeq_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input elements were equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_m_psubsb","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_floor_pd","","Round packed double-precision (64-bit) floating point elements in `a` toward negative infinity.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm256_andnot_pd","","Compute the bitwise NOT of packed double-precision (64-bit) floating-point elements in `a` and then AND with `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fnmadd_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_m_pextrw","","Extracts 16-bit element from a 64-bit vector of `[4 x i16]` and returns it, as specified by the immediate integer operand.",N,[[["__m64"],["i32"]],["i32"]]],[5,"_mm_crc32_u8","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 8-bit integer `v`.",N,[[["u32"],["u8"]],["u32"]]],[17,"_SIDD_NEGATIVE_POLARITY","","Negate results",N,N],[5,"_mm256_broadcastw_epi16","","Broadcast the low packed 16-bit integer from a to all elements of the 256-bit returned value",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_loadu_ps","","Load four `f32` values from memory into a `__m128`. There are no restrictions on memory alignment. For aligned memory `_mm_load_ps` may be faster.",N,N],[5,"_mm_load_pd1","","Load a double-precision (64-bit) floating-point element from memory into both elements of returned vector.",N,N],[5,"_mm_srli_si128","","Shift `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[17,"_MM_HINT_T0","","See `_mm_prefetch`.",N,N],[5,"_mm_adds_pi16","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_blend_epi32","","Blend packed 32-bit integers from `a` and `b` using control mask `imm8`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_mask_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_zextpd128_pd256","","Constructs a 256-bit floating-point vector of `[4 x double]` from a 128-bit floating-point vector of `[2 x double]`. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.",N,[[["__m128d"]],["__m256d"]]],[17,"_CMP_LE_OQ","","Less-than-or-equal (ordered, non-signaling)",N,N],[17,"_MM_EXCEPT_DENORM","","See `_mm_setcsr`",N,N],[5,"_mm_min_ss","","Compare the first single-precision (32-bit) floating-point element of `a` and `b`, and return the minimum value in the first element of the return value, the other elements are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_mask_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_sub_epi64","","Subtract packed 64-bit integers in `b` from packed 64-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_permute_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` using the control in `imm8`.",N,[[["__m128d"],["i32"]],["__m128d"]]],[5,"_mm256_castsi256_ps","","Casts vector of type __m256i to type __m256.",N,[[["__m256i"]],["__m256"]]],[5,"_mm_cvtpi32_ps","","Converts two elements of a 64-bit vector of `[2 x i32]` into two floating point values and writes them to the lower 64-bits of the destination. The remaining higher order elements of the destination are copied from the corresponding elements in the first operand.",N,[[["__m128"],["__m64"]],["__m128"]]],[5,"_mm256_extracti128_si256","","Extract 128 bits (of integer data) from `a` selected with `imm8`.",N,[[["__m256i"],["i32"]],["__m128i"]]],[5,"has_cpuid","","Does the host support the `cpuid` instruction?",N,[[],["bool"]]],[5,"_mm_blend_epi32","","Blend packed 32-bit integers from `a` and `b` using control mask `imm8`.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_setzero_pd","","Returns packed double-precision (64-bit) floating-point elements with all zeros.",N,[[],["__m128d"]]],[5,"_mm256_hadd_pd","","Horizontal addition of adjacent pairs in the two packed vectors of 4 64-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in even locations, while sums of elements from `b` are returned in odd locations.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_cmpgt_epi16","","Compare packed 16-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_permute_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` within 128-bit lanes using the control in `imm8`.",N,[[["__m256d"],["i32"]],["__m256d"]]],[5,"_blsic_u64","","Clears least significant bit and sets all other bits.",N,[[["u64"]],["u64"]]],[5,"_mm256_cvtps_pd","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128"]],["__m256d"]]],[5,"_mm_undefined_pd","","Return vector of type __m128d with undefined elements.",N,[[],["__m128d"]]],[5,"_mm_div_pd","","Divide packed double-precision (64-bit) floating-point elements in `a` by packed elements in `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[17,"_MM_EXCEPT_INEXACT","","See `_mm_setcsr`",N,N],[17,"_CMP_NLE_US","","Not-less-than-or-equal (unordered, signaling)",N,N],[5,"_mm_cvtpd_ps","","Convert packed double-precision (64-bit) floating-point elements in \"a\" to packed single-precision (32-bit) floating-point elements",N,[[["__m128d"]],["__m128"]]],[5,"_mm_setzero_si128","","Returns a vector with all elements set to zero.",N,[[],["__m128i"]]],[5,"_mm_cmpgt_epi8","","Compare packed 8-bit integers in `a` and `b` for greater-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_srl_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_permute4x64_pd","","Shuffle 64-bit floating-point elements in `a` across lanes using the control in `imm8`.",N,[[["__m256d"],["i32"]],["__m256d"]]],[5,"_mm256_set_epi16","","Set packed 16-bit integers in returned vector with the supplied values.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m256i"]]],[5,"_mm_floor_pd","","Round the packed double-precision (64-bit) floating-point elements in `a` down to an integer value, and store the results as packed double-precision floating-point elements.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm256_subs_epu16","","Subtract packed unsigned 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_blendv_epi8","","Blend packed 8-bit integers from `a` and `b` using `mask`.",N,[[["__m256i"],["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_round_pd","","Round packed double-precision (64-bit) floating point elements in `a` according to the flag `b`. The value of `b` may be as follows:",N,[[["__m256d"],["i32"]],["__m256d"]]],[5,"_mm_add_epi32","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpnlt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not less than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_crc32_u64","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 64-bit integer `v`.",N,[[["u64"],["u64"]],["u64"]]],[5,"_mm_unpacklo_epi8","","Unpack and interleave 8-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_subs_pu8","","Subtract packed unsigned 8-bit integers in `b` from packed unsigned 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[17,"_CMP_GE_OQ","","Greater-than-or-equal (ordered, non-signaling)",N,N],[5,"_mm256_setr_pd","","Set packed double-precision (64-bit) floating-point elements in returned vector with the supplied values in reverse order.",N,[[["f64"],["f64"],["f64"],["f64"]],["__m256d"]]],[5,"_mm_stream_sd","","Non-temporal store of `a.0` into `p`.",N,N],[5,"_mm_fnmsub_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_hsubs_epi16","","Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`. Positive differences greater than 7FFFh are saturated to 7FFFh. Negative differences less than 8000h are saturated to 8000h.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mask_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"__cpuid_count","","Returns the result of the `cpuid` instruction for a given `leaf` (`EAX`) and `sub_leaf` (`ECX`).",N,[[["u32"],["u32"]],["cpuidresult"]]],[5,"_mm_cvtss_f32","","Extract the lowest 32 bit float from the input vector.",N,[[["__m128"]],["f32"]]],[5,"_mm_sfence","","Perform a serializing operation on all store-to-memory instructions that were issued prior to this instruction.",N,N],[5,"_mm_srl_epi64","","Shift packed 64-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[17,"_MM_HINT_NTA","","See `_mm_prefetch`.",N,N],[5,"_m_psadbw","","Subtracts the corresponding 8-bit unsigned integer values of the two 64-bit vector operands and computes the absolute value for each of the difference. Then sum of the 8 absolute differences is written to the bits `[15:0]` of the destination; the remaining bits `[63:16]` are cleared.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_broadcastd_epi32","","Broadcast the low packed 32-bit integer from `a` to all elements of the 128-bit returned value.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_add_epi64","","Add packed 64-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_mpsadbw_epu8","","Subtracts 8-bit unsigned integer values and computes the absolute values of the differences to the corresponding bits in the destination. Then sums of the absolute differences are returned according to the bit fields in the immediate operand.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_load_ps","","Load four `f32` values from aligned memory into a `__m128`. If the pointer is not aligned to a 128-bit boundary (16 bytes) a general protection fault will be triggered (fatal program crash).",N,N],[5,"_mm_store_sd","","Stores the lower 64 bits of a 128-bit vector of `[2 x double]` to a memory location.",N,N],[17,"_CMP_NEQ_OQ","","Not-equal (ordered, non-signaling)",N,N],[5,"_blsi_u32","","Extract lowest set isolated bit.",N,[[["u32"]],["u32"]]],[5,"_mm_set1_epi64x","","Broadcast 64-bit integer `a` to all elements.",N,[[["i64"]],["__m128i"]]],[5,"_mm_cmpistrc","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return `1` if the resulting mask was non-zero, and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_packus_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using unsigned saturation",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_castpd_si256","","Casts vector of type __m256d to type __m256i.",N,[[["__m256d"]],["__m256i"]]],[17,"_MM_HINT_T1","","See `_mm_prefetch`.",N,N],[5,"_mm256_slli_si256","","Shift 128-bit lanes in `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_lddqu_si256","","Load 256-bits of integer data from unaligned memory into result. This intrinsic may perform better than `_mm256_loadu_si256` when the data crosses a cache line boundary.",N,N],[5,"_mm_mullo_epi32","","Multiply the packed 32-bit integers in `a` and `b`, producing intermediate 64-bit integers, and returns the lowest 32-bit, whatever they might be, reinterpreted as a signed integer. While `pmulld __m128i::splat(2), __m128i::splat(2)` returns the obvious `__m128i::splat(4)`, due to wrapping arithmetic `pmulld __m128i::splat(i32::MAX), __m128i::splat(2)` would return a negative number.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sqrt_ps","","Return the square root of packed single-precision (32-bit) floating-point elements in `a`.",N,[[["__m128"]],["__m128"]]],[17,"_CMP_UNORD_Q","","Unordered (non-signaling)",N,N],[5,"_mm_insert_epi16","","Return a new vector where the `imm8` element of `a` is replaced with `i`.",N,[[["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_cmpistro","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return bit `0` of the resulting bit mask.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmplt_epi16","","Compare packed 16-bit integers in `a` and `b` for less-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sub_si64","","Subtracts signed or unsigned 64-bit integer values and writes the difference to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubw","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_ceil_ps","","Round the packed single-precision (32-bit) floating-point elements in `a` up to an integer value, and store the results as packed single-precision floating-point elements.",N,[[["__m128"]],["__m128"]]],[5,"_mm_blend_epi16","","Blend packed 16-bit integers from `a` and `b` using the mask `imm8`.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm256_sqrt_pd","","Return the square root of packed double-precision (64-bit) floating point elements in `a`.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm_blendv_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using `mask`",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_storeu_si256","","Store 256-bits of integer data from `a` into memory.    `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_set_pi16","","Set packed 16-bit integers in dst with the supplied values.",N,[[["i16"],["i16"],["i16"],["i16"]],["__m64"]]],[5,"_mm_round_ss","","Round the lower single-precision (32-bit) floating-point element in `b` using the `rounding` parameter, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copy the upper 3 packed elements from `a` to the upper elements of the instrinsic result. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_setr_pi16","","Set packed 16-bit integers in dst with the supplied values in reverse order.",N,[[["i16"],["i16"],["i16"],["i16"]],["__m64"]]],[5,"_mm_store1_ps","","Store the lowest 32 bit float of `a` repeated four times into aligned memory.",N,N],[5,"_mm_comile_sd","","Compare the lower element of `a` and `b` for less-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_cmp_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_tzcnt_u32","","Counts the number of trailing least significant zero bits.",N,[[["u32"]],["u32"]]],[5,"_mm256_insert_epi32","","Copy `a` to result, and insert the 32-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i32"],["i32"]],["__m256i"]]],[5,"_m_psubb","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[17,"_CMP_NEQ_UQ","","Not-equal (unordered, non-signaling)",N,N],[5,"_mm_ucomige_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than or equal to the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_shuffle_epi32","","Shuffle 32-bit integers in `a` using the control in `imm8`.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_cmpestra","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if `b` did not contain a null character and the resulting mask was zero, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_tzmsk_u32","","Sets all bits below the least significant one of `x` and clears all other bits.",N,[[["u32"]],["u32"]]],[5,"_mm256_srlv_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cmplt_sd","","Return a new vector with the low element of `a` replaced by the less-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_min_epi32","","Compare packed 32-bit integers in `a` and `b`, and return packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_srai_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_MM_SET_EXCEPTION_STATE","","See `_mm_setcsr`",N,N],[5,"_mm_cvtpi16_ps","","Converts a 64-bit vector of `i16`s into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm256_packus_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using unsigned saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_sqrt_ss","","Return the square root of the first single-precision (32-bit) floating-point element in `a`, the other elements are unchanged.",N,[[["__m128"]],["__m128"]]],[5,"_mm_load_si128","","Load 128-bits of integer data from memory into a new vector.",N,N],[5,"_mm256_slli_epi32","","Shift packed 32-bit integers in `a` left by `imm8` while shifting in zeros, return the results;",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_zextsi128_si256","","Constructs a 256-bit integer vector from a 128-bit integer vector. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_cvtss_si64","","Convert the lowest 32 bit float in the input vector to a 64 bit integer.",N,[[["__m128"]],["i64"]]],[5,"_mm_cvtps_pi16","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 16-bit integers.",N,[[["__m128"]],["__m64"]]],[5,"_mm256_hadd_ps","","Horizontal addition of adjacent pairs in the two packed vectors of 8 32-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in locations of indices 0, 1, 4, 5; while sums of elements from `b` are locations 2, 3, 6, 7.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_mulhi_epi16","","Multiply the packed 16-bit integers in `a` and `b`, producing intermediate 32-bit integers and returning the high 16 bits of the intermediate integers.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_tzcnt_64","","Counts the number of trailing least significant zero bits.",N,[[["u64"]],["i64"]]],[5,"_mm256_fmaddsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_castps_pd","","Cast vector of type __m256 to type __m256d.",N,[[["__m256"]],["__m256d"]]],[5,"_blsmsk_u64","","Get mask up to lowest set bit.",N,[[["u64"]],["u64"]]],[5,"_mm_sad_pu8","","Subtracts the corresponding 8-bit unsigned integer values of the two 64-bit vector operands and computes the absolute value for each of the difference. Then sum of the 8 absolute differences is written to the bits `[15:0]` of the destination; the remaining bits `[63:16]` are cleared.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_blend_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using control mask `imm8`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_mm_subs_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_bextr2_u32","","Extracts bits of `a` specified by `control` into the least significant bits of the result.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm_hadd_ps","","Horizontally add adjacent pairs of single-precision (32-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_add_ps","","Adds __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpeq_epi32","","Compare packed 32-bit integers in `a` and `b` for equality.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_rdtsc","","Reads the current value of the processor’s time-stamp counter.",N,[[],["i64"]]],[17,"_MM_EXCEPT_DIV_ZERO","","See `_mm_setcsr`",N,N],[5,"_mm_setzero_ps","","Construct a `__m128` with all elements initialized to zero.",N,[[],["__m128"]]],[5,"_mm_srli_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_round_ps","","Round the packed single-precision (32-bit) floating-point elements in `a` using the `rounding` parameter, and store the results as packed single-precision floating-point elements. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm_castps_si128","","Casts a 128-bit floating-point vector of `[4 x float]` into a 128-bit integer vector.",N,[[["__m128"]],["__m128i"]]],[17,"_MM_ROUND_TOWARD_ZERO","","See `_mm_setcsr`",N,N],[5,"_mm_testz_si128","","Tests whether the specified bits in a 128-bit integer vector are all zeros.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm256_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_m_maskmovq","","Conditionally copies the values from each 8-bit element in the first 64-bit integer vector operand to the specified memory location, as specified by the most significant bit in the corresponding element in the second 64-bit integer vector operand.",N,N],[17,"_MM_FROUND_CUR_DIRECTION","","use MXCSR.RC; see `vendor::_MM_SET_ROUNDING_MODE`",N,N],[5,"_mm256_testc_ps","","Compute the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m256"],["__m256"]],["i32"]]],[5,"_xsaves","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`",N,N],[17,"_CMP_FALSE_OS","","False (ordered, signaling)",N,N],[5,"_mm_sub_pi32","","Subtract packed 32-bit integers in `b` from packed 32-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_setzero_si256","","Return vector of type __m256i with all elements set to zero.",N,[[],["__m256i"]]],[5,"_mm_cmpord_pd","","Compare corresponding elements in `a` and `b` to see if neither is `NaN`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_rdrand32_step","","Read a hardware generated 32-bit random value and store the result in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u32"]],["i32"]]],[5,"_mm256_broadcastsi128_si256","","Broadcast 128 bits of integer data from a to all 128-bit lanes in the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_cvtepi32_epi64","","Sign extend packed 32-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_aeskeygenassist_si128","","Assist in expanding the AES cipher key.",N,[[["__m128i"],["i32"]],["__m128i"]]],[17,"_CMP_NGE_UQ","","Not-greater-than-or-equal (unordered, non-signaling)",N,N],[17,"_MM_ROUND_UP","","See `_mm_setcsr`",N,N],[5,"_mm_cvttss_si32","","Convert the lowest 32 bit float in the input vector to a 32 bit integer with truncation.",N,[[["__m128"]],["i32"]]],[5,"_mm_sub_pi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sqrt_sd","","Return a new vector with the low element of `a` replaced by the square root of the lower element `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_setr_m128d","","Set packed __m256d returned vector with the supplied values.",N,[[["__m128d"],["__m128d"]],["__m256d"]]],[17,"_CMP_LT_OQ","","Less-than (ordered, non-signaling)",N,N],[5,"_mm_slli_epi16","","Shift packed 16-bit integers in `a` left by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[17,"_MM_MASK_OVERFLOW","","See `_mm_setcsr`",N,N],[5,"_mm_min_pu8","","Compares the packed 8-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_tzmsk_u64","","Sets all bits below the least significant one of `x` and clears all other bits.",N,[[["u64"]],["u64"]]],[5,"_mm256_testc_pd","","Compute the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m256d"],["__m256d"]],["i32"]]],[5,"_mm_cvttss_si64","","Convert the lowest 32 bit float in the input vector to a 64 bit integer with truncation.",N,[[["__m128"]],["i64"]]],[5,"_mm256_castps_si256","","Casts vector of type __m256 to type __m256i.",N,[[["__m256"]],["__m256i"]]],[5,"_mm256_min_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cvtepi32_ps","","Convert packed 32-bit integers in `a` to packed single-precision (32-bit) floating-point elements.",N,[[["__m128i"]],["__m128"]]],[5,"_mm_cmpord_ss","","Check if the lowest `f32` of both inputs are ordered. The lowest 32 bits of the result will be `0xffffffff` if neither of `a.extract(0)` or `b.extract(0)` is a NaN, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_setr_pd","","Set packed double-precision (64-bit) floating-point elements in the return value with the supplied values in reverse order.",N,[[["f64"],["f64"]],["__m128d"]]],[5,"_mm_add_epi16","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_maskload_epi64","","Load packed 64-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_shuffle_epi8","","Shuffle bytes from `a` according to the content of `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_fxrstor","","Restores the `XMM`, `MMX`, `MXCSR`, and `x87` FPU registers from the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_mm_cmpneq_ss","","Compare the lowest `f32` of both inputs for inequality. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not equal to `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_unpacklo_epi64","","Unpack and interleave 64-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpgt_epi32","","Compare packed 32-bit integers in `a` and `b` for greater-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_maskstore_pd","","Store packed double-precision (64-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm_unpackhi_epi16","","Unpack and interleave 16-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_round_sd","","Round the lower double-precision (64-bit) floating-point element in `b` using the `rounding` parameter, store the result as a double-precision floating-point element in the lower element of the intrinsic result, and copy the upper element from `a` to the upper element of the intrinsic result. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm256_sub_epi64","","Subtract packed 64-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_comilt_sd","","Compare the lower element of `a` and `b` for less-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_sha1msg1_epu32","","Perform an intermediate calculation for the next four SHA1 message values (unsigned 32-bit integers) using previous message values from `a` and `b`, and returning the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_m_paddusb","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_floor_ss","","Round the lower single-precision (32-bit) floating-point element in `b` down to an integer value, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copy the upper 3 packed elements from `a` to the upper elements of the intrinsic result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpgt_pd","","Compare corresponding elements in `a` and `b` for greater-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_setzero_pd","","Return vector of type __m256d with all elements set to zero.",N,[[],["__m256d"]]],[5,"_mm256_max_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_stream_pd","","Stores a 128-bit floating point vector of `[2 x double]` to a 128-bit aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_m_pavgw","","Computes the rounded averages of the packed unsigned 16-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_movemask_epi8","","Return a mask of the most significant bit of each element in `a`.",N,[[["__m128i"]],["i32"]]],[5,"_mm_unpackhi_pi32","","Unpacks the upper element from two `i32x2` vectors and interleaves them into the result: `[a.1, b.1]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_broadcast_ss","","Broadcast a single-precision (32-bit) floating-point element from memory to all elements of the returned vector.",N,[[["f32"]],["__m128"]]],[5,"_mm_setr_epi32","","Set packed 32-bit integers with the supplied values in reverse order.",N,[[["i32"],["i32"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_prefetch","","Fetch the cache line that contains address `p` using the given `strategy`.",N,N],[5,"_mm_bsrli_si128","","Shift `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[17,"_SIDD_CMP_EQUAL_ORDERED","","Search for the defined substring in the target",N,N],[5,"_mm_storeu_si128","","Store 128-bits of integer data from `a` into memory.",N,N],[5,"_mm256_insert_epi8","","Copy `a` to result, and insert the 8-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i8"],["i32"]],["__m256i"]]],[5,"_m_paddsw","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_dp_ps","","Returns the dot product of two __m128 vectors.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm256_srai_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_m_psubd","","Subtract packed 32-bit integers in `b` from packed 32-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[17,"_CMP_LT_OS","","Less-than (ordered, signaling)",N,N],[5,"_mm_store_ss","","Store the lowest 32 bit float of `a` into memory.",N,N],[5,"_mm256_min_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return packed minimum values",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_comieq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm256_min_epi8","","Compare packed 8-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_extractf128_si256","","Extract 128 bits (composed of integer data) from `a`, selected with `imm8`.",N,[[["__m256i"],["i32"]],["__m128i"]]],[5,"_mm_cmpestrm","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return the generated mask.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm256_andnot_si256","","Compute the bitwise NOT of 256 bits (representing integer data) in `a` and then AND with `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[17,"_CMP_NLT_US","","Not-less-than (unordered, signaling)",N,N],[5,"_mm256_xor_si256","","Compute the bitwise XOR of 256 bits (representing integer data) in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_set1_pi8","","Broadcast 8-bit integer a to all all elements of dst.",N,[[["i8"]],["__m64"]]],[5,"_mm256_cmpgt_epi32","","Compare packed 32-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_zeroupper","","Zero the upper 128 bits of all YMM registers; the lower 128-bits of the registers are unmodified.",N,N],[5,"_blci_u32","","Sets all bits of `x` to 1 except for the least significant zero bit.",N,[[["u32"]],["u32"]]],[5,"_mm_srav_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in sign bits.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_mul_epu32","","Multiply the low unsigned 32-bit integers from each packed 64-bit element in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_fnmadd_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_extract_epi32","","Extract an 32-bit integer from `a` selected with `imm8`",N,[[["__m128i"],["i32"]],["i32"]]],[5,"_mm_add_pd","","Add packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_hadd_pd","","Horizontally add adjacent pairs of double-precision (64-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_add_ss","","Adds the first component of `a` and `b`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_avg_epu8","","Average packed unsigned 8-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_hadds_pi16","","Horizontally add the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`. Positive sums greater than 7FFFh are saturated to 7FFFh. Negative sums less than 8000h are saturated to 8000h.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_castsi128_ps","","Casts a 128-bit integer vector into a 128-bit floating-point vector of `[4 x float]`.",N,[[["__m128i"]],["__m128"]]],[5,"_mm_hadds_epi16","","Horizontally add the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`. Positive sums greater than 7FFFh are saturated to 7FFFh. Negative sums less than 8000h are saturated to 8000h.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sha256msg2_epu32","","Perform the final calculation for the next four SHA256 message values (unsigned 32-bit integers) using previous message values from `a` and `b`, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_floor_sd","","Round the lower double-precision (64-bit) floating-point element in `b` down to an integer value, store the result as a double-precision floating-point element in the lower element of the intrinsic result, and copy the upper element from `a` to the upper element of the intrinsic result.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_sign_epi16","","Negate packed 16-bit integers in `a` when the corresponding signed 16-bit integer in `b` is negative, and return the results. Elements in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_xrstors","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_mm_cmpeq_ss","","Compare the lowest `f32` of both inputs for equality. The lowest 32 bits of the result will be `0xffffffff` if the two inputs are equal, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_cmpgt_epi8","","Compare packed 8-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cmpge_pd","","Compare corresponding elements in `a` and `b` for greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_setzero_ps","","Return vector of type __m256 with all elements set to zero.",N,[[],["__m256"]]],[5,"_rdrand16_step","","Read a hardware generated 16-bit random value and store the result in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u16"]],["i32"]]],[5,"_mm_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_cvtsd_si64","","Convert the lower double-precision (64-bit) floating-point element in a to a 64-bit integer.",N,[[["__m128d"]],["i64"]]],[5,"_mm_sra_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[17,"_MM_ROUND_NEAREST","","See `_mm_setcsr`",N,N],[17,"_CMP_GE_OS","","Greater-than-or-equal (ordered, signaling)",N,N],[17,"_MM_FROUND_TO_POS_INF","","round up",N,N],[5,"_mm256_permute4x64_epi64","","Permutes 64-bit integers from `a` using control mask `imm8`.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_abs_epi16","","Compute the absolute value of each of the packed 16-bit signed integers in `a` and return the 16-bit unsigned integer",N,[[["__m128i"]],["__m128i"]]],[17,"_SIDD_POSITIVE_POLARITY","","Do not negate results (Default)",N,N],[5,"_mm_extract_pi16","","Extracts 16-bit element from a 64-bit vector of `[4 x i16]` and returns it, as specified by the immediate integer operand.",N,[[["__m64"],["i32"]],["i32"]]],[5,"_mm256_insert_epi16","","Copy `a` to result, and insert the 16-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i16"],["i32"]],["__m256i"]]],[5,"_mm_adds_pu16","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_ucomilt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm256_srai_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_mul_epi32","","Multiply the low 32-bit integers from each packed 64-bit element in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_MM_SET_ROUNDING_MODE","","See `_mm_setcsr`",N,N],[5,"_mm256_loadu2_m128","","Load two 128-bit values (composed of 4 packed single-precision (32-bit) floating-point elements) from memory, and combine them into a 256-bit value. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[17,"_MM_MASK_MASK","","See `_MM_GET_EXCEPTION_MASK`",N,N],[5,"_mm_cvtepu8_epi16","","Zero extend packed unsigned 8-bit integers in `a` to packed 16-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_srlv_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sign_pi16","","Negate packed 16-bit integers in `a` when the corresponding signed 16-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_testz_pd","","Compute the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m256d"],["__m256d"]],["i32"]]],[5,"_mm_cvtss_sd","","Convert the lower single-precision (32-bit) floating-point element in `b` to a double-precision (64-bit) floating-point element, store the result in the lower element of the return value, and copy the upper element from `a` to the upper element the return value.",N,[[["__m128d"],["__m128"]],["__m128d"]]],[5,"_mm256_hadd_epi16","","Horizontally add adjacent pairs of 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_slli_epi16","","Shift packed 16-bit integers in `a` left by `imm8` while shifting in zeros, return the results;",N,[[["__m256i"],["i32"]],["__m256i"]]],[17,"_MM_EXCEPT_INVALID","","See `_mm_setcsr`",N,N],[5,"_mm256_cvtsi256_si32","","Returns the first element of the input vector of `[8 x i32]`.",N,[[["__m256i"]],["i32"]]],[5,"_mm_set1_ps","","Construct a `__m128` with all element set to `a`.",N,[[["f32"]],["__m128"]]],[5,"_t1mskc_u32","","Clears all bits below the least significant zero of `x` and sets all other bits.",N,[[["u32"]],["u32"]]],[5,"_mm256_cvtepi32_ps","","Convert packed 32-bit integers in `a` to packed single-precision (32-bit) floating-point elements.",N,[[["__m256i"]],["__m256"]]],[5,"_mm_movelh_ps","","Combine lower half of `a` and `b`. The lower half of `b` occupies the higher half of result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpneq_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input elements are not equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_sign_epi8","","Negate packed 8-bit integers in `a` when the corresponding signed 8-bit integer in `b` is negative, and return the results. Results are zeroed out when the corresponding element in `b` is zero.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_fmaddsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_setcsr","","Set the MXCSR register with the 32-bit unsigned integer value.",N,N],[5,"_mm_avg_epu16","","Average packed unsigned 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_add_si64","","Adds two signed or unsigned 64-bit integer values, returning the lower 64 bits of the sum.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_xsavec64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_mm256_undefined_si256","","Return vector of type __m256i with undefined elements.",N,[[],["__m256i"]]],[5,"_MM_SHUFFLE","","A utility function for creating masks to use with Intel shuffle and permute intrinsics.",N,[[["u32"],["u32"],["u32"],["u32"]],["u32"]]],[5,"_mm256_and_pd","","Compute the bitwise AND of a packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fmsubadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_fmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_move_ss","","Return a `__m128` with the first component from `b` and the remaining components from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_dp_pd","","Returns the dot product of two __m128d vectors.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_blci_u64","","Sets all bits of `x` to 1 except for the least significant zero bit.",N,[[["u64"]],["u64"]]],[5,"_mm_srli_epi64","","Shift packed 64-bit integers in `a` right by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm256_cmp_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[17,"_SIDD_UNIT_MASK","","Mask only: return the byte mask",N,N],[5,"_mm_setr_ps","","Construct a `__m128` from four floating point values lowest to highest.",N,[[["f32"],["f32"],["f32"],["f32"]],["__m128"]]],[5,"_mm256_cvtps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m256"]],["__m256i"]]],[5,"_mm_mask_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_setr_m128i","","Set packed __m256i returned vector with the supplied values.",N,[[["__m128i"],["__m128i"]],["__m256i"]]],[5,"_mm_loadl_pd","","Loads a double-precision value into the low-order bits of a 128-bit vector of `[2 x double]`. The high-order bits are copied from the high-order bits of the first operand.",N,N],[5,"_mm_round_pd","","Round the packed double-precision (64-bit) floating-point elements in `a` using the `rounding` parameter, and store the results as packed double-precision floating-point elements. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128d"],["i32"]],["__m128d"]]],[5,"_xsetbv","","Copy 64-bits from `val` to the extended control register (`XCR`) specified by `a`.",N,N],[5,"_mm_broadcastw_epi16","","Broadcast the low packed 16-bit integer from a to all elements of the 128-bit returned value",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_test_all_ones","","Tests whether the specified bits in `a` 128-bit integer vector are all ones.",N,[[["__m128i"]],["i32"]]],[5,"_mm256_store_si256","","Store 256-bits of integer data from `a` into memory. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_fmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_castsi128_si256","","Casts vector of type __m128i to type __m256i; the upper 128 bits of the result are undefined.",N,[[["__m128i"]],["__m256i"]]],[5,"_m_paddd","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_undefined_ps","","Return vector of type __m128 with undefined elements.",N,[[],["__m128"]]],[5,"_blsr_u32","","Resets the lowest set bit of `x`.",N,[[["u32"]],["u32"]]],[5,"_mm256_mullo_epi32","","Multiply the packed 32-bit integers in `a` and `b`, producing intermediate 64-bit integers, and return the low 16 bits of the intermediate integers",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_storel_pi","","Store the lower half of `a` (64 bits) into memory.",N,N],[5,"_mm256_srli_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in zeros",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_cvtsd_ss","","Convert the lower double-precision (64-bit) floating-point element in `b` to a single-precision (32-bit) floating-point element, store the result in the lower element of the return value, and copy the upper element from `a` to the upper element the return value.",N,[[["__m128"],["__m128d"]],["__m128"]]],[5,"_mm_cmpestro","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return bit `0` of the resulting bit mask.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[17,"_SIDD_CMP_RANGES","","For each character in `a`, determine if `b[0] <= c <= b[1] or b[1] <= c <= b[2]...`",N,N],[5,"_mm_loaddup_pd","","Load a double-precision (64-bit) floating-point element from memory into both elements of return vector.",N,N],[5,"_mm256_extractf128_pd","","Extract 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `a`, selected with `imm8`.",N,[[["__m256d"],["i32"]],["__m128d"]]],[5,"_mm_movehl_ps","","Combine higher half of `a` and `b`. The highwe half of `b` occupies the lower half of result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_sign_epi32","","Negate packed 32-bit integers in `a` when the corresponding signed 32-bit integer in `b` is negative, and return the results. Results are zeroed out when the corresponding element in `b` is zero.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_abs_pi8","","Compute the absolute value of packed 8-bit integers in `a` and return the unsigned results.",N,[[["__m64"]],["__m64"]]],[5,"_mm256_srli_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in zeros",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_hadds_epi16","","Horizontally add adjacent pairs of 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_adds_epu16","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sign_pi32","","Negate packed 32-bit integers in `a` when the corresponding signed 32-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_min_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_xsave64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_mm256_unpackhi_epi32","","Unpack and interleave 32-bit integers from the high half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_comieq_sd","","Compare the lower element of `a` and `b` for equality.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_pext_u32","","Gathers the bits of `x` specified by the `mask` into the contiguous low order bit positions of the result.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm_mulhrs_epi16","","Multiply packed 16-bit signed integer values, truncate the 32-bit product to the 18 most significant bits by right-shifting, round the truncated value by adding 1, and write bits `[16:1]` to the destination.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mul_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_unpackhi_pd","","Unpack and interleave double-precision (64-bit) floating-point elements from the high half of each 128-bit lane in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_fmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[17,"_MM_FROUND_RAISE_EXC","","do not suppress exceptions",N,N],[5,"_mm_ucomige_sd","","Compare the lower element of `a` and `b` for greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_sha256rnds2_epu32","","Perform 2 rounds of SHA256 operation using an initial SHA256 state (C,D,G,H) from `a`, an initial SHA256 state (A,B,E,F) from `b`, and a pre-computed sum of the next 2 round message values (unsigned 32-bit integers) and the corresponding round constants from `k`, and store the updated SHA256 state (A,B,E,F) in dst.",N,[[["__m128i"],["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cvt_ss2si","","Alias for `_mm_cvtss_si32`.",N,[[["__m128"]],["i32"]]],[5,"_mm256_srli_epi64","","Shift packed 64-bit integers in `a` right by `imm8` while shifting in zeros",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_fnmsub_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_broadcastss_ps","","Broadcast the low single-precision (32-bit) floating-point element from `a` to all elements of the 128-bit returned value.",N,[[["__m128"]],["__m128"]]],[5,"_mm_cvtsi32_sd","","Return `a` with its lower element replaced by `b` after converting it to an `f64`.",N,[[["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_srai_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m128i"],["i32"]],["__m128i"]]],[17,"_CMP_NGT_UQ","","Not-greater-than (unordered, non-signaling)",N,N],[5,"_mm256_storeu_ps","","Store 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from `a` into memory. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_cvtepi16_epi32","","Sign extend packed 16-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_srl_epi64","","Shift packed 64-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"__get_cpuid_max","","Returns the highest-supported `leaf` (`EAX`) and sub-leaf (`ECX`) `cpuid` values.",N,N],[5,"_mm_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_unpacklo_pi32","","Unpacks the lower element from two `i32x2` vectors and interleaves them into the result: `[a.0, b.0]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cvtps_pi32","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128"]],["__m64"]]],[5,"_mm_ucomineq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are not equal, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_cmpeq_epi64","","Compare packed 64-bit integers in `a` and `b` for equality",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_broadcastb_epi8","","Broadcast the low packed 8-bit integer from `a` to all elements of the 128-bit returned value.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cmpge_ss","","Compare the lowest `f32` of both inputs for greater than or equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is greater than or equal `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_m_paddusw","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_slli_si128","","Shift `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[17,"_CMP_FALSE_OQ","","False (ordered, non-signaling)",N,N],[5,"_mm256_broadcast_ss","","Broadcast a single-precision (32-bit) floating-point element from memory to all elements of the returned vector.",N,[[["f32"]],["__m256"]]],[5,"_mm256_and_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_addsub_pd","","Alternatively add and subtract packed double-precision (64-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mulx_u32","","Unsigned multiply without affecting flags.",N,[[["u32"],["u32"],["u32"]],["u32"]]],[5,"_mm_fmsub_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`,  and subtract the lower element in `c` from the intermediate result. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_add_ps","","Add packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_min_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return the corresponding minimum values.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_mask_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[17,"_SIDD_CMP_EQUAL_EACH","","The strings defined by `a` and `b` are equal",N,N],[5,"_mm_subs_epi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_adds_pi8","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_blcmsk_u64","","Sets the least significant zero bit of `x` and clears all bits above that bit.",N,[[["u64"]],["u64"]]],[5,"_mm_sad_epu8","","Sum the absolute differences of packed unsigned 8-bit integers.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_sra_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_mpsadbw_epu8","","Compute the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in `a` compared to those in `b`, and store the 16-bit results in dst. Eight SADs are performed for each 128-bit lane using one quadruplet from `b` and eight quadruplets from `a`. One quadruplet is selected from `b` starting at on the offset specified in `imm8`. Eight quadruplets are formed from sequential 8-bit integers selected from `a` starting at the offset specified in `imm8`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[17,"_CMP_EQ_OS","","Equal (ordered, signaling)",N,N],[5,"_mm_insert_epi8","","Return a copy of `a` with the 8-bit integer from `i` inserted at a location specified by `imm8`.",N,[[["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_moveldup_ps","","Duplicate even-indexed single-precision (32-bit) floating-point elements from `a`.",N,[[["__m128"]],["__m128"]]],[5,"_rdrand64_step","","Read a hardware generated 64-bit random value and store the result in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u64"]],["i32"]]],[5,"_mm_set1_epi16","","Broadcast 16-bit integer `a` to all elements.",N,[[["i16"]],["__m128i"]]],[5,"_mm256_max_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_mul_epu32","","Multiply the low unsigned 32-bit integers from each packed 64-bit element in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_tzcnt_u64","","Counts the number of trailing least significant zero bits.",N,[[["u64"]],["u64"]]],[5,"_mm256_min_epi32","","Compare packed 32-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cvtepi32_pd","","Convert the lower two packed 32-bit integers in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128i"]],["__m128d"]]],[5,"_mm256_undefined_pd","","Return vector of type `__m256d` with undefined elements.",N,[[],["__m256d"]]],[5,"_mm_min_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return packed minimum.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpackhi_epi32","","Unpack and interleave 32-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mul_epi32","","Multiply the low 32-bit integers from each packed 64-bit element in `a` and `b`, and return the signed 64-bit result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_extract_epi32","","Extract a 32-bit integer from `a`, selected with `imm8`.",N,[[["__m256i"],["i32"]],["i32"]]],[5,"_mm_setr_pi32","","Set packed 32-bit integers in dst with the supplied values in reverse order.",N,[[["i32"],["i32"]],["__m64"]]],[5,"_mm256_maskstore_epi32","","Store packed 32-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_set_epi16","","Set packed 16-bit integers with the supplied values.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m128i"]]],[5,"_mm256_unpackhi_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the high half of each 128-bit lane in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_permutevar_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` using the control in `b`.",N,[[["__m128d"],["__m128i"]],["__m128d"]]],[5,"_mm_clmulepi64_si128","","Perform a carry-less multiplication of two 64-bit polynomials over the finite field GF(2^k).",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_xor_si128","","Compute the bitwise XOR of 128 bits (representing integer data) in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_abs_epi16","","Computes the absolute values of packed 16-bit integers in `a`.",N,[[["__m256i"]],["__m256i"]]],[5,"_mm_extract_epi8","","Extract an 8-bit integer from `a`, selected with `imm8`. Returns a 32-bit integer containing the zero-extended integer data.",N,[[["__m128i"],["i32"]],["i32"]]],[5,"_mm_ucomineq_sd","","Compare the lower element of `a` and `b` for not-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm256_storeu_pd","","Store 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_ceil_pd","","Round the packed double-precision (64-bit) floating-point elements in `a` up to an integer value, and store the results as packed double-precision floating-point elements.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm_cmpgt_epi64","","Compare packed 64-bit integers in `a` and `b` for greater-than, return the results.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_setr_epi16","","Set packed 16-bit integers with the supplied values in reverse order.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m128i"]]],[5,"_mm_storer_ps","","Store four 32-bit floats into aligned memory in reverse order.",N,N],[5,"_mm256_zeroall","","Zero the contents of all XMM or YMM registers.",N,N],[5,"_mm_castsi128_pd","","Casts a 128-bit integer vector into a 128-bit floating-point vector of `[2 x double]`.",N,[[["__m128i"]],["__m128d"]]],[5,"_blcfill_u32","","Clears all bits below the least significant zero bit of `x`.",N,[[["u32"]],["u32"]]],[5,"_mm_mask_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[3,"__m128i","","128-bit wide integer vector type, x86-specific",N,N],[17,"_SIDD_LEAST_SIGNIFICANT","","Index only: return the least significant bit (Default)",N,N],[5,"_mm_movemask_pi8","","Takes the most significant bit from each 8-bit element in a 64-bit integer vector to create a 16-bit mask value. Zero-extends the value to 32-bit integer and writes it to the destination.",N,[[["__m64"]],["i32"]]],[5,"_mm_load1_pd","","Load a double-precision (64-bit) floating-point element from memory into both elements of returned vector.",N,N],[5,"_mm256_shuffle_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` within 128-bit lanes using the control in `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm256_mask_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_set_m128i","","Set packed __m256i returned vector with the supplied values.",N,[[["__m128i"],["__m128i"]],["__m256i"]]],[5,"_mm_slli_epi64","","Shift packed 64-bit integers in `a` left by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[17,"_MM_MASK_DENORM","","See `_mm_setcsr`",N,N],[5,"_mm256_mulhrs_epi16","","Multiply packed 16-bit integers in `a` and `b`, producing intermediate signed 32-bit integers. Truncate each intermediate integer to the 18 most significant bits, round by adding 1, and return bits `[16:1]`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cmpunord_pd","","Compare corresponding elements in `a` and `b` to see if either is `NaN`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_castsi256_si128","","Casts vector of type __m256i to type __m128i.",N,[[["__m256i"]],["__m128i"]]],[17,"_MM_ROUND_DOWN","","See `_mm_setcsr`",N,N],[5,"_blsmsk_u32","","Get mask up to lowest set bit.",N,[[["u32"]],["u32"]]],[5,"_mm_minpos_epu16","","Finds the minimum unsigned 16-bit element in the 128-bit __m128i vector, returning a vector containing its value in its first position, and its index in its second position; all other elements are set to zero.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_div_ss","","Divides the first component of `b` by `a`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cvt_ps2pi","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128"]],["__m64"]]],[5,"_mm_cmpistrm","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return the generated mask.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_mulhi_pu16","","Multiplies packed 16-bit unsigned integer values and writes the high-order 16 bits of each 32-bit product to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_ucomigt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm256_srav_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in sign bits.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cmpge_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is greater than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_sqrt_pd","","Return a new vector with the square root of each of the values in `a`.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm256_fmaddsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_hadd_epi32","","Horizontally add adjacent pairs of 32-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[17,"_MM_MASK_INEXACT","","See `_mm_setcsr`",N,N],[5,"_mm_cvtpu16_ps","","Converts a 64-bit vector of `i16`s into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm_mulhrs_pi16","","Multiplies packed 16-bit signed integer values, truncates the 32-bit products to the 18 most significant bits by right-shifting, rounds the truncated value by adding 1, and writes bits `[16:1]` to the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmpnge_pd","","Compare corresponding elements in `a` and `b` for not-greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_unpackhi_epi8","","Unpack and interleave 8-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_cvtsd_f64","","Returns the first element of the input vector of `[4 x double]`.",N,[[["__m256d"]],["f64"]]],[5,"_mm_mulhi_epu16","","Multiply the packed unsigned 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_avg_pu8","","Computes the rounded averages of the packed unsigned 8-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_cvtepi32_pd","","Convert packed 32-bit integers in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128i"]],["__m256d"]]],[5,"_mm_packs_pi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using signed saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_packus_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using unsigned saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_loadu_ps","","Load 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from memory into result. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_unpackhi_pi8","","Unpacks the upper four elements from two `i8x8` vectors and interleaves them into the result: `[a.4, b.4, a.5, b.5, a.6, b.6, a.7, b.7]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_unpacklo_epi16","","Unpack and interleave 16-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_storeu_ps","","Store four 32-bit floats into memory. There are no restrictions on memory alignment. For aligned memory `_mm_store_ps` may be faster.",N,N],[5,"_mm_cvtepu16_epi64","","Zero extend packed unsigned 16-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_pdep_u32","","Scatter contiguous low order bits of `a` to the result at the positions specified by the `mask`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm_set_ss","","Construct a `__m128` with the lowest element set to `a` and the rest set to zero.",N,[[["f32"]],["__m128"]]],[17,"_MM_FROUND_TO_ZERO","","truncate",N,N],[5,"_mm256_sub_epi8","","Subtract packed 8-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_xsaves64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`",N,N],[5,"_mm256_testz_ps","","Compute the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m256"],["__m256"]],["i32"]]],[3,"CpuidResult","","Result of the `cpuid` instruction.",N,N],[12,"eax","","EAX register.",0,N],[12,"ebx","","EBX register.",0,N],[12,"ecx","","ECX register.",0,N],[12,"edx","","EDX register.",0,N],[17,"_MM_FROUND_TO_NEG_INF","","round down",N,N],[5,"_mm_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_unpackhi_epi8","","Unpack and interleave 8-bit integers from the high half of each 128-bit lane in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_testnzc_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`, and set `ZF` to 1 if the result is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, and set `CF` to 1 if the result is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m256i"],["__m256i"]],["i32"]]],[5,"_mm_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_broadcastsd_pd","","Broadcast the low double-precision (64-bit) floating-point element from `a` to all elements of the 256-bit returned value.",N,[[["__m128d"]],["__m256d"]]],[5,"_mm256_adds_epi16","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[17,"_CMP_EQ_US","","Equal (unordered, signaling)",N,N],[5,"_mm_blendv_epi8","","Blend packed 8-bit integers from `a` and `b` using `mask`",N,[[["__m128i"],["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpngt_ss","","Compare the lowest `f32` of both inputs for not-greater-than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not greater than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_broadcast_sd","","Broadcast a double-precision (64-bit) floating-point element from memory to all elements of the returned vector.",N,[[["f64"]],["__m256d"]]],[5,"_mm_cmpunord_sd","","Return a new vector with the low element of `a` replaced by the result of comparing both of the lower elements of `a` and `b` to `NaN`. If either is equal to `NaN` then `0xFFFFFFFFFFFFFFFF` is used and `0` otherwise.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_add_pd","","Add packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_load_si256","","Load 256-bits of integer data from memory into result. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_stream_ps","","Stores `a` into the memory at `mem_addr` using a non-temporal memory hint.",N,N],[5,"_mm_storel_epi64","","Store the lower 64-bit integer `a` to a memory location.",N,N],[5,"_mm_movehdup_ps","","Duplicate odd-indexed single-precision (32-bit) floating-point elements from `a`.",N,[[["__m128"]],["__m128"]]],[5,"_m_paddsb","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_mullo_pi16","","Multiplies packed 16-bit integer values and writes the low-order 16 bits of each 32-bit product to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_ucomieq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are equal, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_loadh_pi","","Set the upper two single-precision floating-point values with 64 bits of data loaded from the address `p`; the lower two values are passed through from `a`.",N,N],[5,"_mm_fmsub_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and subtract the lower element in `c` from the intermediate result. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[17,"_SIDD_CMP_EQUAL_ANY","","For each character in `a`, find if it is in `b` (Default)",N,N],[5,"_mm_cvtpi32x2_ps","","Converts the two 32-bit signed integer values from each 64-bit vector operand of `[2 x i32]` into a 128-bit vector of `[4 x float]`.",N,[[["__m64"],["__m64"]],["__m128"]]],[5,"_mm_comilt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_sllv_epi32","","Shift packed 32-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_min_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[17,"_CMP_GT_OS","","Greater-than (ordered, signaling)",N,N],[5,"_mm256_set_epi64x","","Set packed 64-bit integers in returned vector with the supplied values.",N,[[["i64"],["i64"],["i64"],["i64"]],["__m256i"]]],[5,"_mm256_cvtepi32_epi64","","Sign-extend 32-bit integers to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_shuffle_pi8","","Shuffle packed 8-bit integers in `a` according to shuffle control mask in the corresponding 8-bit element of `b`, and return the results",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_maskstore_epi64","","Store packed 64-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_fxsave","","Saves the `x87` FPU, `MMX` technology, `XMM`, and `MXCSR` registers to the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_mm_mullo_epi16","","Multiply the packed 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cvtpd_pi32","","Converts the two double-precision floating-point elements of a 128-bit vector of `[2 x double]` into two signed 32-bit integer values, returned in a 64-bit vector of `[2 x i32]`.",N,[[["__m128d"]],["__m64"]]],[5,"_blsi_u64","","Extract lowest set isolated bit.",N,[[["u64"]],["u64"]]],[5,"_mm256_set_epi8","","Set packed 8-bit integers in returned vector with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m256i"]]],[5,"_mm256_max_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_hsub_epi16","","Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_maskload_pd","","Load packed double-precision (64-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_xrstor64","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_mm_cmpord_sd","","Return a new vector with the low element of `a` replaced by the result of comparing both of the lower elements of `a` and `b` to `NaN`. If neither are equal to `NaN` then `0xFFFFFFFFFFFFFFFF` is used and `0` otherwise.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_sub_ps","","Subtract packed single-precision (32-bit) floating-point elements in `b` from packed elements in `a`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_lfence","","Perform a serializing operation on all load-from-memory instructions that were issued prior to this instruction.",N,N],[5,"_MM_SET_FLUSH_ZERO_MODE","","See `_mm_setcsr`",N,N],[5,"_mm_or_ps","","Bitwise OR of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_ucomigt_sd","","Compare the lower element of `a` and `b` for greater-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm256_srl_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm_storel_pd","","Stores the lower 64 bits of a 128-bit vector of `[2 x double]` to a memory location.",N,N],[5,"_mm_cmple_ss","","Compare the lowest `f32` of both inputs for less than or equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is less than or equal `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_set_ps1","","Alias for `_mm_set1_ps`",N,[[["f32"]],["__m128"]]],[17,"_MM_FROUND_NO_EXC","","suppress exceptions",N,N],[5,"_m_pavgb","","Computes the rounded averages of the packed unsigned 8-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cvtss_si32","","Convert the lowest 32 bit float in the input vector to a 32 bit integer.",N,[[["__m128"]],["i32"]]],[5,"_mm256_adds_epu8","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_loadh_pd","","Loads a double-precision value into the high-order bits of a 128-bit vector of `[2 x double]`. The low-order bits are copied from the low-order bits of the first operand.",N,N],[5,"_mm256_mask_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_add_pi16","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_min_pd","","Return a new vector with the minimum values from corresponding elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_storeh_pd","","Stores the upper 64 bits of a 128-bit vector of `[2 x double]` to a memory location.",N,N],[3,"__m128d","","128-bit wide set of two `f64` types, x86-specific",N,N],[5,"_blsfill_u64","","Sets all bits of `x` below the least significant one.",N,[[["u64"]],["u64"]]],[5,"_mm_abs_pi16","","Compute the absolute value of packed 8-bit integers in `a`, and return the unsigned results.",N,[[["__m64"]],["__m64"]]],[17,"_MM_HINT_T2","","See `_mm_prefetch`.",N,N],[5,"_mm_sll_epi64","","Shift packed 64-bit integers in `a` left by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_movedup_pd","","Duplicate the low double-precision (64-bit) floating-point element from `a`.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm256_set1_pd","","Broadcast double-precision (64-bit) floating-point value `a` to all elements of returned vector.",N,[[["f64"]],["__m256d"]]],[5,"_mm_min_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_undefined_ps","","Return vector of type `__m256` with undefined elements.",N,[[],["__m256"]]],[5,"_mm_insert_epi32","","Return a copy of `a` with the 32-bit integer from `i` inserted at a location specified by `imm8`.",N,[[["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm256_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_bswap","","Return an integer with the reversed byte order of x",N,[[["i32"]],["i32"]]],[5,"_mm256_maddubs_epi16","","Vertically multiply each unsigned 8-bit integer from `a` with the corresponding signed 8-bit integer from `b`, producing intermediate signed 16-bit integers. Horizontally add adjacent pairs of intermediate signed 16-bit integers",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpgt_epi64","","Compare packed 64-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_set_epi32","","Set packed 32-bit integers with the supplied values.",N,[[["i32"],["i32"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_cmple_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is less than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_unpacklo_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the lower half of `a` and `b`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_sign_epi16","","Negate packed 16-bit integers in `a` when the corresponding signed 16-bit integer in `b` is negative, and return the results. Results are zeroed out when the corresponding element in `b` is zero.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_ceil_ss","","Round the lower single-precision (32-bit) floating-point element in `b` up to an integer value, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copy the upper 3 packed elements from `a` to the upper elements of the intrinsic result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_alignr_pi8","","Concatenates the two 64-bit integer vector operands, and right-shifts the result by the number of bytes specified in the immediate operand.",N,[[["__m64"],["__m64"],["i32"]],["__m64"]]],[5,"_mm_addsub_ps","","Alternatively add and subtract packed single-precision (32-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_cvtepi8_epi32","","Sign-extend 8-bit integers to 32-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_adds_epu8","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_floor_ps","","Round packed single-precision (32-bit) floating point elements in `a` toward negative infinity.",N,[[["__m256"]],["__m256"]]],[5,"_mm_cmpnge_ss","","Compare the lowest `f32` of both inputs for not-greater-than-or-equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not greater than or equal to `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[3,"__m256d","","256-bit wide set of four `f64` types, x86-specific",N,N],[5,"_mm_crc32_u32","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 32-bit integer `v`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm256_setr_epi64x","","Set packed 64-bit integers in returned vector with the supplied values in reverse order.",N,[[["i64"],["i64"],["i64"],["i64"]],["__m256i"]]],[5,"_mm_sha256msg1_epu32","","Perform an intermediate calculation for the next four SHA256 message values (unsigned 32-bit integers) using previous message values from `a` and `b`, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mask_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_cmpeq_epi16","","Compare packed 16-bit integers in `a` and `b` for equality.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_maskload_ps","","Load packed single-precision (32-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm256_srl_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm_add_epi8","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_mask_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_rsqrt_ps","","Return the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in `a`.",N,[[["__m128"]],["__m128"]]],[17,"_SIDD_SBYTE_OPS","","String contains signed 8-bit characters",N,N],[5,"_mm_unpackhi_pi16","","Unpacks the upper two elements from two `i16x4` vectors and interleaves them into the result: `[a.2, b.2, a.3, b.3]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_undefined_si128","","Return vector of type __m128i with undefined elements.",N,[[],["__m128i"]]],[5,"_mm256_insertf128_ps","","Copy `a` to result, then insert 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from `b` into result at the location specified by `imm8`.",N,[[["__m256"],["__m128"],["i32"]],["__m256"]]],[5,"_mm_cvtepu32_epi64","","Zero extend packed unsigned 32-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_or_si256","","Compute the bitwise OR of 256 bits (representing integer data) in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_set1_pd","","Broadcast double-precision (64-bit) floating-point value a to all elements of the return value.",N,[[["f64"]],["__m128d"]]],[5,"_mm_cvttps_pi32","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128"]],["__m64"]]],[5,"_mm256_mul_ps","","Add packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_loadr_ps","","Load four `f32` values from aligned memory into a `__m128` in reverse order.",N,N],[5,"_mm_test_mix_ones_zeros","","Tests whether the specified bits in a 128-bit integer vector are neither all zeros nor all ones.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm256_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_add_epi8","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_rdseed64_step","","Read a 64-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u64"]],["i32"]]],[5,"_mm_movpi64_epi64","","Moves the 64-bit operand to a 128-bit integer vector, zeroing the upper bits.",N,[[["__m64"]],["__m128i"]]],[5,"_mm_maddubs_pi16","","Multiplies corresponding pairs of packed 8-bit unsigned integer values contained in the first source operand and packed 8-bit signed integer values contained in the second source operand, adds pairs of contiguous products with signed saturation, and writes the 16-bit sums to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_cvtepu8_epi16","","Zero-extend unsigned 8-bit integers in `a` to 16-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_set1_ps","","Broadcast single-precision (32-bit) floating-point value `a` to all elements of returned vector.",N,[[["f32"]],["__m256"]]],[5,"_mm256_sub_epi32","","Subtract packed 32-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_setr_m128","","Set packed __m256 returned vector with the supplied values.",N,[[["__m128"],["__m128"]],["__m256"]]],[17,"_MM_MASK_DIV_ZERO","","See `_mm_setcsr`",N,N],[5,"_mm_abs_epi32","","Compute the absolute value of each of the packed 32-bit signed integers in `a` and return the 32-bit unsigned integer",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_cvtepu8_epi64","","Zero-extend the lower four unsigned 8-bit integers in `a` to 64-bit integers. The upper twelve elements of `a` are unused.",N,[[["__m128i"]],["__m256i"]]],[5,"_pdep_u64","","Scatter contiguous low order bits of `a` to the result at the positions specified by the `mask`.",N,[[["u64"],["u64"]],["u64"]]],[5,"_mm_min_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpneq_sd","","Return a new vector with the low element of `a` replaced by the not-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_permute_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` within 128-bit lanes using the control in `imm8`.",N,[[["__m256"],["i32"]],["__m256"]]],[5,"_mm_blend_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using mask `imm4`",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"__rdtscp","","Reads the current value of the processor’s time-stamp counter and the `IA32_TSC_AUX MSR`.",N,N],[5,"_mm_mul_su32","","Multiplies 32-bit unsigned integer values contained in the lower bits of the two 64-bit integer vectors and returns the 64-bit unsigned product.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_xrstors64","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_mm_cmpgt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is greater than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_or_pd","","Compute the bitwise OR of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_insert_ps","","Select a single value in `a` to store at some position in `b`, Then zero elements according to `imm8`.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm256_extract_epi16","","Extract a 16-bit integer from `a`, selected with `imm8`. Returns a 32-bit integer containing the zero-extended integer data.",N,[[["__m256i"],["i32"]],["i16"]]],[5,"_mm256_bslli_epi128","","Shift 128-bit lanes in `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_div_sd","","Return a new vector with the low element of `a` replaced by the result of diving the lower element of `a` by the lower element of `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_xsavec","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_mm256_sad_epu8","","Compute the absolute differences of packed unsigned 8-bit integers in `a` and `b`, then horizontally sum each consecutive 8 differences to produce four unsigned 16-bit integers, and pack these unsigned 16-bit integers in the low 16 bits of the 64-bit return value",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_mulhi_epi16","","Multiply the packed 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_dp_ps","","Conditionally multiply the packed single-precision (32-bit) floating-point elements in `a` and `b` using the high 4 bits in `imm8`, sum the four products, and conditionally return the sum  using the low 4 bits of `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_xsave","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_mm256_cvtpd_ps","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed single-precision (32-bit) floating-point elements.",N,[[["__m256d"]],["__m128"]]],[5,"_mm_hadd_epi32","","Horizontally add the adjacent pairs of values contained in 2 packed 128-bit vectors of `[4 x i32]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_permute2x128_si256","","Shuffle 128-bits of integer data selected by `imm8` from `a` and `b`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_cvtsi64_sd","","Return `a` with its lower element replaced by `b` after converting it to an `f64`.",N,[[["__m128d"],["i64"]],["__m128d"]]],[5,"_mm256_cmp_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_MM_GET_ROUNDING_MODE","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_m_pmovmskb","","Takes the most significant bit from each 8-bit element in a 64-bit integer vector to create a 16-bit mask value. Zero-extends the value to 32-bit integer and writes it to the destination.",N,[[["__m64"]],["i32"]]],[5,"_mm_xor_ps","","Bitwise exclusive OR of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_set_m128d","","Set packed __m256d returned vector with the supplied values.",N,[[["__m128d"],["__m128d"]],["__m256d"]]],[5,"_mm_store_si128","","Store 128-bits of integer data from `a` into memory.",N,N],[5,"_mm_store_ps","","Store four 32-bit floats into aligned memory.",N,N],[5,"_mm256_adds_epi8","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cvtsd_si32","","Convert the lower double-precision (64-bit) floating-point element in a to a 32-bit integer.",N,[[["__m128d"]],["i32"]]],[17,"_CMP_EQ_OQ","","Equal (ordered, non-signaling)",N,N],[5,"_mm_unpacklo_pi16","","Unpacks the lower two elements from two `i16x4` vectors and interleaves them into the result: `[a.0 b.0 a.1 b.1]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_ucomile_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than or equal to the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm256_movemask_epi8","","Create mask from the most significant bit of each 8-bit element in `a`, return the result.",N,[[["__m256i"]],["i32"]]],[14,"is_arm_feature_detected","stdsimd","",N,N],[14,"is_aarch64_feature_detected","","",N,N],[14,"is_powerpc_feature_detected","","",N,N],[14,"is_powerpc64_feature_detected","","",N,N],[14,"is_mips_feature_detected","","",N,N],[14,"is_mips64_feature_detected","","",N,N],[14,"is_x86_feature_detected","","A macro to test at runtime whether a CPU feature is available on x86/x86-64 platforms.",N,N],[11,"try_from","stdsimd::arch::x86_64","",1,[[["u"]],["result"]]],[11,"from","","",1,[[["t"]],["t"]]],[11,"try_into","","",1,[[["self"]],["result"]]],[11,"into","","",1,[[["self"]],["u"]]],[11,"borrow","","",1,[[["self"]],["t"]]],[11,"borrow_mut","","",1,[[["self"]],["t"]]],[11,"get_type_id","","",1,[[["self"]],["typeid"]]],[11,"to_owned","","",1,[[["self"]],["t"]]],[11,"clone_into","","",1,N],[11,"partial_cmp","","",0,[[["self"],["cpuidresult"]],["option",["ordering"]]]],[11,"lt","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"le","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"gt","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"ge","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"clone","","",0,[[["self"]],["cpuidresult"]]],[11,"clone","","",2,[[["self"]],["__m256d"]]],[11,"clone","","",3,[[["self"]],["__m128i"]]],[11,"clone","","",4,[[["self"]],["__m256i"]]],[11,"clone","","",5,[[["self"]],["__m128d"]]],[11,"clone","","",1,[[["self"]],["__m128"]]],[11,"clone","","",6,[[["self"]],["__m64"]]],[11,"clone","","",7,[[["self"]],["__m256"]]],[11,"eq","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"ne","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"cmp","","",0,[[["self"],["cpuidresult"]],["ordering"]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",3,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",2,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",1,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",5,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result",["error"]]]],[11,"try_from","","",4,[[["u"]],["result"]]],[11,"from","","",4,[[["t"]],["t"]]],[11,"try_into","","",4,[[["self"]],["result"]]],[11,"into","","",4,[[["self"]],["u"]]],[11,"borrow","","",4,[[["self"]],["t"]]],[11,"borrow_mut","","",4,[[["self"]],["t"]]],[11,"get_type_id","","",4,[[["self"]],["typeid"]]],[11,"to_owned","","",4,[[["self"]],["t"]]],[11,"clone_into","","",4,N],[11,"try_from","","",7,[[["u"]],["result"]]],[11,"from","","",7,[[["t"]],["t"]]],[11,"try_into","","",7,[[["self"]],["result"]]],[11,"into","","",7,[[["self"]],["u"]]],[11,"borrow","","",7,[[["self"]],["t"]]],[11,"borrow_mut","","",7,[[["self"]],["t"]]],[11,"get_type_id","","",7,[[["self"]],["typeid"]]],[11,"to_owned","","",7,[[["self"]],["t"]]],[11,"clone_into","","",7,N],[11,"try_from","","",6,[[["u"]],["result"]]],[11,"from","","",6,[[["t"]],["t"]]],[11,"try_into","","",6,[[["self"]],["result"]]],[11,"into","","",6,[[["self"]],["u"]]],[11,"borrow","","",6,[[["self"]],["t"]]],[11,"borrow_mut","","",6,[[["self"]],["t"]]],[11,"get_type_id","","",6,[[["self"]],["typeid"]]],[11,"to_owned","","",6,[[["self"]],["t"]]],[11,"clone_into","","",6,N],[11,"try_from","","",3,[[["u"]],["result"]]],[11,"from","","",3,[[["t"]],["t"]]],[11,"try_into","","",3,[[["self"]],["result"]]],[11,"into","","",3,[[["self"]],["u"]]],[11,"borrow","","",3,[[["self"]],["t"]]],[11,"borrow_mut","","",3,[[["self"]],["t"]]],[11,"get_type_id","","",3,[[["self"]],["typeid"]]],[11,"to_owned","","",3,[[["self"]],["t"]]],[11,"clone_into","","",3,N],[11,"try_from","","",0,[[["u"]],["result"]]],[11,"from","","",0,[[["t"]],["t"]]],[11,"try_into","","",0,[[["self"]],["result"]]],[11,"into","","",0,[[["self"]],["u"]]],[11,"borrow","","",0,[[["self"]],["t"]]],[11,"borrow_mut","","",0,[[["self"]],["t"]]],[11,"get_type_id","","",0,[[["self"]],["typeid"]]],[11,"to_owned","","",0,[[["self"]],["t"]]],[11,"clone_into","","",0,N],[11,"try_from","","",5,[[["u"]],["result"]]],[11,"from","","",5,[[["t"]],["t"]]],[11,"try_into","","",5,[[["self"]],["result"]]],[11,"into","","",5,[[["self"]],["u"]]],[11,"borrow","","",5,[[["self"]],["t"]]],[11,"borrow_mut","","",5,[[["self"]],["t"]]],[11,"get_type_id","","",5,[[["self"]],["typeid"]]],[11,"to_owned","","",5,[[["self"]],["t"]]],[11,"clone_into","","",5,N],[11,"try_from","","",2,[[["u"]],["result"]]],[11,"from","","",2,[[["t"]],["t"]]],[11,"try_into","","",2,[[["self"]],["result"]]],[11,"into","","",2,[[["self"]],["u"]]],[11,"borrow","","",2,[[["self"]],["t"]]],[11,"borrow_mut","","",2,[[["self"]],["t"]]],[11,"get_type_id","","",2,[[["self"]],["typeid"]]],[11,"to_owned","","",2,[[["self"]],["t"]]],[11,"clone_into","","",2,N]],"paths":[[3,"CpuidResult"],[3,"__m128"],[3,"__m256d"],[3,"__m128i"],[3,"__m256i"],[3,"__m128d"],[3,"__m64"],[3,"__m256"]]};
initSearch(searchIndex);
